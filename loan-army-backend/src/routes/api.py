from flask import Blueprint, request, jsonify, make_response, render_template, Response, current_app, g
from src.models.league import db, League, Team, LoanedPlayer, Newsletter, UserSubscription, EmailToken, LoanFlag, AdminSetting, NewsletterComment, UserAccount, SupplementalLoan, NewsletterPlayerYoutubeLink, NewsletterCommentary, Player, JournalistTeamAssignment, CommentaryApplause, TeamTrackingRequest, StripeSubscription, NewsletterDigestQueue, JournalistSubscription, BackgroundJob, TeamSubreddit, RedditPost, TeamAlias, ManualPlayerSubmission, CommunityTake, AcademyAppearance, _as_utc, _dedupe_loans
from src.models.sponsor import Sponsor
from src.api_football_client import APIFootballClient
from src.admin.sandbox_tasks import (
    SandboxContext,
    TaskExecutionError,
    TaskNotFoundError,
    TaskValidationError,
    list_tasks as sandbox_list_tasks,
    run_task as sandbox_run_task,
)
from datetime import datetime, date, timedelta, timezone
import uuid
import json
import logging
import csv
import io
import math
import re
import os
import shutil
from io import BytesIO
from functools import wraps
from uuid import uuid4
from sqlalchemy import or_, func
import time
from datetime import timedelta
from typing import Any
from itsdangerous import URLSafeTimedSerializer, BadSignature, SignatureExpired
import secrets
import base64
import string
import requests
from src.extensions import limiter
from src.utils.sanitize import sanitize_comment_body, sanitize_plain_text, sanitize_commentary_html
from src.agents.errors import NoActiveLoaneesError
from src.utils.newsletter_slug import compose_newsletter_public_slug
from src.services.email_service import email_service
import threading

# Import auth utilities from the extracted auth module
from src.auth import (
    require_api_key,
    require_user_auth,
    issue_user_token,
    _user_serializer,
    _get_authorized_email,
    _admin_email_list,
    _ensure_user_account,
    _generate_default_display_name,
    _normalize_display_name,
    _make_display_name_unique,
    get_client_ip,
    ALLOWED_ADMIN_IPS,
    _safe_error_payload,
    _is_production,
)
from src.utils.background_jobs import (
    create_background_job as _create_background_job,
    update_job as _update_job,
    get_job as _get_job,
)

logger = logging.getLogger(__name__)

api_bp = Blueprint('api', __name__)

# Background job functions (_create_background_job, _update_job, _get_job) are imported from src.utils.background_jobs


class LazyAPIFootballClient:
    """Instantiate APIFootballClient only when first touched to avoid early network calls."""

    def __init__(self, factory):
        self._factory = factory
        self._instance = None

    def _resolve(self):
        if self._instance is None:
            self._instance = self._factory()
        return self._instance

    def __getattr__(self, item: str):
        return getattr(self._resolve(), item)

    def __repr__(self) -> str:
        state = "initialized" if self._instance is not None else "uninitialized"
        return f"<LazyAPIFootballClient {state}>"


# Initialize API-Football client lazily to keep migrations/test tools offline-friendly
api_client = LazyAPIFootballClient(APIFootballClient)

SUBSCRIPTIONS_REQUIRE_VERIFY = os.getenv('SUBSCRIPTIONS_REQUIRE_VERIFY', '1').lower() in ('1', 'true', 'yes', 'on')
try:
    SUBSCRIPTIONS_VERIFY_TTL_MINUTES = int(os.getenv('SUBSCRIPTIONS_VERIFY_TTL_MINUTES') or 60 * 24)
except Exception:
    SUBSCRIPTIONS_VERIFY_TTL_MINUTES = 60 * 24


# require_api_key, require_user_auth, and other auth utilities are imported from src.auth

# CORS support - only add headers not already set by Flask-CORS
# Do NOT override Access-Control-Allow-Origin (Flask-CORS in main.py handles this based on CORS_ALLOW_ORIGINS)
@api_bp.after_request
def after_request(response):
    if 'Access-Control-Allow-Headers' not in response.headers:
        response.headers.add('Access-Control-Allow-Headers', 'Content-Type,Authorization,X-API-Key,X-Admin-Key')
    if 'Access-Control-Allow-Methods' not in response.headers:
        response.headers.add('Access-Control-Allow-Methods', 'GET,PUT,POST,DELETE,OPTIONS')
    return response


@api_bp.route('/admin/auth-check', methods=['GET'])
@require_api_key
def admin_auth_check():
    """Lightweight endpoint to verify admin credentials from the client UI."""
    return jsonify({
        'status': 'ok',
        'user': getattr(g, 'user_email', None),
    })


@api_bp.route('/admin/sandbox', methods=['GET'])
@require_api_key
def admin_sandbox_home():
    """Render the admin sandbox interface with available diagnostic tasks."""
    teams = Team.query.order_by(Team.name.asc()).all()
    logger.info("[admin-sandbox] fetched %d teams (pre-dedupe) for dropdown", len(teams))
    # Deduplicate by lowercase name, keep the latest id
    dedup: dict[str, Team] = {}
    for t in teams:
        key = (t.name or '').strip().lower()
        if key:
            dedup[key] = t
    teams = sorted(dedup.values(), key=lambda t: (t.name or '').lower())
    logger.info("[admin-sandbox] teams after dedupe: %d", len(teams))
    if not teams:
        logger.warning("[admin-sandbox] no teams found in database")
    else:
        sample = ", ".join(f"{team.name}#{team.team_id}" for team in teams[:5])
        logger.debug("[admin-sandbox] sample teams: %s", sample)

    team_options = [
        {
            'label': f"{team.name} (API #{team.team_id})",
            'value': team.name,
            'team_id': team.team_id,
            'team_db_id': team.id,
        }
        for team in teams
    ]

    tasks = [
        {
            'task_id': task.task_id,
            'label': task.label,
            'description': task.description,
            'parameters': [
                {
                    **param,
                    'options': team_options if param.get('name') == 'team_name' else param.get('options'),
                }
                for param in task.parameters
            ],
        }
        for task in sandbox_list_tasks()
    ]
    accept_json = request.accept_mimetypes['application/json']
    accept_html = request.accept_mimetypes['text/html']
    wants_json = (
        request.args.get('format') == 'json'
        or (accept_json > accept_html and accept_json > 0)
    )
    if wants_json:
        return jsonify({'tasks': tasks})
    return render_template('admin_sandbox.html', tasks=tasks)


@api_bp.route('/admin/sandbox/run/<task_id>', methods=['POST'])
@require_api_key
def admin_sandbox_run(task_id: str):
    """Execute a sandbox diagnostic task and return the structured result."""

    payload = request.get_json(silent=True) or {}
    context = SandboxContext(db_session=db.session, api_client=api_client)

    try:
        result = sandbox_run_task(task_id, payload, context)
    except TaskNotFoundError as exc:
        return (
            jsonify({'status': 'error', 'summary': str(exc), 'payload': {}, 'task_id': task_id}),
            404,
        )
    except TaskValidationError as exc:
        return (
            jsonify({'status': 'error', 'summary': str(exc), 'payload': {}, 'task_id': task_id}),
            400,
        )
    except TaskExecutionError as exc:
        return (
            jsonify({'status': 'error', 'summary': str(exc), 'payload': {}, 'task_id': task_id}),
            500,
        )

    return jsonify(result)


@api_bp.route('/admin/users', methods=['GET'])
@require_api_key
def admin_get_users():
    """Get all users with their subscriptions and assignments."""
    try:
        users = UserAccount.query.order_by(UserAccount.created_at.desc()).all()
        result = []
        for user in users:
            # Get subscriptions (teams they follow)
            # Note: UserSubscription links by email, not user_id
            subscriptions = UserSubscription.query.filter_by(email=user.email, active=True).all()
            following = []
            for sub in subscriptions:
                if sub.team:
                    following.append({
                        'team_id': sub.team.team_id,
                        'name': sub.team.name
                    })
            
            # Get assignments (teams they report on)
            assignments = JournalistTeamAssignment.query.filter_by(user_id=user.id).all()
            reporting = []
            for assign in assignments:
                if assign.team:
                    reporting.append({
                        'team_id': assign.team.team_id,
                        'name': assign.team.name
                    })
            
            user_data = user.to_dict()
            user_data['following'] = following
            user_data['reporting'] = reporting
            result.append(user_data)
            
        return jsonify(result)
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'Failed to fetch users')), 500


@api_bp.route('/admin/users/<int:user_id>/role', methods=['POST'])
@require_api_key
def admin_toggle_user_role(user_id):
    """Toggle user role (specifically journalist status)."""
    try:
        data = request.get_json() or {}
        is_journalist = data.get('is_journalist')
        
        if is_journalist is None:
            return jsonify({'error': 'is_journalist boolean is required'}), 400
            
        user = UserAccount.query.get(user_id)
        if not user:
            return jsonify({'error': 'User not found'}), 404
            
        user.is_journalist = bool(is_journalist)
        # If becoming a journalist, ensure they can author commentary
        if user.is_journalist:
            user.can_author_commentary = True
            
        db.session.commit()
        
        return jsonify({
            'message': f"User role updated. Journalist: {user.is_journalist}",
            'user': user.to_dict()
        })
    except Exception as e:
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to update user role')), 500


@api_bp.route('/admin/users/<int:user_id>/editor-role', methods=['POST'])
@require_api_key
def admin_toggle_editor_role(user_id):
    """Toggle user's editor status (can manage external writers)."""
    try:
        data = request.get_json() or {}
        is_editor = data.get('is_editor')

        if is_editor is None:
            return jsonify({'error': 'is_editor boolean is required'}), 400

        user = UserAccount.query.get(user_id)
        if not user:
            return jsonify({'error': 'User not found'}), 404

        user.is_editor = bool(is_editor)
        user.updated_at = datetime.now(timezone.utc)
        db.session.commit()

        return jsonify({
            'message': f"Editor status {'granted' if is_editor else 'revoked'}",
            'user': user.to_dict()
        })
    except Exception as e:
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to update editor role')), 500


# Auth utilities (_user_serializer, _ensure_user_account, issue_user_token, require_user_auth,
# _get_authorized_email, _is_production, _safe_error_payload, display name helpers) are imported from src.auth
# _send_login_code is now in auth_routes.py


def _send_email_via_webhook(
    *,
    email: str,
    subject: str,
    text: str,
    html: str | None = None,
    meta: dict | None = None,
    http_method_override: str | None = None,
) -> dict:
    """Send email via email service (Mailgun/SMTP).
    
    This function maintains backward compatibility with the old n8n webhook interface.
    The meta and http_method_override parameters are ignored but kept for compatibility.
    """
    if not email_service.is_configured():
        raise RuntimeError('Email service is not configured (set MAILGUN_* or SMTP_* env vars)')

    # Extract tags from meta if present
    tags = None
    if meta and 'kind' in meta:
        tags = [meta['kind']]

    try:
        result = email_service.send_email(
            to=email,
            subject=subject,
            html=html or text,
            text=text,
            tags=tags,
        )
        return {
            'status': 'ok' if result.success else 'error',
            'http_status': result.http_status or (200 if result.success else 500),
            'response_text': result.message_id or result.error or '',
            'provider': result.provider,
        }
    except Exception as exc:
        logger.exception('Failed to send email to %s', email)
        raise RuntimeError(f'Email delivery failed: {exc}') from exc


def _send_subscription_verification_email(email: str, team_names: list[str], token: str) -> dict:
    public_base = os.getenv('PUBLIC_BASE_URL', '').rstrip('/')
    confirm_path = f"/verify?token={token}"
    confirm_url = f"{public_base}{confirm_path}" if public_base else confirm_path

    subject = f"Confirm your newsletter subscription"

    team_lines_html = ''.join(f'<li>{name}</li>' for name in team_names)
    team_lines_text = '\n'.join(f" ‚Ä¢ {name}" for name in team_names)

    html = f"""
    <p>Thanks for subscribing to The Academy Watch newsletters.</p>
    <p>Please confirm your email address to start receiving weekly updates.</p>
    <p><a href="{confirm_url}">Confirm subscription</a></p>
    <p>You requested updates for:</p>
    <ul>{team_lines_html}</ul>
    <p>If you did not make this request, you can ignore this message.</p>
    """
    text = (
        "Thanks for subscribing to The Academy Watch newsletters.\n\n"
        "Confirm your email address to start receiving updates:\n"
        f"{confirm_url}\n\n"
        "You requested updates for:\n"
        f"{team_lines_text}\n\n"
        "If you did not make this request, you can ignore this message."
    )

    meta = {
        'kind': 'subscription_verification',
        'team_count': len(team_names),
    }
    return _send_email_via_webhook(email=email, subject=subject, text=text, html=html, meta=meta)


def _send_waitlist_welcome_email(email: str, team_names: list[str]) -> dict:
    """Send a welcome email for teams that don't have active newsletters yet."""
    subject = "Thanks for your interest in The Academy Watch newsletters"
    
    team_lines_html = ''.join(f'<li>{name}</li>' for name in team_names)
    team_lines_text = '\n'.join(f" ‚Ä¢ {name}" for name in team_names)
    
    html = f"""
    <p>Thanks for subscribing to The Academy Watch newsletters!</p>
    <p>You've subscribed to the following team(s):</p>
    <ul>{team_lines_html}</ul>
    <p><strong>Important:</strong> We're not currently generating newsletters for {'this team' if len(team_names) == 1 else 'these teams'} yet. 
    Newsletter generation is resource-intensive, and we only activate it once a team has sufficient subscriber interest.</p>
    <p>We'll notify you via email once we start creating newsletters for your selected team(s). 
    In the meantime, thank you for your patience and support!</p>
    <p>If you have any questions, feel free to reach out.</p>
    """
    
    text = (
        "Thanks for subscribing to The Academy Watch newsletters!\n\n"
        "You've subscribed to:\n"
        f"{team_lines_text}\n\n"
        f"Important: We're not currently generating newsletters for {'this team' if len(team_names) == 1 else 'these teams'} yet. "
        "Newsletter generation is resource-intensive, and we only activate it once a team has sufficient subscriber interest.\n\n"
        "We'll notify you via email once we start creating newsletters for your selected team(s). "
        "In the meantime, thank you for your patience and support!"
    )
    
    meta = {
        'kind': 'waitlist_welcome',
        'team_count': len(team_names),
    }
    return _send_email_via_webhook(email=email, subject=subject, text=text, html=html, meta=meta)


@api_bp.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint."""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now(timezone.utc).isoformat(),
        'api_version': '1.3.0',
        'features': {
            'transfer_windows': True,
            'window_key_support': True,
            'backward_compatibility': True,
            'team_name_resolution': True,
            'enhanced_loan_detection': True,
            'outbound_loan_sweep': True,
            'csv_table_split': True
        }
    })

@api_bp.route('/options', methods=['OPTIONS'])
def handle_options():
    return '', 200

# Auth endpoints (/auth/request-code, /auth/me, /auth/verify-code, /auth/display-name, /auth/status)
# are now in src/routes/auth_routes.py

@api_bp.route('/user/email-preferences', methods=['GET', 'PATCH'])
@require_user_auth
def user_email_preferences():
    """Get or update user's email delivery preference."""
    try:
        email = getattr(g, 'user_email', None)
        if not email:
            return jsonify({'error': 'auth context missing email'}), 401
        
        user = UserAccount.query.filter_by(email=email).first()
        if not user:
            user = _ensure_user_account(email)
        
        if request.method == 'PATCH':
            payload = request.get_json() or {}
            pref = (payload.get('email_delivery_preference') or '').strip().lower()
            if pref not in ('individual', 'digest'):
                return jsonify({'error': 'email_delivery_preference must be "individual" or "digest"'}), 400
            user.email_delivery_preference = pref
            user.updated_at = datetime.now(timezone.utc)
            db.session.commit()
        
        return jsonify({
            'email_delivery_preference': user.email_delivery_preference or 'individual',
            'user_id': user.id,
        })
    except Exception as e:
        try:
            db.session.rollback()
        except Exception:
            pass
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500


@api_bp.route('/user/all-subscriptions', methods=['GET'])
@require_user_auth
def user_all_subscriptions():
    """Get all user's subscriptions (both free team subs and paid journalist subs)."""
    try:
        email = getattr(g, 'user_email', None)
        if not email:
            return jsonify({'error': 'auth context missing email'}), 401
        
        user = UserAccount.query.filter_by(email=email).first()
        
        # Get free team subscriptions (by email)
        team_subs = UserSubscription.query.filter_by(email=email, active=True).all()
        free_subscriptions = []
        for sub in team_subs:
            team = sub.team
            free_subscriptions.append({
                'id': sub.id,
                'type': 'free',
                'team_id': sub.team_id,
                'team_name': team.name if team else None,
                'team_logo': team.logo if team else None,
                'created_at': sub.created_at.isoformat() if sub.created_at else None,
                'last_email_sent': sub.last_email_sent.isoformat() if sub.last_email_sent else None,
            })
        
        # Get PAID journalist subscriptions (Stripe only)
        paid_subscriptions = []
        
        if user:
            stripe_subs = StripeSubscription.query.filter_by(
                subscriber_user_id=user.id
            ).filter(StripeSubscription.status.in_(['active', 'trialing', 'past_due', 'canceled'])).all()
            
            for sub in stripe_subs:
                # Skip canceled subscriptions that have already ended
                if sub.status == 'canceled' and sub.current_period_end:
                    if sub.current_period_end < datetime.now(timezone.utc):
                        continue
                        
                journalist = sub.journalist
                
                # Get journalist's assigned teams for context
                assigned_teams = []
                if journalist:
                    for assignment in journalist.assigned_teams:
                        if assignment.team:
                            assigned_teams.append({
                                'id': assignment.team.id,
                                'name': assignment.team.name,
                                'logo': assignment.team.logo,
                            })
                
                paid_subscriptions.append({
                    'id': sub.id,
                    'type': 'paid',
                    'journalist_id': sub.journalist_user_id,
                    'journalist_name': journalist.display_name if journalist else None,
                    'journalist_email': journalist.email if journalist else None,
                    'journalist_profile_image': journalist.profile_image_url if journalist else None,
                    'assigned_teams': assigned_teams,
                    'status': sub.status,
                    'current_period_end': sub.current_period_end.isoformat() if sub.current_period_end else None,
                    'cancel_at_period_end': sub.cancel_at_period_end,
                    'created_at': sub.created_at.isoformat() if sub.created_at else None,
                })
        
        # Get FREE journalist follows (JournalistSubscription)
        journalist_follows = []
        if user:
            follows = JournalistSubscription.query.filter_by(
                subscriber_user_id=user.id,
                is_active=True
            ).all()
            
            for follow in follows:
                journalist = UserAccount.query.get(follow.journalist_user_id)
                
                # Get journalist's assigned teams for context
                assigned_teams = []
                if journalist:
                    for assignment in getattr(journalist, 'assigned_teams', []) or []:
                        if assignment.team:
                            assigned_teams.append({
                                'id': assignment.team.id,
                                'name': assignment.team.name,
                                'logo': assignment.team.logo,
                            })
                
                journalist_follows.append({
                    'id': follow.id,
                    'journalist_id': follow.journalist_user_id,
                    'journalist_name': journalist.display_name if journalist else None,
                    'journalist_email': journalist.email if journalist else None,
                    'journalist_profile_image': journalist.profile_image_url if journalist else None,
                    'assigned_teams': assigned_teams,
                    'created_at': follow.created_at.isoformat() if follow.created_at else None,
                })
        
        # Calculate estimated emails per week
        # Assume each team/journalist sends ~1 newsletter per week
        individual_count = len(free_subscriptions) + len(journalist_follows)
        
        return jsonify({
            'free_subscriptions': free_subscriptions,
            'paid_subscriptions': paid_subscriptions,
            'journalist_follows': journalist_follows,
            'total_count': individual_count,
            'estimated_emails_per_week': {
                'individual': individual_count,
                'digest': 1 if individual_count > 0 else 0,
            },
            'email_delivery_preference': (user.email_delivery_preference if user else 'individual') or 'individual',
        })
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500


def _user_rate_limit_key() -> str | None:
    return getattr(g, 'user_email', None) or (request.remote_addr or 'anon')

# Auth endpoints moved to src/routes/auth_routes.py:
# - /auth/display-name, /auth/verify-code, /auth/status

# In api.py
@api_bp.route('/newsletters/generate-weekly-all', methods=['POST'])
@require_api_key
def generate_weekly_all():
    try:
        data = request.get_json() or {}
        target_date_str = data.get('target_date')  # YYYY-MM-DD
        from datetime import datetime
        if target_date_str:
            target_dt = datetime.strptime(target_date_str, "%Y-%m-%d").date()
        else:
            target_dt = datetime.now(timezone.utc).date()
        from src.jobs.run_weekly_newsletters import run_for_date
        result = run_for_date(target_dt)
        # Append to run history for admin UI visibility
        try:
            ok = len([r for r in (result or []) if r.get("newsletter_id")])
            errs = len([r for r in (result or []) if r.get("error")])
            _append_run_history({
                "kind": "newsletter-run",
                "ran_for": target_dt.isoformat(),
                "ok": ok,
                "errors": errs,
                "message": f"Weekly newsletters run for {target_dt.isoformat()} ({ok} ok, {errs} errors)"
            })
        except Exception:
            pass
        return jsonify({"ran_for": target_dt.isoformat(), "results": result})
    except Exception as e:
        logger.exception("generate-weekly-all failed")
        return jsonify({"error": str(e)}), 500

@api_bp.route('/newsletters/generate-weekly-all-mcp', methods=['POST'])
@require_api_key
def generate_weekly_all_mcp():
    try:
        payload = request.get_json() or {}
        target_date = payload.get('target_date')
        from datetime import datetime, date as d
        tdate = datetime.strptime(target_date, "%Y-%m-%d").date() if target_date else d.today()

        from src.jobs.run_weekly_newsletters_mcp import run_for_date
        result = run_for_date(tdate)
        # Append to run history
        try:
            ok = len([r for r in (result or []) if r.get("status") == "ok"])  # mcp variant shape
            errs = len([r for r in (result or []) if r.get("status") == "error"]) 
            _append_run_history({
                "kind": "newsletter-run-mcp",
                "ran_for": tdate.isoformat(),
                "ok": ok,
                "errors": errs,
                "message": f"Weekly newsletters (MCP) for {tdate.isoformat()} ({ok} ok, {errs} errors)"
            })
        except Exception:
            pass
        return jsonify({"ran_for": tdate.isoformat(), "results": result})
    except Exception as e:
        logger.exception("generate-weekly-all-mcp failed")
        return jsonify({"error": str(e)}), 500
    
def _sync_season(window_key: str | None = None, season: int | None = None):
    """Set api_client season and prime cache. Returns the start-year int."""
    if window_key:
        season_start = int(window_key.split("::")[0].split("-")[0])
        api_client.set_season_from_window_key(window_key)
    elif season is not None:
        season_start = season
        api_client.set_season_year(season_start)
    else:
        raise ValueError("Either window_key or season required")
    api_client._prime_team_cache(season_start)
    return season_start

# ALLOWED_ADMIN_IPS and get_client_ip are imported from src.auth

# League endpoints
@api_bp.route('/leagues', methods=['GET'])
def get_leagues():
    """Get all European leagues."""
    try:
        leagues = League.query.filter_by(is_european_top_league=True).all()
        return jsonify([league.to_dict() for league in leagues])
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

# Gameweek endpoints
@api_bp.route('/gameweeks', methods=['GET'])
def get_gameweeks():
    """Get available gameweeks for the season."""
    try:
        season = request.args.get('season', type=int)
        from src.utils.gameweeks import get_season_gameweeks
        weeks = get_season_gameweeks(season_start_year=season)
        return jsonify(weeks)
    except Exception as e:
        logger.error(f"Error getting gameweeks: {e}")
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

# Team endpoints
@api_bp.route('/teams', methods=['GET'])
def get_teams():
    """Get all teams with optional filtering."""
    try:
        logger.info("üèüÔ∏è GET /teams endpoint called")
        logger.info(f"üìã Request args: {dict(request.args)}")
        
        # Check database connection and teams table
        total_teams = Team.query.count()
        logger.info(f"üìä Total teams in database: {total_teams}")
        
        # Start with base query for active teams
        query = Team.query.filter_by(is_active=True)
        
        # Handle season filter
        season = request.args.get('season', type=int)
        if season:
            logger.info(f"üèÜ Filtering for season: {season}")
            query = query.filter_by(season=season)
        
        # Handle european_only filter
        european_only = request.args.get('european_only', '').lower() == 'true'
        if european_only:
            logger.info("üåç Filtering for European teams only")
            # European leagues: Premier League, La Liga, Serie A, Bundesliga, Ligue 1
            european_leagues = ['Premier League', 'La Liga', 'Serie A', 'Bundesliga', 'Ligue 1']
            query = query.join(League).filter(League.name.in_(european_leagues))
        
        # Handle has_loans filter
        has_loans = request.args.get('has_loans', '').lower() == 'true'
        if has_loans:
            logger.info("‚öΩ Filtering for teams with active loans")
            # Join with LoanedPlayer and filter for teams that have active loans
            query = query.join(LoanedPlayer, Team.id == LoanedPlayer.primary_team_id)\
                        .filter(LoanedPlayer.is_active == True)\
                        .distinct()

        # Handle search filter (for global search)
        search = request.args.get('search', '').strip()
        if search:
            logger.info(f"üîç Searching teams for: {search}")
            query = query.filter(Team.name.ilike(f'%{search}%'))

        teams = query.all()
        active_teams_count = len(teams)
        logger.info(f"‚úÖ Filtered teams found: {active_teams_count}")
        
        # Deduplicate teams by team_id, keeping the latest season
        # This is necessary because we store teams per season
        deduped_teams = {}
        for team in teams:
            existing = deduped_teams.get(team.team_id)
            if not existing or team.season > existing.season:
                deduped_teams[team.team_id] = team
        
        teams = list(deduped_teams.values())
        # Sort by name for consistent display
        teams.sort(key=lambda x: x.name)
        
        if active_teams_count == 0:
            logger.warning("‚ö†Ô∏è No teams found matching the filters")
            # If user asked for European-only teams and none are in DB, lazily sync minimal data for current season
            if european_only:
                try:
                    season = season or api_client.current_season_start_year
                    logger.info(f"üîÅ Attempting lazy sync for European top leagues for season {season}")
                    # Sync leagues (top-5)
                    leagues_data = api_client.get_european_leagues(season)
                    for league_data in leagues_data:
                        league_info = league_data.get('league', {})
                        country_info = league_data.get('country', {})
                        seasons = league_data.get('seasons', [])
                        current_season = next((s for s in seasons if s.get('current')), seasons[0] if seasons else {})
                        existing = League.query.filter_by(league_id=league_info.get('id')).first()
                        if existing:
                            existing.name = league_info.get('name')
                            existing.country = country_info.get('name')
                            existing.season = current_season.get('year', api_client.current_season_start_year)
                            existing.logo = league_info.get('logo')
                            existing.is_european_top_league = True
                        else:
                            db.session.add(League(
                                league_id=league_info.get('id'),
                                name=league_info.get('name'),
                                country=country_info.get('name'),
                                season=current_season.get('year', api_client.current_season_start_year),
                                is_european_top_league=True,
                                logo=league_info.get('logo')
                            ))
                    # Sync teams for those leagues
                    all_teams = api_client.get_all_european_teams(season)
                    for team_data in all_teams:
                        team_info = team_data.get('team', {})
                        league_info = team_data.get('league_info', {})
                        league = League.query.filter_by(league_id=league_info.get('id')).first()
                        if not league:
                            continue
                        existing_team = Team.query.filter_by(team_id=team_info.get('id'), season=season).first()
                        if existing_team:
                            existing_team.name = team_info.get('name')
                            existing_team.country = team_info.get('country')
                            existing_team.founded = team_info.get('founded')
                            existing_team.logo = team_info.get('logo')
                            existing_team.league_id = league.id
                            existing_team.is_active = True
                        else:
                            db.session.add(Team(
                                team_id=team_info.get('id'),
                                name=team_info.get('name'),
                                country=team_info.get('country'),
                                founded=team_info.get('founded'),
                                logo=team_info.get('logo'),
                                league_id=league.id,
                                season=season,
                                is_active=True
                            ))
                    db.session.commit()
                    logger.info("‚úÖ Lazy sync complete, refetching teams")
                    # Re-run the filtered query
                    query = Team.query.filter_by(is_active=True)
                    if season:
                        query = query.filter_by(season=season)
                    if european_only:
                        european_leagues = ['Premier League', 'La Liga', 'Serie A', 'Bundesliga', 'Ligue 1']
                        query = query.join(League).filter(League.name.in_(european_leagues))
                    teams = query.all()
                    active_teams_count = len(teams)
                except Exception as sync_ex:
                    logger.error(f"Lazy sync failed: {sync_ex}")
            
        team_dicts = [team.to_dict() for team in teams]
        logger.info(f"üì§ Returning {len(team_dicts)} team records")
        
        return jsonify(team_dicts)
    except Exception as e:
        logger.error(f"‚ùå Error in get_teams: {str(e)}")
        logger.error(f"‚ùå Exception type: {type(e).__name__}")
        import traceback
        logger.error(f"‚ùå Traceback: {traceback.format_exc()}")
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/teams/<int:team_id>', methods=['GET'])
def get_team(team_id):
    """Get specific team with loan details."""
    try:
        team = Team.query.get_or_404(team_id)
        team_dict = team.to_dict()
        
        # Add detailed loan information with duplicates removed
        active_loans = team.unique_active_loans()

        team_dict['active_loans'] = [loan.to_dict() for loan in active_loans]
        
        return jsonify(team_dict)
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/teams/<int:team_id>/loans', methods=['GET'])
def get_team_loans(team_id):
    """Get loans for a specific team.
    
    Query params:
    - direction: 'loaned_from' (default) to show players loaned OUT from this team,
                 'loaned_to' to show players loaned TO this team
    - active_only: filter to only active loans (default: true)
    - dedupe: deduplicate loans by player_id (default: true)
    - season: filter by season year
    """
    try:
        # Import helper functions for player photos and team logos
        from src.agents.weekly_agent import _player_photo_for, _team_logo_for_team  # type: ignore
        
        team = Team.query.get_or_404(team_id)
        active_only = request.args.get('active_only', 'true').lower() in ('1', 'true', 'yes', 'on', 'y')
        dedupe = request.args.get('dedupe', 'true').lower() in ('1', 'true', 'yes', 'on', 'y')
        season_val = request.args.get('season', type=int)
        direction = request.args.get('direction', 'loaned_from').lower()

        # Filter by direction: loaned_from = parent club, loaned_to = loan destination
        if direction == 'loaned_to':
            query = LoanedPlayer.query.filter_by(loan_team_id=team.id)
        else:
            query = LoanedPlayer.query.filter_by(primary_team_id=team.id)
        if active_only:
            query = query.filter(LoanedPlayer.is_active.is_(True))
        if season_val:
            slug = f"{season_val}-{str(season_val + 1)[-2:]}"
            query = query.filter(LoanedPlayer.window_key.like(f"{slug}%"))

        loans = query.order_by(LoanedPlayer.updated_at.desc()).all()
        if dedupe:
            loans = _dedupe_loans(loans)

        # Optionally enrich with season context stats (like newsletter does)
        include_season_context = request.args.get('include_season_context', 'false').lower() in ('1', 'true', 'yes', 'on', 'y')
        
        result = []
        for loan in loans:
            loan_dict = loan.to_dict()
            
            # Add player photo and position from Player table
            if loan_dict.get('player_id'):
                try:
                    loan_dict['player_photo'] = _player_photo_for(loan_dict['player_id'])
                except Exception:
                    loan_dict['player_photo'] = None
                
                # Get player position from Player table
                try:
                    player = Player.query.filter_by(player_id=loan_dict['player_id']).first()
                    if player:
                        loan_dict['position'] = player.position  # e.g., 'G', 'D', 'M', 'F'
                    else:
                        loan_dict['position'] = None
                except Exception:
                    loan_dict['position'] = None
            else:
                loan_dict['player_photo'] = None
                loan_dict['position'] = None
            
            # Add loan team logo if loan_team_api_id is available
            if loan_dict.get('loan_team_api_id'):
                try:
                    loan_dict['loan_team_logo'] = _team_logo_for_team(loan_dict['loan_team_api_id'])
                except Exception:
                    loan_dict['loan_team_logo'] = None
            else:
                loan_dict['loan_team_logo'] = None
            
            # Optionally enrich with cumulative season stats (like newsletter generation)
            if include_season_context and loan_dict.get('player_id') and loan_dict.get('loan_team_api_id'):
                try:
                    from src.api_football_client import APIFootballClient
                    from src.models.weekly import FixturePlayerStats
                    api_client = APIFootballClient()
                    
                    # Determine season from window_key or use current season
                    season_year = season_val
                    if not season_year and loan.window_key:
                        # Extract season from window_key (e.g., "2024-25::FULL" -> 2024)
                        try:
                            season_str = loan.window_key.split('-')[0]
                            season_year = int(season_str)
                        except (ValueError, IndexError):
                            # Fallback to current season
                            now = datetime.now(timezone.utc)
                            season_year = now.year if now.month >= 8 else now.year - 1
                    
                    if not season_year:
                        now = datetime.now(timezone.utc)
                        season_year = now.year if now.month >= 8 else now.year - 1
                    
                    # üîÑ VERIFY player ID before fetching stats for Browse Teams
                    # This ensures we show correct stats even if player was seeded with wrong ID
                    player_id_to_use = loan_dict['player_id']
                    verified_id, method = api_client.verify_player_id_via_fixtures(
                        candidate_player_id=loan_dict['player_id'],
                        player_name=loan.player_name,
                        loan_team_id=loan_dict['loan_team_api_id'],
                        season=season_year,
                        max_fixtures=3
                    )
                    if verified_id != loan_dict['player_id']:
                        logger.warning(
                            f"üîÑ Browse Teams ID correction for '{loan.player_name}': "
                            f"{loan_dict['player_id']} ‚Üí {verified_id}"
                        )
                        player_id_to_use = verified_id
                        # Update the database record
                        loan.player_id = verified_id
                        loan.reviewer_notes = (loan.reviewer_notes or '') + f' | ID auto-corrected in browse: {loan_dict["player_id"]} ‚Üí {verified_id}'
                        loan.updated_at = datetime.now(timezone.utc)
                        db.session.commit()
                        # Delete ghost stats
                        ghost_deleted = FixturePlayerStats.query.filter(
                            FixturePlayerStats.player_api_id == loan_dict['player_id'],
                            FixturePlayerStats.team_api_id == loan_dict['loan_team_api_id'],
                            FixturePlayerStats.minutes == 0
                        ).delete()
                        if ghost_deleted:
                            db.session.commit()
                        # Update loan_dict to reflect new ID
                        loan_dict['player_id'] = verified_id
                    
                    # Get season context with verified ID
                    season_context = api_client.get_player_season_context(
                        player_id=player_id_to_use,
                        loan_team_id=loan_dict['loan_team_api_id'],
                        season=season_year,
                        up_to_date=datetime.now(timezone.utc).date(),
                        db_session=db.session
                    )
                    
                    # Use cumulative season stats if available and more complete
                    season_stats = season_context.get('season_stats', {})
                    if season_stats:
                        # Prefer season context stats for appearances (games_played)
                        if season_stats.get('games_played', 0) > 0:
                            loan_dict['appearances'] = season_stats.get('games_played', loan_dict.get('appearances', 0))
                        # Prefer season context stats for goals/assists if they're higher (more complete)
                        if season_stats.get('goals', 0) > (loan_dict.get('goals') or 0):
                            loan_dict['goals'] = season_stats.get('goals', loan_dict.get('goals', 0))
                        if season_stats.get('assists', 0) > (loan_dict.get('assists') or 0):
                            loan_dict['assists'] = season_stats.get('assists', loan_dict.get('assists', 0))
                        if season_stats.get('minutes', 0) > (loan_dict.get('minutes_played') or 0):
                            loan_dict['minutes_played'] = season_stats.get('minutes', loan_dict.get('minutes_played', 0))
                        
                        # Include position-specific stats for the Browse page display
                        # Defender/Midfielder stats
                        if season_stats.get('tackles_total') is not None:
                            loan_dict['tackles'] = season_stats.get('tackles_total')
                        if season_stats.get('interceptions') is not None:
                            loan_dict['interceptions'] = season_stats.get('interceptions')
                        if season_stats.get('duels_won') is not None:
                            loan_dict['duels_won'] = season_stats.get('duels_won')
                        if season_stats.get('duels_total') is not None:
                            loan_dict['duels_total'] = season_stats.get('duels_total')
                        if season_stats.get('passes_key') is not None:
                            loan_dict['key_passes'] = season_stats.get('passes_key')
                        
                        # Goalkeeper stats
                        if season_stats.get('saves') is not None:
                            loan_dict['saves'] = season_stats.get('saves')
                        if season_stats.get('goals_conceded') is not None:
                            loan_dict['goals_conceded'] = season_stats.get('goals_conceded')
                        
                        # Clean sheets (calculate from games where goals_conceded is 0)
                        if season_stats.get('clean_sheets') is not None:
                            loan_dict['clean_sheets'] = season_stats.get('clean_sheets')
                except Exception as e:
                    # If season context fails, use stored stats (fallback)
                    logger.debug(f"Failed to enrich loan {loan.id} with season context: {e}")
                    pass
            
            result.append(loan_dict)

        include_supp = request.args.get('include_supplemental', 'false').lower() in ('1', 'true', 'yes', 'on')
        if include_supp:
            supp_query = SupplementalLoan.query.filter_by(parent_team_id=team.id)
            if season_val:
                supp_query = supp_query.filter_by(season_year=season_val)
            supp_rows = supp_query.all()
            for s in supp_rows:
                try:
                    item = {
                        'player_name': s.player_name,
                        'primary_team_name': s.parent_team_name,
                        'primary_team_api_id': getattr(s.parent_team, 'team_id', None),
                        'loan_team_id': s.loan_team_id,
                        'loan_team_name': s.loan_team_name,
                        'loan_team_api_id': getattr(s.loan_team, 'team_id', None),
                        'window_key': f"{s.season_year}-{str(s.season_year + 1)[-2:]}" if s.season_year else None,
                        'is_active': True,
                        'appearances': None,
                        'goals': None,
                        'assists': None,
                        'minutes_played': None,
                        'yellows': None,
                        'reds': None,
                        'data_source': s.data_source or 'supplemental',
                        'can_fetch_stats': False,
                        'created_at': s.created_at.isoformat() if s.created_at else None,
                        'updated_at': s.updated_at.isoformat() if s.updated_at else None,
                        'season_year': s.season_year,
                        'id': f"supp-{s.id}",
                        'player_id': s.api_player_id,
                    }
                    # Add player photo for supplemental loans if available
                    if item.get('player_id'):
                        try:
                            item['player_photo'] = _player_photo_for(item['player_id'])
                        except Exception:
                            item['player_photo'] = None
                    else:
                        item['player_photo'] = None
                    
                    # Add loan team logo for supplemental loans if available
                    if item.get('loan_team_api_id'):
                        try:
                            item['loan_team_logo'] = _team_logo_for_team(item['loan_team_api_id'])
                        except Exception:
                            item['loan_team_logo'] = None
                    else:
                        item['loan_team_logo'] = None
                    
                    result.append(item)
                except Exception:
                    continue
        return jsonify(result)
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/teams/<int:team_id>/loans/season/<int:season>', methods=['GET'])
def get_team_loans_by_season(team_id: int, season: int):
    """Get loans for a specific team in a specific season (by window_key prefix)."""
    try:
        team = Team.query.get_or_404(team_id)
        slug = f"{season}-{str(season + 1)[-2:]}"
        active_only = (request.args.get('active_only', 'false').lower() in ('true', '1', 'yes', 'y'))
        q = (
            LoanedPlayer.query
            .filter(LoanedPlayer.primary_team_id == team.id)
            .filter(LoanedPlayer.window_key.like(f"{slug}%"))
        )
        if active_only:
            q = q.filter(LoanedPlayer.is_active.is_(True))
        loans = q.order_by(LoanedPlayer.updated_at.desc()).all()
        return jsonify([loan.to_dict() for loan in loans])
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/teams/season/<int:season>', methods=['GET'])
def get_teams_for_season(season):
    """Get all teams for a specific season with their names."""
    try:
        team_mapping = api_client.get_teams_for_season(season)
        return jsonify({
            'season': season,
            'teams': team_mapping,
            'count': len(team_mapping)
        })
    except Exception as e:
        logger.error(f"Error fetching teams for season {season}: {e}")
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/teams/<int:team_id>/api-info', methods=['GET'])
def get_team_api_info(team_id):
    """Get team information from API-Football by ID."""
    try:
        season = request.args.get('season', api_client.current_season_start_year)
        team_data = api_client.get_team_by_id(team_id)
        
        if not team_data:
            return jsonify({'error': f'Team {team_id} not found'}), 404
            
        return jsonify({
            'team_id': team_id,
            'season': season,
            'data': team_data
        })
    except Exception as e:
        logger.error(f"Error fetching team {team_id} from API: {e}")
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

def resolve_team_ids(id_or_api_id: int, season: int = None) -> tuple[int | None, int | None, str | None]:
    """
    Return (db_id, api_id, name) for a team, accepting either a DB PK or an
    API-Football team_id.  We prefer an API-id match first, then DB PK.
    If season is provided, it will be used to filter the team lookup.
    """
    # 1 ‚Äì exact API-id match (with season if provided)
    if season:
        row = Team.query.filter_by(team_id=id_or_api_id, season=season).first()
    else:
        row = Team.query.filter_by(team_id=id_or_api_id).first()
    if row:
        return row.id, row.team_id, row.name

    # 2 ‚Äì fallback: treat as DB primary-key
    row = Team.query.get(id_or_api_id)
    if row:
        return row.id, row.team_id, row.name

    # 3 ‚Äì not found
    return None, None, None


def resolve_team_name_and_logo(team_api_id: int, season: int = None) -> tuple[str, str | None]:
    """
    Resolve team name and logo from multiple sources with fallback chain.
    
    Returns (team_name, team_logo) tuple. Always returns a non-empty team_name.
    
    Fallback order:
    1. Team table (any season, prefer current)
    2. TeamProfile table (stores canonical team info)
    3. API Football client (fetch from API) - also caches to TeamProfile
    4. Final fallback: "Team {id}"
    """
    from src.models.league import Team, TeamProfile
    
    if not team_api_id:
        return "Unknown", None
    
    # 1. Try Team table - first with season if provided, then any season
    if season:
        team = Team.query.filter_by(team_id=team_api_id, season=season).first()
    else:
        team = Team.query.filter_by(team_id=team_api_id).first()
    
    if team and team.name:
        return team.name, team.logo
    
    # 2. Try TeamProfile table (stores canonical team info without season)
    try:
        profile = TeamProfile.query.filter_by(team_id=team_api_id).first()
        if profile and profile.name:
            return profile.name, profile.logo_url
    except Exception:
        pass  # Table might not exist in some environments
    
    # 3. Try API Football client as last resort
    try:
        team_name = api_client.get_team_name(team_api_id, season)
        if team_name and team_name != f"Team {team_api_id}":
            # Also get team info for logo
            team_info = api_client._team_profile_cache.get(team_api_id) or {}
            team_logo = team_info.get('team', {}).get('logo')
            
            # Cache to TeamProfile for future lookups (avoids repeated API calls)
            try:
                existing_profile = TeamProfile.query.filter_by(team_id=team_api_id).first()
                if not existing_profile:
                    team_data = team_info.get('team', {})
                    venue_data = team_info.get('venue', {})
                    new_profile = TeamProfile(
                        team_id=team_api_id,
                        name=team_name,
                        code=team_data.get('code'),
                        country=team_data.get('country'),
                        founded=team_data.get('founded'),
                        is_national=team_data.get('national'),
                        logo_url=team_logo,
                        venue_id=venue_data.get('id'),
                        venue_name=venue_data.get('name'),
                        venue_address=venue_data.get('address'),
                        venue_city=venue_data.get('city'),
                        venue_capacity=venue_data.get('capacity'),
                        venue_surface=venue_data.get('surface'),
                        venue_image=venue_data.get('image'),
                    )
                    db.session.add(new_profile)
                    db.session.commit()
                    logger.info(f"Cached team profile for {team_name} (id={team_api_id})")
            except Exception as cache_err:
                # Don't fail the lookup if caching fails
                logger.warning(f"Failed to cache team profile for {team_api_id}: {cache_err}")
                try:
                    db.session.rollback()
                except Exception:
                    pass
            
            return team_name, team_logo
    except Exception as e:
        logger.warning(f"Failed to resolve team name from API for team_id={team_api_id}: {e}")
    
    # 4. Final fallback
    return f"Team {team_api_id}", None


# Loan endpoints
@api_bp.route('/loans', methods=['GET'])
def get_loans():
    """Get all loans with optional filters."""
    try:
        query = LoanedPlayer.query
        
        # Filter by season (derive from window_key prefix)
        season_val = request.args.get('season', type=int)
        if season_val:
            slug = f"{season_val}-{str(season_val + 1)[-2:]}"
            query = query.filter(LoanedPlayer.window_key.like(f"{slug}%"))
        
        # Filter by active status
        active_only = request.args.get('active_only', 'false').lower() == 'true'
        if active_only:
            query = query.filter_by(is_active=True)
        
        # Filter by loan type
        loan_type = request.args.get('loan_type')
        if loan_type:
            query = query.filter_by(loan_type=loan_type)
        
        # Filter by early termination
        early_termination = request.args.get('early_termination')
        if early_termination is not None:
            query = query.filter_by(early_termination=early_termination.lower() == 'true')
        
        loans = query.order_by(LoanedPlayer.updated_at.desc()).all()
        result = [loan.to_dict() for loan in loans]

        include_supp = request.args.get('include_supplemental', 'false').lower() in ('1','true','yes','on')
        if include_supp:
            supp_q = SupplementalLoan.query
            # Align season filter if present
            if season_val:
                supp_q = supp_q.filter(SupplementalLoan.season_year == season_val)
            supp_rows = supp_q.order_by(SupplementalLoan.updated_at.desc()).all()
            for s in supp_rows:
                try:
                    item = {
                        'player_name': s.player_name,
                        'primary_team_name': s.parent_team_name,
                        'primary_team_api_id': getattr(s.parent_team, 'team_id', None),
                        'loan_team_id': s.loan_team_id,
                        'loan_team_name': s.loan_team_name,
                        'loan_team_api_id': getattr(s.loan_team, 'team_id', None),
                        'window_key': f"{s.season_year}-{str(s.season_year + 1)[-2:]}",
                        'is_active': True,
                        'appearances': None,
                        'goals': None,
                        'assists': None,
                        'minutes_played': None,
                        'yellows': None,
                        'reds': None,
                        'data_source': s.data_source or 'supplemental',
                        'can_fetch_stats': False,
                        'created_at': s.created_at.isoformat() if s.created_at else None,
                        'updated_at': s.updated_at.isoformat() if s.updated_at else None,
                        'season_year': s.season_year,
                        'source': 'supplemental',
                    }
                    result.append(item)
                except Exception:
                    continue
        return jsonify(result)
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/loans/active', methods=['GET'])
def get_active_loans():
    """Get active loans."""
    try:
        loans = LoanedPlayer.query.filter_by(is_active=True).all()
        return jsonify([loan.to_dict() for loan in loans])
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/loans/season/<int:season>', methods=['GET'])
def get_loans_by_season(season: int):
    """Get all loans for a specific season (by window_key prefix)."""
    try:
        slug = f"{season}-{str(season + 1)[-2:]}"
        loans = LoanedPlayer.query.filter(LoanedPlayer.window_key.like(f"{slug}%")).all()
        return jsonify([loan.to_dict() for loan in loans])
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

# ---------------------------------------------------------------------
# Weekly Loans Report Endpoint
# ---------------------------------------------------------------------
@api_bp.route('/loans/weekly-report', methods=['GET'])
@require_api_key
def weekly_loans_report():
    """
    Weekly report summarising all active loanees from a parent club.
    Query parameters:
              - primary_team_id (int)  [required]
      - season (int)          [optional, default current]
      - from (YYYY-MM-DD)     [required] week start
      - to   (YYYY-MM-DD)     [required] week end
      - include_team_stats    [optional bool] include team statistics per match
    """
    try:
        # Accept either a DB PK or an API-Football team_id for primary_team_id
        arg_team_id = request.args.get('primary_team_id', type=int)
        if not arg_team_id:
            return jsonify({'error': 'primary_team_id is required'}), 400

        season_param = request.args.get('season', type=int)
        start_str = request.args.get('from')
        end_str = request.args.get('to')
        if not start_str or not end_str:
            return jsonify({'error': "'from' and 'to' query params are required (YYYY-MM-DD)"}), 400

        try:
            week_start = datetime.strptime(start_str, '%Y-%m-%d').date()
            week_end = datetime.strptime(end_str, '%Y-%m-%d').date()
        except ValueError:
            return jsonify({'error': "Invalid 'from' or 'to' date. Use YYYY-MM-DD"}), 400

        # Infer season from 'from' date if not provided explicitly (European season starts Aug 1)
        if season_param is None:
            season = week_start.year if week_start.month >= 8 else week_start.year - 1
        else:
            season = season_param

        db_id, api_id, team_name = resolve_team_ids(arg_team_id, season)
        if not db_id:
            return jsonify({'error': f'Team {arg_team_id} not found for season {season}'}), 404

        include_team_stats = request.args.get('include_team_stats', 'false').lower() in ('true', '1', 'yes', 'y')

        # Sync season with API client & prime cache
        api_client.set_season_year(season)
        api_client._prime_team_cache(season)

        report = api_client.summarize_parent_loans_week(
            parent_team_db_id=db_id,
            parent_team_api_id=api_id,
            season=season,
            week_start=week_start,
            week_end=week_end,
            include_team_stats=include_team_stats,
            db_session=db.session,
        )

        # Overwrite parent_team for consistent shape
        report['parent_team'] = {
            'id': api_id,     # API id for clients
            'db_id': db_id,   # DB PK
            'name': team_name
        }

        # Persist fixtures / stats fetched above
        db.session.commit()

        return jsonify(report)
    except Exception as e:
        logger.error(f"Error generating weekly loans report: {e}")
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/loans/<int:loan_id>/terminate', methods=['POST'])
@require_api_key
def terminate_loan(loan_id):
    """Terminate a loan early."""
    try:
        loan = LoanedPlayer.query.get_or_404(loan_id)
        data = request.get_json()
        
        termination_reason = data.get('reason', 'Not specified')
        termination_date = data.get('termination_date')
        
        if termination_date:
            try:
                termination_date = datetime.strptime(termination_date, '%Y-%m-%d').date()
            except ValueError:
                return jsonify({'error': 'Invalid date format. Use YYYY-MM-DD'}), 400
        else:
            termination_date = datetime.now(timezone.utc).date()
        
        # Update loan record
        loan.early_termination = True
        loan.termination_reason = termination_reason
        loan.termination_date = termination_date
        loan.actual_end_date = termination_date
        loan.is_active = False
        loan.updated_at = datetime.now(timezone.utc)
        
        db.session.commit()
        
        return jsonify({
            'message': 'Loan terminated successfully',
            'loan': loan.to_dict()
        })
        
    except Exception as e:
        logger.error(f"Error terminating loan: {e}")
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/loans/<int:loan_id>/performance', methods=['PUT'])
@require_api_key
def update_loan_performance(loan_id):
    """Update performance stats for a loan."""
    try:
        loan = LoanedPlayer.query.get_or_404(loan_id)
        data = request.get_json()
        
        # Update performance fields
        if 'appearances' in data:
            loan.appearances = data['appearances']
        if 'goals' in data:
            loan.goals = data['goals']
        if 'assists' in data:
            loan.assists = data['assists']
        if 'minutes_played' in data:
            loan.minutes_played = data['minutes_played']
        if 'performance_notes' in data:
            loan.performance_notes = data['performance_notes']
        
        loan.last_performance_update = datetime.now(timezone.utc)
        loan.updated_at = datetime.now(timezone.utc)
        
        db.session.commit()
        
        return jsonify({
            'message': 'Performance updated successfully',
            'loan': loan.to_dict()
        })
        
    except Exception as e:
        logger.error(f"Error updating performance: {e}")
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route("/reviewed-loan-candidates/upload", methods=["POST"])
@require_api_key
def upload_reviewed_loan_candidates():
    try:
        if "file" not in request.files:
            return {"error": "CSV file required"}, 400
        file = request.files["file"]
        if not file.filename.lower().endswith(".csv"):
            return {"error": "Must be a CSV"}, 400

        dry_run = request.args.get("dry_run", "false").lower() in ("true", "1", "yes", "y")

        # --- read and tidy CSV text ---
        raw = file.read().decode("utf-8", errors="ignore")
        raw = raw.replace("\r\n", "\n").replace("\r", "\n")

        # Auto‚Äëdetect delimiter (tab vs comma)
        first_line = raw.split("\n", 1)[0]
        delimiter = "\t" if first_line.count("\t") > first_line.count(",") else ","

        # If header starts with an empty first cell (leading delimiter), strip it
        if first_line.startswith(delimiter):
            raw_lines = raw.split("\n")
            raw_lines[0] = raw_lines[0].lstrip(delimiter)
            raw = "\n".join(raw_lines)

        rows = csv.DictReader(io.StringIO(raw), delimiter=delimiter, skipinitialspace=True)
        rows.fieldnames = [f.strip() for f in (rows.fieldnames or [])]
        logger.info(f"Detected delimiter: '{delimiter}' | headers: {rows.fieldnames}")

        required = {"player_id", "loan_team_id", "window_key", "is_likely_loan"}
        has_parent_alias = ("parent_team_id" in rows.fieldnames) or ("primary_team_id" in rows.fieldnames)
        if not required.issubset(set(rows.fieldnames)) or not has_parent_alias:
            return {
                "error": "Missing required columns",
                "required": "player_id, loan_team_id, window_key, is_likely_loan, and one of parent_team_id or primary_team_id"
            }, 400

        def _truthy(v):
            return str(v).strip().lower() in ("true", "1", "yes", "y")

        def _to_int(v):
            try:
                return int(str(v).strip())
            except Exception:
                return None

        def _parse_season_from_window(window_key: str):
            try:
                season_slug, _ = window_key.split("::")
                return int(season_slug.split("-")[0])  # e.g. "2022" from "2022-23::FULL"
            except Exception:
                return None

        def _ensure_team(api_team_id: int, season_start_year: int):
            """
            Ensure a Team row exists for given API team id and season.
            If missing, fetch from API-Football and insert minimal Team.
            Returns Team (DB row) or None if not resolvable.
            """
            if not api_team_id:
                return None
            t = Team.query.filter_by(team_id=api_team_id, season=season_start_year).first()
            if t:
                return t

            # Fetch from API-Football (season helps name resolution)
            tdata = api_client.get_team_by_id(api_team_id, season_start_year)
            if not tdata or "team" not in tdata:
                return None

            ti = tdata["team"] or {}
            team = Team(
                team_id=ti.get("id"),
                name=ti.get("name") or f"Team {api_team_id}",
                code=ti.get("code"),
                country=ti.get("country") or "Unknown",
                founded=ti.get("founded"),
                national=bool(ti.get("national", False)),
                logo=ti.get("logo"),
                season=season_start_year or api_client.current_season_start_year,
                is_active=True,
                league_id=None  # Optional: backfill league later if desired
            )
            db.session.add(team)
            db.session.flush()
            return team

        created, skipped, errors = [], [], []

        # Data starts on line 2 for DictReader; idx here is CSV line number
        for idx, row in enumerate(rows, start=2):
            try:
                # Skip empty/separator rows (club headings, etc.)
                if not any(v and str(v).strip() for v in row.values()):
                    continue

                # Only process rows marked as TRUE
                if not _truthy(row.get("is_likely_loan", "")):
                    skipped.append({"row": idx, "reason": "not marked TRUE"})
                    continue

                # Parse required values
                api_player_id = _to_int(row.get("player_id"))
                api_parent_id = _to_int(row.get("parent_team_id") or row.get("primary_team_id"))
                api_loan_id = _to_int(row.get("loan_team_id"))
                window_key = (row.get("window_key") or "").strip()

                if not (api_player_id and api_parent_id and api_loan_id and window_key):
                    errors.append(f"Row {idx}: missing player_id / primary_team_id / loan_team_id / window_key")
                    continue

                # Optional values from CSV (fallbacks applied below)
                player_name = (row.get("player_name") or "").strip()
                age = _to_int(row.get("age"))
                nationality = (row.get("nationality") or "").strip() or None
                primary_team_name_csv = (row.get("primary_team_name") or "").strip()
                loan_team_name_csv = (row.get("loan_team_name") or "").strip()
                team_ids_str = (row.get("team_ids") or "").strip()
                reviewer_notes = (row.get("reviewer_notes") or "").strip()

                season_start_year = _parse_season_from_window(window_key) or api_client.current_season_start_year

                # Ensure teams exist (create if missing)
                parent_team = _ensure_team(api_parent_id, season_start_year)
                if not parent_team:
                    errors.append(f"Row {idx}: parent team API id {api_parent_id} not found or not resolvable")
                    continue

                loan_team = _ensure_team(api_loan_id, season_start_year)
                if not loan_team:
                    errors.append(f"Row {idx}: loan team API id {api_loan_id} not found or not resolvable")
                    continue

                # Determine final human names
                primary_team_name = primary_team_name_csv or parent_team.name
                loan_team_name = loan_team_name_csv or loan_team.name

                # Duplicate check
                dup = LoanedPlayer.query.filter_by(
                    player_id=api_player_id,
                    primary_team_id=parent_team.id,
                    loan_team_id=loan_team.id,
                    window_key=window_key,
                    is_active=True
                ).first()
                if dup:
                    skipped.append({
                        "row": idx,
                        "reason": "duplicate (same player/teams/window_key active)",
                        "player_id": api_player_id,
                        "primary_team_id": parent_team.id,
                        "loan_team_id": loan_team.id,
                        "window_key": window_key
                    })
                    continue

                # Build record
                loan_data = dict(
                    player_id=api_player_id,  # raw API-Football ID per your current model
                    player_name=player_name or f"Player {api_player_id}",
                    age=age,
                    nationality=nationality,
                    primary_team_id=parent_team.id,
                    primary_team_name=primary_team_name,
                    loan_team_id=loan_team.id,
                    loan_team_name=loan_team_name,
                    team_ids=team_ids_str,
                    window_key=window_key,
                    reviewer_notes=reviewer_notes,
                    is_active=True
                )

                if dry_run:
                    created.append({**loan_data, "dry_run": True})
                else:
                    loan = LoanedPlayer(**loan_data)
                    db.session.add(loan)
                    created.append({
                        "player_id": api_player_id,
                        "primary_team_id": parent_team.id,
                        "loan_team_id": loan_team.id,
                        "window_key": window_key
                    })
            except Exception as ex:
                logger.exception(f"Row {idx} processing error")
                errors.append(f"Row {idx}: {ex}")

        if not dry_run and created:
            db.session.commit()

        return {
            "created_count": len(created),
            "skipped_count": len(skipped),
            "errors_count": len(errors),
            "dry_run": dry_run,
            "created": created[:5],
            "skipped": skipped[:5],
            "errors": errors[:5],
        }, 201 if created and not dry_run else 200

    except Exception as e:
        logger.exception("Unhandled error in reviewed-loan-candidates/upload")
        return {"error": str(e)}, 500

@api_bp.route('/loans/csv-template', methods=['GET'])
def get_csv_template():
    """Download CSV template for bulk loan upload."""
    try:
        # Create CSV template with headers and example data
        output = io.StringIO()
        writer = csv.writer(output)
        
        # Write headers
        headers = [
            'player_id', 'parent_team_id', 'loan_team_id', 'loan_start_date', 'loan_season',
            'loan_end_date', 'loan_type', 'loan_fee', 'buy_option_fee', 'recall_option',
            'appearances', 'goals', 'assists', 'minutes_played', 'performance_notes'
        ]
        writer.writerow(headers)
        
        # Write example rows
        writer.writerow([
            '1001', '33', '532', '2024-08-15', '2024-25',
            '2025-06-30', 'Season Long', '5000000', '25000000', 'true',
            '15', '3', '2', '1200', 'Performing well at Valencia'
        ])
        writer.writerow([
            '1002', '33', '165', '2025-01-15', '2024-25',
            '2025-06-30', 'Half Season', '', '15000000', 'true',
            '8', '1', '4', '650', 'Good impact since joining Dortmund'
        ])
        
        output.seek(0)
        csv_content = output.getvalue()
        output.close()
        
        from flask import Response
        return Response(
            csv_content,
            mimetype='text/csv',
            headers={'Content-Disposition': 'attachment; filename=loan_upload_template.csv'}
        )
        
    except Exception as e:
        logger.error(f"Error generating CSV template: {e}")
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

# Newsletter endpoints
@api_bp.route('/newsletters', methods=['GET'])
def get_newsletters():
    """Get newsletters with filters."""
    try:
        query = Newsletter.query
        
        # Filter by team
        team_id = request.args.get('team')
        if team_id:
            query = query.filter_by(team_id=team_id)

        # Filter by multiple teams (comma-separated list)
        raw_team_ids = request.args.get('team_ids')
        if raw_team_ids:
            try:
                ids = [int(x.strip()) for x in str(raw_team_ids).split(',') if str(x).strip().isdigit()]
                if ids:
                    query = query.filter(Newsletter.team_id.in_(ids))
            except Exception:
                pass
        
        # Filter by newsletter type
        newsletter_type = request.args.get('type')
        if newsletter_type:
            query = query.filter_by(newsletter_type=newsletter_type)

        # Filter by league (by leagues PK)
        league_id = request.args.get('league_id', type=int)
        if league_id:
            query = query.join(Team).filter(Team.league_id == league_id)
        
        # Filter by published status
        published_only = request.args.get('published_only', 'false').lower() == 'true'
        if published_only:
            query = query.filter_by(published=True)
        
        # Filter by date range
        days = request.args.get('days')
        if days:
            try:
                cutoff_date = datetime.now(timezone.utc) - timedelta(days=int(days))
                query = query.filter(Newsletter.generated_date >= cutoff_date)
            except ValueError:
                pass

        # Filter by a specific week range (inclusive)
        # Expect week_start and week_end as YYYY-MM-DD
        week_start_str = request.args.get('week_start')
        week_end_str = request.args.get('week_end')
        if week_start_str and week_end_str:
            try:
                week_start = datetime.strptime(week_start_str, '%Y-%m-%d').date()
                week_end = datetime.strptime(week_end_str, '%Y-%m-%d').date()
                # Match newsletters whose stored week range overlaps the requested week
                query = query.filter(
                    db.and_(
                        Newsletter.week_start_date <= week_end,
                        Newsletter.week_end_date >= week_start,
                    )
                )
            except ValueError:
                pass

        # Handle search filter (for global search)
        search = request.args.get('search', '').strip()
        if search:
            # Search in newsletter title or team name
            # Need to join with Team if not already joined
            query = query.outerjoin(Team, Newsletter.team_id == Team.id).filter(
                db.or_(
                    Newsletter.title.ilike(f'%{search}%'),
                    Team.name.ilike(f'%{search}%')
                )
            )

        # Exclude current week (server-side)
        exclude_current_week = request.args.get('exclude_current_week', 'false').lower() in ('true', '1', 'yes', 'y')
        if exclude_current_week:
            today = datetime.now(timezone.utc).date()
            # Compute Monday..Sunday of current week
            days_since_monday = today.weekday()
            current_week_start = today - timedelta(days=days_since_monday)
            current_week_end = current_week_start + timedelta(days=6)
            # Exclude if generated/published in current week OR stored week overlaps current week
            query = query.filter(
                db.and_(
                    db.or_(
                        Newsletter.published_date == None,
                        db.not_(db.and_(
                            db.func.date(Newsletter.published_date) >= current_week_start,
                            db.func.date(Newsletter.published_date) <= current_week_end,
                        )),
                    ),
                    db.or_(
                        Newsletter.week_start_date == None,
                        Newsletter.week_end_date == None,
                        db.not_(db.and_(
                            Newsletter.week_start_date <= current_week_end,
                            Newsletter.week_end_date >= current_week_start,
                        )),
                    ),
                )
            )
        
        newsletters = query.order_by(Newsletter.generated_date.desc()).all()
        payload: list[dict] = []
        for newsletter in newsletters:
            row = newsletter.to_dict()
            try:
                raw_structured = newsletter.structured_content or newsletter.content or "{}"
                raw_obj = json.loads(raw_structured)
            except Exception:
                raw_obj = None
            if isinstance(raw_obj, dict):
                rendered = raw_obj.get('rendered')
                if isinstance(rendered, dict):
                    row['rendered'] = {
                        key: value if isinstance(value, str) else ''
                        for key, value in rendered.items()
                    }
            try:
                row['enriched_content'] = _load_newsletter_json(newsletter)
            except Exception:
                row['enriched_content'] = None
            payload.append(row)
        return jsonify(payload)
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/subscriptions/me', methods=['GET'])
@require_user_auth
def my_subscriptions():
    """Return active subscriptions for the authenticated user's email."""
    try:
        email = getattr(g, 'user_email', None)
        email_norm = (email or '').strip().lower()
        if not email_norm:
            return jsonify({'error': 'Unauthorized'}), 401
        subs = UserSubscription.query.filter_by(email=email_norm, active=True).all()
        return jsonify([s.to_dict() for s in subs])
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500


@api_bp.route('/subscriptions/me', methods=['POST'])
@require_user_auth
def update_my_subscriptions():
    """Create, reactivate, or deactivate team subscriptions for the signed-in user."""
    try:
        email = getattr(g, 'user_email', None)
        if not email:
            return jsonify({'error': 'Unauthorized'}), 401

        payload = request.get_json() or {}
        team_ids_raw = payload.get('team_ids') or []
        preferred_frequency = (payload.get('preferred_frequency') or 'weekly').strip() or 'weekly'

        parsed_ids: list[int] = []
        rejected_inputs: list[Any] = []
        for raw in team_ids_raw:
            try:
                tid = int(raw)
            except (TypeError, ValueError):
                rejected_inputs.append(raw)
                continue
            parsed_ids.append(tid)

        # Preserve order but drop duplicates
        unique_ids: list[int] = []
        seen: set[int] = set()
        for tid in parsed_ids:
            if tid not in seen:
                seen.add(tid)
                unique_ids.append(tid)

        team_rows = Team.query.filter(Team.id.in_(unique_ids)).all() if unique_ids else []
        valid_ids = {row.id for row in team_rows}
        missing_team_ids = [tid for tid in unique_ids if tid not in valid_ids]

        desired_team_ids = set(valid_ids)
        email_norm = (email or '').strip().lower()
        now = datetime.now(timezone.utc)

        existing_rows = UserSubscription.query.filter_by(email=email_norm).all()
        existing_map = {row.team_id: row for row in existing_rows}

        created_count = 0
        reactivated_count = 0
        updated_pref_count = 0

        for team in team_rows:
            sub = existing_map.get(team.id)
            if sub:
                changed = False
                if not sub.active:
                    sub.active = True
                    changed = True
                    reactivated_count += 1
                if sub.preferred_frequency != preferred_frequency:
                    sub.preferred_frequency = preferred_frequency
                    changed = True
                    updated_pref_count += 1
                if not sub.unsubscribe_token:
                    sub.unsubscribe_token = str(uuid.uuid4())
                    changed = True
                if changed:
                    sub.updated_at = now
            else:
                subscription = UserSubscription(
                    email=email_norm,
                    team_id=team.id,
                    preferred_frequency=preferred_frequency,
                    active=True,
                    unsubscribe_token=str(uuid.uuid4()),
                    created_at=now,
                    updated_at=now,
                )
                db.session.add(subscription)
                created_count += 1

        deactivated_count = 0
        for sub in existing_rows:
            if sub.team_id not in desired_team_ids and sub.active:
                sub.active = False
                sub.updated_at = now
                deactivated_count += 1

        db.session.commit()

        active_subs = UserSubscription.query.filter_by(email=email_norm, active=True).all()
        response = {
            'message': 'Subscriptions updated',
            'created_count': created_count,
            'reactivated_count': reactivated_count,
            'updated_frequency_count': updated_pref_count,
            'deactivated_count': deactivated_count,
            'ignored_team_ids': missing_team_ids + rejected_inputs,
            'subscriptions': [s.to_dict() for s in active_subs],
        }
        return jsonify(response)
    except Exception as e:
        try:
            db.session.rollback()
        except Exception:
            pass
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

        return jsonify(payload)
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/newsletters/<int:newsletter_id>', methods=['GET'])
def get_newsletter(newsletter_id):
    """Get specific newsletter."""
    try:
        newsletter = Newsletter.query.get_or_404(newsletter_id)
        payload = newsletter.to_dict()
        
        # Collect all commentaries
        all_commentaries = [c.to_dict() for c in _collect_commentaries_for_newsletter(newsletter)]
        
        # Check for journalist filter
        journalist_id_param = request.args.get('journalist_id')
        if journalist_id_param:
            try:
                journalist_id = int(journalist_id_param)
                # Filter commentaries
                filtered_commentaries = [c for c in all_commentaries if c.get('author_id') == journalist_id]
                
                # Check subscription status
                is_subscribed = False
                email = _get_authorized_email()
                if email:
                    user = UserAccount.query.filter_by(email=email).first()
                    if user:
                        sub = JournalistSubscription.query.filter_by(
                            subscriber_user_id=user.id,
                            journalist_user_id=journalist_id,
                            is_active=True
                        ).first()
                        if sub:
                            is_subscribed = True
                
                # Apply masking
                for c in filtered_commentaries:
                    if c.get('is_premium') and not is_subscribed:
                        # Mask content
                        raw_content = c.get('content') or ''
                        # Simple strip tags for preview
                        clean_text = re.sub('<[^<]+?>', '', raw_content)
                        preview = clean_text[:200] + '...' if len(clean_text) > 200 else clean_text
                        c['content'] = preview
                        c['is_locked'] = True
                    else:
                        c['is_locked'] = False
                
                payload['commentaries'] = filtered_commentaries
                
            except ValueError:
                # Invalid journalist_id, ignore filter
                payload['commentaries'] = all_commentaries
        else:
            payload['commentaries'] = all_commentaries

        logger.info(f"üì∞ [get_newsletter] Serving newsletter ID: {newsletter_id}")
        
        # Extract embedded rendered variants if present
        try:
            obj = json.loads(payload.get('structured_content') or payload.get('content') or '{}')
            rendered = obj.get('rendered') if isinstance(obj, dict) else None
            if isinstance(rendered, dict):
                payload['rendered'] = {
                    k: (v if isinstance(v, str) else '') for k, v in rendered.items()
                }
                logger.info(f"‚úÖ [get_newsletter] Found rendered variants - web_html: {len(payload['rendered'].get('web_html', ''))} chars")
                
                # Check if web_html has expanded stats
                web_html = payload['rendered'].get('web_html', '')
                if 'Shots' in web_html or 'Saves' in web_html or 'Key Passes' in web_html:
                    logger.info(f"‚úÖ [get_newsletter] Rendered HTML contains expanded stats!")
                else:
                    logger.warning(f"‚ö†Ô∏è  [get_newsletter] Rendered HTML might not contain expanded stats")
            else:
                logger.warning(f"‚ö†Ô∏è  [get_newsletter] No rendered variants found in newsletter content")
                
            # Log sample stats from the JSON
            sections = obj.get('sections', [])
            if sections:
                first_section = sections[0]
                items = first_section.get('items', [])
                if items:
                    first_item = items[0]
                    stats = first_item.get('stats', {})
                    logger.info(f"üìä [get_newsletter] Sample item stats from JSON:")
                    logger.info(f"   Player: {first_item.get('player_name')}")
                    logger.info(f"   Stats keys: {list(stats.keys())}")
                    logger.info(f"   Position: {stats.get('position')}")
                    logger.info(f"   Rating: {stats.get('rating')}")
                    logger.info(f"   Shots: {stats.get('shots_total')}")
                    logger.info(f"   Passes: {stats.get('passes_total')}")
        except Exception as e:
            logger.error(f"‚ùå [get_newsletter] Error extracting rendered variants: {e}")
            pass

        try:
            comments = (
                NewsletterComment.query
                .filter_by(newsletter_id=newsletter_id, is_deleted=False)
                .order_by(NewsletterComment.created_at.asc())
                .all()
            )
            payload['comments'] = [comment.to_dict() for comment in comments]
        except Exception:
            payload['comments'] = []

        try:
            payload['enriched_content'] = _load_newsletter_json(newsletter)
        except Exception:
            payload['enriched_content'] = None

        return jsonify(payload)
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/newsletters/<int:newsletter_id>/refresh-fixtures', methods=['POST'])
def refresh_newsletter_fixtures(newsletter_id: int):
    """
    Check upcoming fixtures in a newsletter and update with results if games have been played.
    This makes newsletters 'living documents' that show actual match outcomes.
    """
    try:
        newsletter = Newsletter.query.get_or_404(newsletter_id)
        
        # Parse structured content
        raw_content = newsletter.structured_content or newsletter.content or '{}'
        try:
            content = json.loads(raw_content)
        except json.JSONDecodeError:
            return jsonify({'error': 'Invalid newsletter content'}), 400
        
        sections = content.get('sections', [])
        if not sections:
            return jsonify({'updated': False, 'message': 'No sections found'})
        
        # Initialize API client for fixture lookups
        from src.api_football_client import APIFootballClient
        api_client = APIFootballClient()
        
        now = datetime.now(timezone.utc)
        fixtures_updated = 0
        fixtures_checked = 0
        
        # Iterate through all player sections and their upcoming fixtures
        for section in sections:
            items = section.get('items', [])
            for item in items:
                # Get loan team info from the player item (for fallback lookups)
                item_loan_team_id = item.get('loan_team_id') or item.get('loan_team_api_id')
                
                upcoming_fixtures = item.get('upcoming_fixtures', [])
                for fixture in upcoming_fixtures:
                    # Skip if already has result
                    if fixture.get('result'):
                        continue
                    
                    # Check if fixture date is in the past
                    fixture_date_str = fixture.get('date')
                    if not fixture_date_str:
                        continue
                    
                    try:
                        fixture_date = datetime.fromisoformat(fixture_date_str.replace('Z', '+00:00'))
                    except (ValueError, TypeError):
                        continue
                    
                    # Only check fixtures that should have been played (add 3 hour buffer for match duration)
                    if fixture_date + timedelta(hours=3) > now:
                        continue
                    
                    fixtures_checked += 1
                    
                    # Get fixture_id - either from fixture data or look it up
                    fixture_id = fixture.get('fixture_id')
                    loan_team_id = fixture.get('loan_team_id') or item_loan_team_id
                    
                    result_data = None
                    
                    if fixture_id:
                        # Direct lookup by fixture ID
                        result_data = api_client.get_fixture_result(fixture_id)
                    elif loan_team_id:
                        # Fallback: Look up by team + date (for older newsletters without fixture_id)
                        try:
                            fixture_date_only = fixture_date.date()
                            date_str = fixture_date_only.strftime('%Y-%m-%d')
                            season = api_client.current_season_start_year
                            
                            # Fetch fixtures for this team on this date
                            team_fixtures = api_client.get_fixtures_for_team(
                                loan_team_id, season, date_str, date_str
                            )
                            
                            # Find matching fixture by opponent
                            opponent_id = fixture.get('opponent_id')
                            opponent_name = fixture.get('opponent', '').lower()
                            
                            for fx in team_fixtures:
                                fx_info = fx.get('fixture', {})
                                teams = fx.get('teams', {})
                                home = teams.get('home', {}) or {}
                                away = teams.get('away', {}) or {}
                                
                                # Check if this fixture matches by opponent
                                is_home = loan_team_id == home.get('id')
                                opp_team = away if is_home else home
                                
                                match_by_id = opponent_id and opp_team.get('id') == opponent_id
                                match_by_name = opponent_name and opponent_name in (opp_team.get('name', '')).lower()
                                
                                if match_by_id or match_by_name:
                                    # Found it - extract result data
                                    goals = fx.get('goals', {})
                                    result_data = {
                                        'fixture_id': fx_info.get('id'),
                                        'status': fx_info.get('status', {}).get('short', ''),
                                        'home_team_id': home.get('id'),
                                        'away_team_id': away.get('id'),
                                        'home_score': goals.get('home'),
                                        'away_score': goals.get('away'),
                                    }
                                    # Store fixture_id for future lookups
                                    fixture['fixture_id'] = fx_info.get('id')
                                    fixture['loan_team_id'] = loan_team_id
                                    break
                        except Exception as e:
                            logger.warning(f"Fallback fixture lookup failed: {e}")
                            continue
                    
                    if not result_data:
                        continue
                    
                    status = result_data.get('status', '')
                    # Only update if match is finished (FT, AET, PEN)
                    if status not in ('FT', 'AET', 'PEN'):
                        continue
                    
                    home_score = result_data.get('home_score')
                    away_score = result_data.get('away_score')
                    
                    if home_score is None or away_score is None:
                        continue
                    
                    # Determine W/L/D based on loan team
                    home_team_id = result_data.get('home_team_id')
                    is_home = loan_team_id == home_team_id
                    
                    if is_home:
                        team_score = home_score
                        opponent_score = away_score
                    else:
                        team_score = away_score
                        opponent_score = home_score
                    
                    if team_score > opponent_score:
                        match_result = 'W'
                    elif team_score < opponent_score:
                        match_result = 'L'
                    else:
                        match_result = 'D'
                    
                    # Update the fixture with result data
                    fixture['status'] = 'completed'
                    fixture['home_score'] = home_score
                    fixture['away_score'] = away_score
                    fixture['result'] = match_result
                    fixture['team_score'] = team_score
                    fixture['opponent_score'] = opponent_score
                    
                    fixtures_updated += 1
        
        # Save updated content if any fixtures were updated
        if fixtures_updated > 0:
            content_json = json.dumps(content, ensure_ascii=False)
            newsletter.structured_content = content_json
            newsletter.content = content_json
            db.session.commit()
            logger.info(f"Updated {fixtures_updated} fixture results for newsletter {newsletter_id}")
        
        # Return updated newsletter content
        return jsonify({
            'updated': fixtures_updated > 0,
            'fixtures_checked': fixtures_checked,
            'fixtures_updated': fixtures_updated,
            'enriched_content': content
        })
        
    except Exception as e:
        logger.error(f"Error refreshing fixtures for newsletter {newsletter_id}: {e}")
        import traceback
        traceback.print_exc()
        return jsonify(_safe_error_payload(e, 'Failed to refresh fixture results')), 500

@api_bp.route('/players/<int:player_id>/stats', methods=['GET'])
def get_public_player_stats(player_id: int):
    """
    Get historical stats for a player (public endpoint).
    Fetches directly from API-Football if local data is incomplete.
    Only returns CLUB games (not international).
    
    Query params:
    - force_sync: If 'true', force sync from API-Football even if local count matches
    """
    try:
        from src.models.weekly import FixturePlayerStats, Fixture
        from src.models.league import LoanedPlayer
        from src.api_football_client import APIFootballClient
        
        # Check for force sync flag
        force_sync = request.args.get('force_sync', '').lower() == 'true'
        
        # Get current season
        now_utc = datetime.now(timezone.utc)
        current_year = now_utc.year
        current_month = now_utc.month
        season = current_year if current_month >= 8 else current_year - 1
        season_prefix = f"{season}-{str(season + 1)[-2:]}"  # e.g., "2025-26"
        
        # Find ALL loan teams for this player this season (handles mid-season transfers)
        all_loans = LoanedPlayer.query.filter(
            LoanedPlayer.player_id == player_id,
            LoanedPlayer.window_key.like(f"{season_prefix}%")
        ).order_by(LoanedPlayer.updated_at.desc()).all()
        
        # If no season-specific loans, try getting any loan
        if not all_loans:
            all_loans = [LoanedPlayer.query.filter_by(player_id=player_id).order_by(LoanedPlayer.updated_at.desc()).first()]
            all_loans = [l for l in all_loans if l]  # Remove None
        
        # Build a map of team_api_id -> team info for all loan teams
        loan_teams_info = {}  # {api_team_id: {name, logo, window_type}}
        for loan in all_loans:
            if loan and loan.loan_team_id:
                loan_team = Team.query.get(loan.loan_team_id)
                if loan_team:
                    window_type = 'Summer'
                    if loan.window_key and '::' in loan.window_key:
                        window_part = loan.window_key.split('::')[1]
                        if window_part.upper() == 'JANUARY':
                            window_type = 'January'
                    loan_teams_info[loan_team.team_id] = {
                        'name': loan_team.name,
                        'logo': loan_team.logo,
                        'window_type': window_type,
                        'is_active': loan.is_active,
                    }
        
        loan_team_api_ids = list(loan_teams_info.keys())
        
        # Query local stats for ALL loan teams
        stats_query = db.session.query(
            FixturePlayerStats, Fixture
        ).join(
            Fixture, FixturePlayerStats.fixture_id == Fixture.id
        ).filter(
            FixturePlayerStats.player_api_id == player_id
        )
        
        # Filter to only loan team games
        if loan_team_api_ids:
            stats_query = stats_query.filter(
                FixturePlayerStats.team_api_id.in_(loan_team_api_ids)
            )
        
        stats_query = stats_query.order_by(Fixture.date_utc.asc()).all()
        
        # Sync missing games from each loan team
        # Get player name from loan records for ID verification during sync
        player_name_for_sync = all_loans[0].player_name if all_loans else None
        
        for loan_team_api_id in loan_team_api_ids:
            try:
                local_count = sum(1 for s, f in stats_query if s.team_api_id == loan_team_api_id)
                api_client = APIFootballClient()
                api_totals = api_client._fetch_player_team_season_totals_api(
                    player_id=player_id,
                    team_id=loan_team_api_id,
                    season=season,
                )
                api_appearances = api_totals.get('games_played', 0)
                
                # Sync if API has more games OR force_sync is requested
                if api_appearances > local_count or force_sync:
                    logger.info(f"Player {player_id} at team {loan_team_api_id}: API={api_appearances}, local={local_count}, force={force_sync}. Syncing...")
                    _sync_player_club_fixtures(player_id, loan_team_api_id, season, player_name=player_name_for_sync)
            except Exception as e:
                logger.warning(f"Failed to sync for player {player_id} at team {loan_team_api_id}: {e}")
        
        # Re-query after potential sync
        stats_query = db.session.query(
            FixturePlayerStats, Fixture
        ).join(
            Fixture, FixturePlayerStats.fixture_id == Fixture.id
        ).filter(
            FixturePlayerStats.player_api_id == player_id
        )
        if loan_team_api_ids:
            stats_query = stats_query.filter(
                FixturePlayerStats.team_api_id.in_(loan_team_api_ids)
            )
        stats_query = stats_query.order_by(Fixture.date_utc.asc()).all()

        result = []
        for stats, fixture in stats_query:
            # Get opponent name using robust resolution with fallbacks
            is_home = (stats.team_api_id == fixture.home_team_api_id)
            opponent_api_id = fixture.away_team_api_id if is_home else fixture.home_team_api_id
            opponent_name, _ = resolve_team_name_and_logo(opponent_api_id, season)
            
            # Get loan team info for this stat
            team_info = loan_teams_info.get(stats.team_api_id, {})
            
            # Fallback: use robust team name resolution if not in loan_teams_info
            if not team_info or not team_info.get('name'):
                loan_team_name, loan_team_logo = resolve_team_name_and_logo(stats.team_api_id, season)
                team_info = {
                    'name': loan_team_name,
                    'logo': loan_team_logo,
                    'window_type': 'Summer',
                }
            
            stats_dict = stats.to_dict()
            stats_dict['fixture_date'] = fixture.date_utc.isoformat() if fixture.date_utc else None
            stats_dict['opponent'] = opponent_name
            stats_dict['is_home'] = is_home
            stats_dict['competition'] = fixture.competition_name
            stats_dict['loan_team_name'] = team_info.get('name') or "Unknown"
            stats_dict['loan_team_logo'] = team_info.get('logo')
            stats_dict['loan_window'] = team_info.get('window_type', 'Summer')
            
            # Include match score for context
            stats_dict['home_goals'] = fixture.home_goals
            stats_dict['away_goals'] = fixture.away_goals
            stats_dict['opponent_api_id'] = opponent_api_id
            
            result.append(stats_dict)

        return jsonify(result)

    except Exception as e:
        logger.error(f"Error fetching player stats for player_id={player_id}: {e}")
        import traceback
        traceback.print_exc()
        return jsonify(_safe_error_payload(e, 'Failed to fetch player stats')), 500


def _sync_player_club_fixtures(player_id: int, loan_team_api_id: int, season: int, player_name: str = None) -> int:
    """
    Sync all fixtures for a player at their loan club from API-Football.
    Returns number of fixtures synced.
    
    Now includes automatic ID verification - if player_id yields no results but
    a matching player name is found with a different ID, updates the LoanedPlayer
    record and syncs with the correct ID.
    """
    from src.api_football_client import APIFootballClient
    from src.models.weekly import Fixture, FixturePlayerStats
    from src.models.league import LoanedPlayer, Team
    
    api_client = APIFootballClient()
    
    # Fetch all fixtures for the loan team this season
    season_start = f"{season}-08-01"
    today = datetime.now(timezone.utc).strftime('%Y-%m-%d')
    
    fixtures = api_client.get_fixtures_for_team(
        loan_team_api_id, 
        season, 
        season_start, 
        today
    )
    
    logger.info(f"Found {len(fixtures)} fixtures for team {loan_team_api_id} in season {season}")
    
    # üîÑ If we have a player name, verify ID via fixtures BEFORE syncing
    # This catches ID mismatches early (e.g., seeded before player played)
    corrected_id = None
    if player_name and len(fixtures) > 0:
        verified_id, method = api_client.verify_player_id_via_fixtures(
            candidate_player_id=player_id,
            player_name=player_name,
            loan_team_id=loan_team_api_id,
            season=season,
            max_fixtures=3
        )
        if verified_id != player_id:
            logger.warning(
                f"üîÑ ID mismatch detected during stats sync for '{player_name}': "
                f"stored={player_id}, correct={verified_id}. Auto-correcting..."
            )
            # Update the LoanedPlayer record
            loan_team_db = Team.query.filter_by(team_id=loan_team_api_id).first()
            if loan_team_db:
                loan = LoanedPlayer.query.filter(
                    LoanedPlayer.player_id == player_id,
                    LoanedPlayer.loan_team_id == loan_team_db.id,
                    LoanedPlayer.is_active.is_(True)
                ).first()
                if loan:
                    loan.player_id = verified_id
                    loan.reviewer_notes = (loan.reviewer_notes or '') + f' | ID auto-corrected during sync: {player_id} ‚Üí {verified_id}'
                    loan.updated_at = datetime.now(timezone.utc)
                    db.session.commit()
                    logger.info(f"‚úÖ Updated LoanedPlayer ID from {player_id} to {verified_id}")
            
            # Also delete any ghost stats with the old ID
            ghost_deleted = FixturePlayerStats.query.filter(
                FixturePlayerStats.player_api_id == player_id,
                FixturePlayerStats.team_api_id == loan_team_api_id,
                FixturePlayerStats.minutes == 0
            ).delete()
            if ghost_deleted:
                db.session.commit()
                logger.info(f"üóëÔ∏è Deleted {ghost_deleted} ghost stat records with old ID {player_id}")
            
            corrected_id = verified_id
            player_id = verified_id  # Use corrected ID for syncing
    
    synced = 0
    for fx in fixtures:
        fixture_info = fx.get('fixture', {})
        fixture_id_api = fixture_info.get('id')
        fixture_status = fixture_info.get('status', {}).get('short', '')
        
        # Only process finished games
        if fixture_status not in ('FT', 'AET', 'PEN'):
            continue
        
        # Get or create fixture record
        existing_fixture = Fixture.query.filter_by(fixture_id_api=fixture_id_api).first()
        
        if not existing_fixture:
            teams = fx.get('teams', {})
            goals = fx.get('goals', {})
            league = fx.get('league', {})
            
            existing_fixture = Fixture(
                fixture_id_api=fixture_id_api,
                date_utc=datetime.fromisoformat(fixture_info.get('date', '').replace('Z', '+00:00')) if fixture_info.get('date') else None,
                season=season,
                competition_name=league.get('name'),
                home_team_api_id=teams.get('home', {}).get('id'),
                away_team_api_id=teams.get('away', {}).get('id'),
                home_goals=goals.get('home'),
                away_goals=goals.get('away'),
            )
            db.session.add(existing_fixture)
            db.session.flush()
        
        # Check if we already have player stats for this fixture
        existing_stats = FixturePlayerStats.query.filter_by(
            fixture_id=existing_fixture.id,
            player_api_id=player_id
        ).first()
        
        if existing_stats:
            continue
        
        # Fetch player stats for this fixture from API
        try:
            player_stats = api_client.get_player_stats_for_fixture(player_id, season, fixture_id_api)
            
            if player_stats and player_stats.get('statistics'):
                # statistics is a LIST, get first element
                stat_list = player_stats['statistics']
                if not stat_list:
                    continue
                st = stat_list[0] if isinstance(stat_list, list) else stat_list
                
                # Extract stats from the nested structure
                games = st.get('games', {}) or {}
                goals_obj = st.get('goals', {}) or {}
                cards = st.get('cards', {}) or {}
                shots = st.get('shots', {}) or {}
                passes = st.get('passes', {}) or {}
                tackles = st.get('tackles', {}) or {}
                duels = st.get('duels', {}) or {}
                dribbles = st.get('dribbles', {}) or {}
                
                minutes = games.get('minutes', 0) or 0
                
                # Only add if player actually played
                if minutes and minutes > 0:
                    # Fouls and penalties for more complete stats
                    fouls = st.get('fouls', {}) or {}
                    penalty = st.get('penalty', {}) or {}
                    
                    fps = FixturePlayerStats(
                        fixture_id=existing_fixture.id,
                        player_api_id=player_id,
                        team_api_id=loan_team_api_id,
                        minutes=minutes,
                        position=games.get('position'),
                        rating=games.get('rating'),
                        goals=goals_obj.get('total', 0) or 0,
                        assists=goals_obj.get('assists', 0) or 0,
                        yellows=cards.get('yellow', 0) or 0,
                        reds=cards.get('red', 0) or 0,
                        shots_total=shots.get('total'),
                        shots_on=shots.get('on'),
                        passes_total=passes.get('total'),
                        passes_key=passes.get('key'),
                        tackles_total=tackles.get('total'),
                        duels_won=duels.get('won'),
                        duels_total=duels.get('total'),
                        dribbles_success=dribbles.get('success'),
                        # Goalkeeper stats - saves and conceded are in goals block
                        saves=goals_obj.get('saves'),
                        goals_conceded=goals_obj.get('conceded'),
                        # Additional stats
                        fouls_drawn=fouls.get('drawn'),
                        fouls_committed=fouls.get('committed'),
                        penalty_saved=penalty.get('saved'),
                    )
                    db.session.add(fps)
                    synced += 1
                    logger.debug(f"Added stats for fixture {fixture_id_api}: {minutes}' played")
        except Exception as e:
            logger.warning(f"Failed to get player stats for fixture {fixture_id_api}: {e}")
            continue
    
    if synced > 0:
        db.session.commit()
        logger.info(f"Synced {synced} fixtures for player {player_id} at team {loan_team_api_id}")
    
    return synced

@api_bp.route('/players/<int:player_id>/profile', methods=['GET'])
def get_public_player_profile(player_id: int):
    """
    Get player profile info including name, team, position, photo.
    Used for the public player profile pages.
    """
    try:
        from src.models.league import LoanedPlayer, SupplementalLoan, Player
        
        result = {
            'player_id': player_id,
            'name': None,
            'photo': None,
            'position': None,
            'loan_team_name': None,
            'loan_team_id': None,
            'loan_team_logo': None,
            'parent_team_name': None,
            'parent_team_id': None,
            'parent_team_logo': None,
            'nationality': None,
            'age': None,
        }
        
        # Get player base info from Player table (has photo)
        player = Player.query.filter_by(player_id=player_id).first()
        if player:
            result['name'] = player.name
            result['photo'] = player.photo_url
            result['position'] = player.position
            result['nationality'] = player.nationality
            result['age'] = player.age
        
        # Get loan info from LoanedPlayer (most recent active loan)
        loaned = LoanedPlayer.query.filter_by(player_id=player_id, is_active=True).order_by(LoanedPlayer.updated_at.desc()).first()
        if not loaned:
            # Try any loan record for this player
            loaned = LoanedPlayer.query.filter_by(player_id=player_id).order_by(LoanedPlayer.updated_at.desc()).first()
        
        if loaned:
            # üîÑ VERIFY player ID for Player Profile page
            # This ensures we show correct data and fix the database if ID was wrong
            if loaned.loan_team_id and loaned.can_fetch_stats:
                try:
                    from src.api_football_client import APIFootballClient
                    from src.models.weekly import FixturePlayerStats
                    
                    loan_team = Team.query.get(loaned.loan_team_id)
                    if loan_team and loan_team.team_id:
                        # Get current season
                        now_utc = datetime.now(timezone.utc)
                        season = now_utc.year if now_utc.month >= 8 else now_utc.year - 1
                        
                        api_client = APIFootballClient()
                        verified_id, method = api_client.verify_player_id_via_fixtures(
                            candidate_player_id=player_id,
                            player_name=loaned.player_name,
                            loan_team_id=loan_team.team_id,
                            season=season,
                            max_fixtures=3
                        )
                        if verified_id != player_id:
                            logger.warning(
                                f"üîÑ Player Profile ID correction for '{loaned.player_name}': "
                                f"{player_id} ‚Üí {verified_id}"
                            )
                            # Update the database record
                            loaned.player_id = verified_id
                            loaned.reviewer_notes = (loaned.reviewer_notes or '') + f' | ID auto-corrected in profile: {player_id} ‚Üí {verified_id}'
                            loaned.updated_at = datetime.now(timezone.utc)
                            db.session.commit()
                            # Delete ghost stats
                            ghost_deleted = FixturePlayerStats.query.filter(
                                FixturePlayerStats.player_api_id == player_id,
                                FixturePlayerStats.team_api_id == loan_team.team_id,
                                FixturePlayerStats.minutes == 0
                            ).delete()
                            if ghost_deleted:
                                db.session.commit()
                            # Update result to use corrected ID
                            result['player_id'] = verified_id
                            # Also update Player table if exists
                            if player:
                                player.player_id = verified_id
                                db.session.commit()
                except Exception as verify_err:
                    logger.debug(f"ID verification failed for profile: {verify_err}")
            
            if not result['name']:
                result['name'] = loaned.player_name
            result['loan_team_name'] = loaned.loan_team_name
            result['parent_team_name'] = loaned.primary_team_name
            
            # Get team logos from Team table
            if loaned.loan_team_id:
                loan_team = Team.query.get(loaned.loan_team_id)
                if loan_team:
                    result['loan_team_logo'] = loan_team.logo
                    result['loan_team_id'] = loan_team.team_id
                    result['loan_team_db_id'] = loaned.loan_team_id  # DB ID for API calls
            
            if loaned.primary_team_id:
                parent_team = Team.query.get(loaned.primary_team_id)
                if parent_team:
                    result['parent_team_logo'] = parent_team.logo
                    result['parent_team_id'] = parent_team.team_id
                    result['primary_team_db_id'] = loaned.primary_team_id  # DB ID for API calls
        
        # If still no name, try supplemental loans
        if not result['name']:
            supplemental = SupplementalLoan.query.filter_by(api_player_id=player_id).first()
            if supplemental:
                result['name'] = supplemental.player_name
                result['loan_team_name'] = supplemental.loan_team_name
                result['parent_team_name'] = supplemental.parent_team_name
                if supplemental.loan_team:
                    result['loan_team_logo'] = supplemental.loan_team.logo
                if supplemental.parent_team:
                    result['parent_team_logo'] = supplemental.parent_team.logo
        
        # If still no name, try to get from fixture stats position
        if not result['name']:
            from src.models.weekly import FixturePlayerStats
            stats = FixturePlayerStats.query.filter_by(player_api_id=player_id).first()
            if stats:
                result['position'] = stats.position
        
        # Final fallback for name
        if not result['name']:
            result['name'] = f"Player #{player_id}"
        
        # Get ALL loans for this season (for mid-season transfers)
        now_utc = datetime.now(timezone.utc)
        current_year = now_utc.year
        current_month = now_utc.month
        season_year = current_year if current_month >= 8 else current_year - 1
        season_prefix = f"{season_year}-{str(season_year + 1)[-2:]}"  # e.g., "2025-26"
        
        all_season_loans = LoanedPlayer.query.filter(
            LoanedPlayer.player_id == player_id,
            LoanedPlayer.window_key.like(f"{season_prefix}%")
        ).order_by(LoanedPlayer.updated_at.desc()).all()
        
        # Deduplicate by (loan_team_id, window_key) - keep only the first (most recent) entry
        seen_loan_keys = set()
        loan_history = []
        for loan in all_season_loans:
            # Create unique key for deduplication
            dedup_key = (loan.loan_team_id, loan.window_key)
            if dedup_key in seen_loan_keys:
                continue
            seen_loan_keys.add(dedup_key)
            
            loan_team = Team.query.get(loan.loan_team_id) if loan.loan_team_id else None
            parent_team = Team.query.get(loan.primary_team_id) if loan.primary_team_id else None
            
            # Determine window type from window_key (e.g., "2025-26::FULL" or "2025-26::JANUARY")
            window_type = 'Summer'
            if loan.window_key and '::' in loan.window_key:
                window_part = loan.window_key.split('::')[1]
                if window_part.upper() == 'JANUARY':
                    window_type = 'January'
                elif window_part.upper() == 'FULL':
                    window_type = 'Summer'
                else:
                    window_type = window_part.title()
            
            loan_history.append({
                'loan_team_name': loan.loan_team_name,
                'loan_team_id': loan_team.team_id if loan_team else None,
                'loan_team_db_id': loan.loan_team_id,  # DB ID for API calls
                'loan_team_logo': loan_team.logo if loan_team else None,
                'parent_team_name': loan.primary_team_name,
                'parent_team_id': parent_team.team_id if parent_team else None,
                'parent_team_logo': parent_team.logo if parent_team else None,
                'window_type': window_type,
                'window_key': loan.window_key,
                'is_active': loan.is_active,
            })
        
        result['loan_history'] = loan_history
        result['has_multiple_loans'] = len(loan_history) > 1
        
        return jsonify(result)

    except Exception as e:
        logger.error(f"Error fetching player profile for player_id={player_id}: {e}")
        import traceback
        traceback.print_exc()
        return jsonify(_safe_error_payload(e, 'Failed to fetch player profile')), 500

@api_bp.route('/players/<int:player_id>/season-stats', methods=['GET'])
def get_public_player_season_stats(player_id: int):
    """
    Get aggregated season stats for a player at their LOAN CLUB only.
    Does NOT include international games or games at other clubs.
    """
    try:
        from src.models.weekly import FixturePlayerStats, Fixture
        from src.models.league import LoanedPlayer
        from src.api_football_client import APIFootballClient
        from sqlalchemy import func
        
        # Get current season
        now_utc = datetime.now(timezone.utc)
        current_year = now_utc.year
        current_month = now_utc.month
        season_start_year = current_year if current_month >= 8 else current_year - 1
        season_start = datetime(season_start_year, 8, 1, tzinfo=timezone.utc)
        
        season_prefix = f"{season_start_year}-{str(season_start_year + 1)[-2:]}"  # e.g., "2025-26"
        
        result = {
            'player_id': player_id,
            'season': f"{season_start_year}/{season_start_year + 1}",
            'appearances': 0,
            'minutes': 0,
            'goals': 0,
            'assists': 0,
            'yellows': 0,
            'reds': 0,
            'avg_rating': None,
            'saves': 0,
            'goals_conceded': 0,
            'clean_sheets': 0,
            'source': 'none',
            'loan_clubs_only': True,  # Stats are only from loan clubs (not international)
            'clubs': [],  # Per-club breakdown
        }
        
        # Find ALL loan teams for this player this season
        all_loans = LoanedPlayer.query.filter(
            LoanedPlayer.player_id == player_id,
            LoanedPlayer.window_key.like(f"{season_prefix}%")
        ).order_by(LoanedPlayer.updated_at.desc()).all()
        
        if not all_loans:
            # Fallback to any loan
            loaned = LoanedPlayer.query.filter_by(player_id=player_id).order_by(LoanedPlayer.updated_at.desc()).first()
            all_loans = [loaned] if loaned else []
        
        if not all_loans:
            return jsonify(result)  # Can't get stats without loan teams
        
        # üìä CHECK FOR LIMITED COVERAGE (e.g., National League)
        # If the player has limited stats coverage, use denormalized stats from LoanedPlayer
        primary_loan = all_loans[0]
        if getattr(primary_loan, 'stats_coverage', 'full') == 'limited':
            logger.info(f"Using limited coverage stats for player {player_id} ({primary_loan.player_name})")
            result['appearances'] = primary_loan.appearances or 0
            result['minutes'] = 0  # Not available for limited coverage
            result['goals'] = primary_loan.goals or 0
            result['assists'] = primary_loan.assists or 0
            result['yellows'] = primary_loan.yellows or 0
            result['reds'] = primary_loan.reds or 0
            result['source'] = 'limited-coverage'
            result['stats_coverage'] = 'limited'
            result['limited_stats_note'] = 'Full match stats not available for this league. Showing appearances, goals, and assists from lineup/event data.'
            
            # Get loan team info
            if primary_loan.loan_team_id:
                loan_team = Team.query.get(primary_loan.loan_team_id)
                if loan_team:
                    result['loan_team'] = loan_team.name
                    result['clubs'] = [{
                        'team_name': loan_team.name,
                        'team_logo': loan_team.logo,
                        'appearances': primary_loan.appearances or 0,
                        'goals': primary_loan.goals or 0,
                        'assists': primary_loan.assists or 0,
                        'is_current': primary_loan.is_active,
                    }]
            
            return jsonify(result)
        
        # Build list of loan teams with their API IDs
        loan_teams_info = []
        loan_team_api_ids = []
        for loan in all_loans:
            if loan and loan.loan_team_id:
                loan_team = Team.query.get(loan.loan_team_id)
                if loan_team and loan_team.team_id not in loan_team_api_ids:
                    window_type = 'Summer'
                    if loan.window_key and '::' in loan.window_key:
                        window_part = loan.window_key.split('::')[1]
                        if window_part.upper() == 'JANUARY':
                            window_type = 'January'
                    loan_teams_info.append({
                        'api_id': loan_team.team_id,
                        'name': loan_team.name,
                        'logo': loan_team.logo,
                        'window_type': window_type,
                        'is_active': loan.is_active,
                    })
                    loan_team_api_ids.append(loan_team.team_id)
        
        result['loan_team'] = loan_teams_info[0]['name'] if loan_teams_info else None
        result['has_multiple_clubs'] = len(loan_teams_info) > 1
        
        # üîÑ VERIFY player ID before fetching season stats
        # This ensures we show correct stats even if player was seeded with wrong ID
        api_client = APIFootballClient()
        player_id_to_use = player_id
        player_name_for_verify = all_loans[0].player_name if all_loans else None
        
        if player_name_for_verify and loan_teams_info:
            verified_id, method = api_client.verify_player_id_via_fixtures(
                candidate_player_id=player_id,
                player_name=player_name_for_verify,
                loan_team_id=loan_teams_info[0]['api_id'],
                season=season_start_year,
                max_fixtures=3
            )
            if verified_id != player_id:
                logger.warning(
                    f"üîÑ Season-stats ID correction for '{player_name_for_verify}': "
                    f"{player_id} ‚Üí {verified_id}"
                )
                player_id_to_use = verified_id
                # Update the database record
                for loan in all_loans:
                    if loan.player_id == player_id:
                        loan.player_id = verified_id
                        loan.reviewer_notes = (loan.reviewer_notes or '') + f' | ID auto-corrected in season-stats: {player_id} ‚Üí {verified_id}'
                        loan.updated_at = datetime.now(timezone.utc)
                db.session.commit()
                # Delete ghost stats
                ghost_deleted = FixturePlayerStats.query.filter(
                    FixturePlayerStats.player_api_id == player_id,
                    FixturePlayerStats.team_api_id.in_(loan_team_api_ids),
                    FixturePlayerStats.minutes == 0
                ).delete()
                if ghost_deleted:
                    db.session.commit()
                # Update result to reflect new ID
                result['player_id'] = verified_id
        
        # Aggregate stats from API-Football for ALL loan clubs
        total_appearances = 0
        total_minutes = 0
        total_goals = 0
        total_assists = 0
        clubs_breakdown = []
        
        for team_info in loan_teams_info:
            try:
                api_totals = api_client._fetch_player_team_season_totals_api(
                    player_id=player_id_to_use,
                    team_id=team_info['api_id'],
                    season=season_start_year,
                )
                
                if api_totals and api_totals.get('games_played', 0) > 0:
                    club_stats = {
                        'team_name': team_info['name'],
                        'team_logo': team_info['logo'],
                        'window_type': team_info['window_type'],
                        'is_current': team_info['is_active'],
                        'appearances': api_totals.get('games_played', 0),
                        'minutes': api_totals.get('minutes', 0),
                        'goals': api_totals.get('goals', 0),
                        'assists': api_totals.get('assists', 0),
                        'saves': api_totals.get('saves', 0),
                        'goals_conceded': api_totals.get('goals_conceded', 0),
                    }
                    clubs_breakdown.append(club_stats)
                    total_appearances += club_stats['appearances']
                    total_minutes += club_stats['minutes']
                    total_goals += club_stats['goals']
                    total_assists += club_stats['assists']
                    result['source'] = 'api-football'
            except Exception as api_err:
                logger.warning(f"Failed to get API-Football stats for player {player_id} at {team_info['name']}: {api_err}")
        
        result['appearances'] = total_appearances
        result['minutes'] = total_minutes
        result['goals'] = total_goals
        result['assists'] = total_assists
        result['clubs'] = clubs_breakdown
        
        # Get detailed stats from local DB (aggregate across ALL loan clubs)
        stats_query = db.session.query(
            func.count(FixturePlayerStats.id).label('appearances'),
            func.sum(FixturePlayerStats.minutes).label('total_minutes'),
            func.sum(FixturePlayerStats.goals).label('total_goals'),
            func.sum(FixturePlayerStats.assists).label('total_assists'),
            func.sum(FixturePlayerStats.yellows).label('total_yellows'),
            func.sum(FixturePlayerStats.reds).label('total_reds'),
            func.avg(FixturePlayerStats.rating).label('avg_rating'),
            func.sum(FixturePlayerStats.shots_total).label('total_shots'),
            func.sum(FixturePlayerStats.shots_on).label('shots_on_target'),
            func.sum(FixturePlayerStats.passes_key).label('total_key_passes'),
            func.sum(FixturePlayerStats.tackles_total).label('total_tackles'),
            func.sum(FixturePlayerStats.saves).label('total_saves'),
            func.sum(FixturePlayerStats.goals_conceded).label('total_goals_conceded'),
        ).join(
            Fixture, FixturePlayerStats.fixture_id == Fixture.id
        ).filter(
            FixturePlayerStats.player_api_id == player_id,
            FixturePlayerStats.team_api_id.in_(loan_team_api_ids),  # ALL loan clubs
            Fixture.date_utc >= season_start
        ).first()
        
        if stats_query and stats_query.appearances:
            local_appearances = stats_query.appearances or 0
            local_minutes = int(stats_query.total_minutes or 0)
            local_goals = int(stats_query.total_goals or 0)
            local_assists = int(stats_query.total_assists or 0)
            
            result['yellows'] = int(stats_query.total_yellows or 0)
            result['reds'] = int(stats_query.total_reds or 0)
            result['avg_rating'] = round(float(stats_query.avg_rating or 0), 2) if stats_query.avg_rating else None
            result['shots'] = int(stats_query.total_shots or 0)
            result['shots_on_target'] = int(stats_query.shots_on_target or 0)
            result['key_passes'] = int(stats_query.total_key_passes or 0)
            result['tackles'] = int(stats_query.total_tackles or 0)
            result['saves'] = int(stats_query.total_saves or 0)
            result['goals_conceded'] = int(stats_query.total_goals_conceded or 0)
            result['local_appearances'] = local_appearances
            
            # PREFER local fixture data when it has MORE appearances than API-Football
            # This handles cases where API-Football's aggregated endpoint is incomplete
            # Our fixture data is captured per-game and is more reliable
            if local_appearances > result.get('appearances', 0):
                logger.info(
                    f"Using local fixture data for player {player_id}: "
                    f"local={local_appearances} apps > API={result.get('appearances', 0)} apps"
                )
                result['appearances'] = local_appearances
                result['minutes'] = local_minutes
                result['goals'] = local_goals
                result['assists'] = local_assists
                result['source'] = 'local-db'
            elif result['source'] == 'none':
                # Fallback to local DB if API-Football returned nothing
                result['appearances'] = local_appearances
                result['minutes'] = local_minutes
                result['goals'] = local_goals
                result['assists'] = local_assists
                result['source'] = 'local-db'
        
        # Calculate clean sheets for goalkeepers (games with 0 goals conceded and >= 45 mins)
        clean_sheets_query = db.session.query(
            func.count(FixturePlayerStats.id).label('clean_sheets')
        ).join(
            Fixture, FixturePlayerStats.fixture_id == Fixture.id
        ).filter(
            FixturePlayerStats.player_api_id == player_id,
            FixturePlayerStats.team_api_id.in_(loan_team_api_ids),
            Fixture.date_utc >= season_start,
            FixturePlayerStats.goals_conceded == 0,
            FixturePlayerStats.minutes >= 45
        ).first()
        
        result['clean_sheets'] = clean_sheets_query.clean_sheets if clean_sheets_query else 0
        
        return jsonify(result)

    except Exception as e:
        logger.error(f"Error fetching season stats for player_id={player_id}: {e}")
        import traceback
        traceback.print_exc()
        return jsonify(_safe_error_payload(e, 'Failed to fetch season stats')), 500


@api_bp.route('/players/<int:player_id>/commentaries', methods=['GET'])
def get_player_commentaries(player_id: int):
    """
    Get all commentaries/writeups that mention this player.
    Returns journalist writeups with author info.
    """
    try:
        # Find all commentaries that reference this player
        commentaries = NewsletterCommentary.query.filter(
            NewsletterCommentary.player_id == player_id,
            NewsletterCommentary.is_active == True
        ).order_by(NewsletterCommentary.created_at.desc()).all()
        
        result = []
        for c in commentaries:
            author = c.author
            newsletter = c.newsletter
            
            commentary_data = {
                'id': c.id,
                'content': c.content,
                'title': c.title,
                'commentary_type': c.commentary_type,
                'is_premium': c.is_premium,
                'created_at': c.created_at.isoformat() if c.created_at else None,
                'updated_at': c.updated_at.isoformat() if c.updated_at else None,
                'author': {
                    'id': author.id if author else None,
                    'display_name': author.display_name if author else None,
                    'profile_image_url': author.profile_image_url if author else None,
                    'is_journalist': author.is_journalist if author else False,
                } if author else None,
                'newsletter': {
                    'id': newsletter.id if newsletter else None,
                    'title': newsletter.title if newsletter else None,
                    'week_start_date': newsletter.week_start_date.isoformat() if newsletter and newsletter.week_start_date else None,
                    'week_end_date': newsletter.week_end_date.isoformat() if newsletter and newsletter.week_end_date else None,
                    'team_name': newsletter.team.name if newsletter and newsletter.team else None,
                } if newsletter else None,
            }
            result.append(commentary_data)
        
        # Also get unique authors who have written about this player
        unique_authors = {}
        for c in commentaries:
            if c.author and c.author.id not in unique_authors:
                unique_authors[c.author.id] = {
                    'id': c.author.id,
                    'display_name': c.author.display_name,
                    'profile_image_url': c.author.profile_image_url,
                    'is_journalist': c.author.is_journalist,
                    'commentary_count': 0,
                }
            if c.author:
                unique_authors[c.author.id]['commentary_count'] += 1
        
        return jsonify({
            'player_id': player_id,
            'commentaries': result,
            'total_count': len(result),
            'authors': list(unique_authors.values()),
        })
        
    except Exception as e:
        logger.error(f"Error fetching commentaries for player_id={player_id}: {e}")
        import traceback
        traceback.print_exc()
        return jsonify(_safe_error_payload(e, 'Failed to fetch player commentaries')), 500


@api_bp.route('/newsletters/<int:newsletter_id>/comments', methods=['GET'])
def list_newsletter_comments(newsletter_id: int):
    try:
        # Ensure newsletter exists
        Newsletter.query.get_or_404(newsletter_id)
        rows = NewsletterComment.query\
            .filter_by(newsletter_id=newsletter_id, is_deleted=False)\
            .order_by(NewsletterComment.created_at.asc())\
            .all()
        return jsonify([r.to_dict() for r in rows])
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/newsletters/<int:newsletter_id>/comments', methods=['POST'])
@require_user_auth
@limiter.limit("8 per minute", key_func=_user_rate_limit_key)
def create_newsletter_comment(newsletter_id: int):
    try:
        nl = Newsletter.query.get_or_404(newsletter_id)
        payload = request.get_json() or {}
        raw_body = (payload.get('body') or '').strip()
        if not raw_body:
            return jsonify({'error': 'body is required'}), 400
        body = sanitize_comment_body(raw_body)
        user_email = getattr(g, 'user_email', None)
        if not user_email:
            return jsonify({'error': 'auth context missing email'}), 401
        user = UserAccount.query.filter_by(email=user_email).first()
        if not user:
            user = _ensure_user_account(user_email)
        if not body:
            return jsonify({'error': 'body is required'}), 400
        c = NewsletterComment(
            newsletter_id=nl.id,
            user_id=user.id if user else None,
            author_email=user_email,
            author_name=user.display_name if user else None,
            author_name_legacy=user.display_name if user else None,
            user=user,
            body=body,
        )
        if not c.author_email:
            return jsonify({'error': 'auth context missing email'}), 401
        db.session.add(c)
        db.session.commit()
        return jsonify({'message': 'Comment created', 'comment': c.to_dict()}), 201
    except Exception as e:
        try:
            db.session.rollback()
        except Exception:
            pass
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/newsletters/generate', methods=['POST'])
def generate_newsletter():
    """Generate a newsletter for a specific team and date."""
    try:
        logger.info("=" * 80)
        logger.info("üì∞ NEWSLETTER GENERATION REQUEST STARTED")
        
        data = request.get_json()
        team_id = data.get('team_id')
        target_date = data.get('target_date')  # Format: YYYY-MM-DD
        newsletter_type = data.get('type', 'weekly')
        force_refresh = data.get('force_refresh', False)
        
        logger.info(f"üìù Request data: team_id={team_id}, target_date={target_date}, type={newsletter_type}, force_refresh={force_refresh}")
        
        if not team_id:
            logger.warning("‚ùå Missing team_id in request")
            return jsonify({'error': 'team_id is required'}), 400
        
        logger.info(f"üîç Fetching team with ID: {team_id}")
        team = Team.query.get_or_404(team_id)
        logger.info(f"‚úÖ Found team: {team.name} (ID: {team.id})")
        
        # Parse target date
        if target_date:
            try:
                target_date = datetime.strptime(target_date, '%Y-%m-%d').date()
                logger.info(f"üìÖ Parsed target date: {target_date}")
            except ValueError as ve:
                logger.error(f"‚ùå Invalid date format: {target_date}, error: {ve}")
                return jsonify({'error': 'Invalid date format. Use YYYY-MM-DD'}), 400
        else:
            target_date = datetime.now(timezone.utc).date()
            logger.info(f"üìÖ Using today's date: {target_date}")
        
        # Compute week window for weekly newsletters
        week_start = None
        week_end = None
        if newsletter_type == 'weekly' and target_date:
            week_start = target_date - timedelta(days=target_date.weekday())
            week_end = week_start + timedelta(days=6)
            logger.info(f"üìÜ Computed week range: {week_start} to {week_end}")

        # Check if newsletter already exists for this team and week/date
        logger.info(f"üîç Checking for existing newsletter: team_id={team_id}, type={newsletter_type}, date={target_date}")
        if week_start and week_end:
            existing = Newsletter.query.filter_by(
                team_id=team_id,
                newsletter_type=newsletter_type,
                week_start_date=week_start,
                week_end_date=week_end
            ).first()
        else:
            existing = Newsletter.query.filter_by(
                team_id=team_id,
                newsletter_type=newsletter_type,
                issue_date=target_date
            ).first()

        if existing and not force_refresh:
            logger.info(f"‚ÑπÔ∏è  Newsletter already exists with ID: {existing.id}")
            return jsonify({
                'message': 'Newsletter already exists for this date',
                'newsletter': existing.to_dict()
            })
        
        # For weekly newsletters, use the OpenAI-powered generator which
        # compiles full player + loan team weekly context before writing,
        # then persist the newsletter with the same semantics as before.
        if newsletter_type == 'weekly':
            logger.info("ü§ñ Starting weekly newsletter composition...")
            try:
                from src.agents.weekly_newsletter_agent import (
                    compose_team_weekly_newsletter,
                    persist_newsletter,
                )
                logger.info("‚úÖ Successfully imported newsletter agent functions")
            except ImportError as ie:
                logger.error(f"‚ùå IMPORT ERROR: Failed to import newsletter agent: {ie}")
                logger.exception("Full import traceback:")
                raise

            try:
                logger.info(f"üöÄ Calling compose_team_weekly_newsletter(team_id={team_id}, target_date={target_date}, force_refresh={force_refresh})")
                composed = compose_team_weekly_newsletter(team_id, target_date, force_refresh=force_refresh)
                logger.info("‚úÖ Newsletter composed successfully")
                logger.info(f"üìä Composed data keys: {list(composed.keys())}")
            except Exception as compose_error:
                logger.error(f"‚ùå COMPOSITION ERROR: {type(compose_error).__name__}: {compose_error}")
                logger.exception("Full composition traceback:")
                raise
            
            try:
                logger.info("üíæ Persisting newsletter to database...")
                if existing and force_refresh:
                    logger.info(f"‚ôªÔ∏è  Force refresh requested; updating existing newsletter ID: {existing.id}")
                    payload_obj = None
                    content_json_str = composed.get('content_json') or '{}'
                    try:
                        payload_obj = json.loads(content_json_str) if isinstance(content_json_str, str) else content_json_str
                    except Exception:
                        payload_obj = None

                    if isinstance(payload_obj, dict):
                        # Render variants for preview/email
                        try:
                            from src.agents.weekly_newsletter_agent import _render_variants
                            team_name = team.name if team else None
                            variants = _render_variants(payload_obj, team_name)
                            payload_obj['rendered'] = variants
                            content_json_str = json.dumps(payload_obj, ensure_ascii=False)
                        except Exception:
                            pass

                    now = datetime.now(timezone.utc)
                    if isinstance(payload_obj, dict):
                        title = payload_obj.get('title')
                        if isinstance(title, str) and title.strip():
                            existing.title = title.strip()
                    existing.content = content_json_str
                    existing.structured_content = content_json_str
                    existing.issue_date = target_date
                    existing.week_start_date = composed.get('week_start') or week_start
                    existing.week_end_date = composed.get('week_end') or week_end
                    existing.generated_date = now
                    existing.updated_at = now
                    db.session.commit()
                    logger.info(f"‚úÖ Newsletter refreshed for ID: {existing.id}")
                    row = existing
                else:
                    # Persist using shared helper (sets generated_date/published_date)
                    row = persist_newsletter(
                        team_db_id=team_id,
                        content_json_str=composed['content_json'],
                        week_start=composed['week_start'],
                        week_end=composed['week_end'],
                        issue_date=target_date,
                        newsletter_type='weekly',
                    )
                    logger.info(f"‚úÖ Newsletter persisted with ID: {row.id}")
            except Exception as persist_error:
                logger.error(f"‚ùå PERSISTENCE ERROR: {type(persist_error).__name__}: {persist_error}")
                logger.exception("Full persistence traceback:")
                raise
            
            logger.info("üéâ Newsletter generation completed successfully!")
            logger.info("=" * 80)
            return jsonify({
                'message': 'Newsletter generated successfully',
                'newsletter': row.to_dict()
            })
        
        # Fallback for other types (currently unsupported):
        logger.warning(f"‚ùå Unsupported newsletter type: {newsletter_type}")
        return jsonify({'error': f'Unsupported newsletter type: {newsletter_type}'}), 400
        
    except Exception as e:
        # Ensure DB session is not left in a failed state for subsequent requests
        try:
            db.session.rollback()
        except Exception:
            pass
        logger.error("=" * 80)
        logger.error(f"üí• FATAL ERROR in generate_newsletter: {type(e).__name__}: {e}")
        logger.exception("Full error traceback:")
        logger.error("=" * 80)
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

def generate_newsletter_content(*args, **kwargs):  # pragma: no cover - legacy shim
    """Deprecated: shim retained for backward compatibility.
    The /newsletters/generate endpoint now uses the OpenAI-backed
    generator for 'weekly' type. This function is unused and will
    be removed in a future cleanup.
    """
    raise NotImplementedError("Legacy mock generator removed; use generate_team_weekly_newsletter")

# Subscription endpoints
@api_bp.route('/subscriptions', methods=['GET'])
@require_api_key
def get_subscriptions():
    """Admin: list subscriptions with optional active filter."""
    try:
        active_only = request.args.get('active_only', 'false').lower() in ('true', '1', 'yes', 'y')
        query = UserSubscription.query
        if active_only:
            query = query.filter(UserSubscription.active == True)
        subscriptions = query.all()
        return jsonify([sub.to_dict() for sub in subscriptions])
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500


def _activate_subscriptions(email: str, team_ids: list[int], preferred_frequency: str = 'weekly') -> dict[str, Any]:
    created_ids: list[int] = []
    updated_ids: list[int] = []
    skipped: list[dict[str, Any]] = []
    teams_without_newsletters: list[dict[str, Any]] = []

    unique_ids: list[int] = []
    seen_ids: set[int] = set()
    for tid in team_ids:
        if tid in seen_ids:
            continue
        seen_ids.add(tid)
        unique_ids.append(tid)

    team_rows = Team.query.filter(Team.id.in_(unique_ids)).all() if unique_ids else []
    team_map = {row.id: row for row in team_rows}

    for tid in unique_ids:
        team = team_map.get(tid)
        if not team:
            skipped.append({'team_id': tid, 'reason': 'team not found'})
            continue

        # Track teams without active newsletters
        if not team.newsletters_active:
            teams_without_newsletters.append({
                'team_id': team.id,
                'team_name': team.name
            })

        existing = UserSubscription.query.filter_by(email=email, team_id=team.id).first()
        if existing:
            changed = False
            if not existing.active:
                existing.active = True
                changed = True
            if existing.preferred_frequency != preferred_frequency:
                existing.preferred_frequency = preferred_frequency
                changed = True
            if not existing.unsubscribe_token:
                existing.unsubscribe_token = str(uuid.uuid4())
                changed = True
            if changed:
                updated_ids.append(existing.id)
            else:
                skipped.append({'team_id': team.id, 'reason': 'already active'})
            continue

        subscription = UserSubscription(
            email=email,
            team_id=team.id,
            preferred_frequency=preferred_frequency,
            active=True,
            unsubscribe_token=str(uuid.uuid4()),
        )
        db.session.add(subscription)
        db.session.flush()
        created_ids.append(subscription.id)

    result_ids = created_ids + updated_ids
    subs = UserSubscription.query.filter(UserSubscription.id.in_(result_ids)).all() if result_ids else []

    # Send waitlist email if there are teams without newsletters
    if teams_without_newsletters:
        try:
            team_names = [t['team_name'] for t in teams_without_newsletters]
            _send_waitlist_welcome_email(email, team_names)
        except Exception as e:
            logger.warning('Failed to send waitlist email to %s: %s', email, e)

    return {
        'message': 'Subscriptions updated',
        'created_count': len(created_ids),
        'updated_count': len(updated_ids),
        'skipped': skipped,
        'created_ids': created_ids,
        'updated_ids': updated_ids,
        'subscriptions': [s.to_dict() for s in subs],
        'teams_without_newsletters': teams_without_newsletters,
    }


def _process_subscriptions(email: str, team_ids_raw: list[Any], preferred_frequency: str) -> tuple[dict[str, Any], int]:
    if not email:
        return {'error': 'email is required'}, 400
    if not team_ids_raw:
        return {'error': 'team_ids are required'}, 400

    parsed_ids: list[int] = []
    skipped: list[dict[str, Any]] = []
    for raw_id in team_ids_raw:
        try:
            tid = int(raw_id)
        except (TypeError, ValueError):
            skipped.append({'team_id': raw_id, 'reason': 'invalid team id'})
            continue
        parsed_ids.append(tid)

    if not parsed_ids:
        return {'error': 'No valid team ids provided', 'skipped': skipped}, 400

    team_rows = Team.query.filter(Team.id.in_(parsed_ids)).all()
    team_map = {row.id: row for row in team_rows}

    valid_ids: list[int] = []
    team_names: list[str] = []
    teams_without_newsletters: list[dict[str, Any]] = []
    seen_ids: set[int] = set()
    for tid in parsed_ids:
        if tid in seen_ids:
            continue
        seen_ids.add(tid)
        team = team_map.get(tid)
        if not team:
            skipped.append({'team_id': tid, 'reason': 'team not found'})
            continue
        valid_ids.append(tid)
        team_names.append(team.name or f'Team #{tid}')
        
        # Track teams without active newsletters
        if not team.newsletters_active:
            teams_without_newsletters.append({
                'team_id': team.id,
                'team_name': team.name
            })

    if not valid_ids:
        return {'error': 'No valid team ids provided', 'skipped': skipped}, 400

    if SUBSCRIPTIONS_REQUIRE_VERIFY:
        try:
            token_row = _create_email_token(
                email=email,
                purpose='subscribe_confirm',
                metadata={'team_ids': valid_ids, 'preferred_frequency': preferred_frequency},
                ttl_minutes=SUBSCRIPTIONS_VERIFY_TTL_MINUTES,
            )
            db.session.flush()
            _send_subscription_verification_email(email, team_names, token_row.token)
            db.session.commit()
            return ({
                'message': 'Verification email sent. Please check your inbox to confirm.',
                'verification_required': True,
                'team_count': len(valid_ids),
                'expires_at': token_row.expires_at.isoformat() if token_row.expires_at else None,
                'skipped': skipped,
                'teams_without_newsletters': teams_without_newsletters,
            }, 202)
        except Exception as exc:
            try:
                db.session.rollback()
            except Exception:
                pass
            logger.exception('Failed to queue subscription verification for %s', email)
            return _safe_error_payload(exc, 'Failed to send verification email'), 500

    result = _activate_subscriptions(email, valid_ids, preferred_frequency)
    result['skipped'].extend(skipped)
    db.session.commit()
    status = 201 if result['created_count'] else 200
    return result, status

@api_bp.route('/subscriptions', methods=['POST'])
def create_subscription():
    """Create a new subscription for a single team."""
    try:
        data = request.get_json() or {}

        email = data.get('email')
        team_id = data.get('team_id')
        preferred_frequency = data.get('preferred_frequency', 'weekly')

        if not email or team_id is None:
            return jsonify({'error': 'email and team_id are required'}), 400

        payload, status = _process_subscriptions(email, [team_id], preferred_frequency)
        return jsonify(payload), status
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/subscriptions/bulk_create', methods=['POST'])
def bulk_create_subscriptions():
    """Create or update subscriptions for multiple teams in one request."""
    try:
        data = request.get_json() or {}
        email = data.get('email')
        team_ids = data.get('team_ids') or []
        preferred_frequency = data.get('preferred_frequency', 'weekly')

        if not email or not team_ids:
            return jsonify({'error': 'email and team_ids are required'}), 400

        payload, status = _process_subscriptions(email, team_ids, preferred_frequency)
        return jsonify(payload), status
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

def _create_email_token(email: str, purpose: str, metadata: dict | None = None, ttl_minutes: int = 60) -> EmailToken:
    token = str(uuid.uuid4())
    expires_at = datetime.now(timezone.utc) + timedelta(minutes=ttl_minutes)
    row = EmailToken(
        token=token,
        email=email,
        purpose=purpose,
        expires_at=expires_at,
        metadata_json=json.dumps(metadata or {})
    )
    db.session.add(row)
    db.session.flush()
    logger.info(
        "Created email token id=%s purpose=%s email=%s expires_at=%s",
        row.id,
        purpose,
        email,
        expires_at.isoformat(),
    )
    return row

@api_bp.route('/subscriptions/request-manage-link', methods=['POST'])
def request_manage_link():
    """Issue a one-time manage token emailed to the user (email delivery handled elsewhere)."""
    try:
        data = request.get_json() or {}
        email = data.get('email')
        if not email:
            return jsonify({'error': 'email is required'}), 400
        # 30 days TTL so links in newsletters remain useful across sends
        tok = _create_email_token(email=email, purpose='manage', ttl_minutes=60 * 24 * 30)
        db.session.commit()
        return jsonify({'message': 'Manage link created', 'token': tok.token, 'expires_at': tok.expires_at.isoformat()})
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/subscriptions/manage/<token>', methods=['GET'])
def get_manage_state(token: str):
    """Validate token and return current subscriptions for that email."""
    try:
        row = EmailToken.query.filter_by(token=token, purpose='manage').first()
        if not row or not row.is_valid():
            return jsonify({'error': 'invalid or expired token'}), 400
        subs = UserSubscription.query.filter_by(email=row.email, active=True).all()
        return jsonify({'email': row.email, 'subscriptions': [s.to_dict() for s in subs], 'expires_at': row.expires_at.isoformat()})
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/subscriptions/manage/<token>', methods=['POST'])
def update_manage_state(token: str):
    """Upsert subscriptions for the token's email using team_ids and preferred_frequency."""
    try:
        row = EmailToken.query.filter_by(token=token, purpose='manage').first()
        if not row or not row.is_valid():
            return jsonify({'error': 'invalid or expired token'}), 400

        payload = request.get_json() or {}
        team_ids = payload.get('team_ids') or []
        preferred_frequency = payload.get('preferred_frequency', 'weekly')

        # Deactivate all current subscriptions for this email first
        UserSubscription.query.filter_by(email=row.email, active=True).update({UserSubscription.active: False})

        # Activate/create for provided list
        for raw_id in team_ids:
            team = Team.query.get(int(raw_id))
            if not team:
                continue
            existing = UserSubscription.query.filter_by(email=row.email, team_id=team.id).first()
            if existing:
                existing.active = True
                existing.preferred_frequency = preferred_frequency
                if not existing.unsubscribe_token:
                    existing.unsubscribe_token = str(uuid.uuid4())
            else:
                db.session.add(UserSubscription(
                    email=row.email,
                    team_id=team.id,
                    preferred_frequency=preferred_frequency,
                    active=True,
                    unsubscribe_token=str(uuid.uuid4()),
                ))

        # Optionally mark token as used immediately or let it remain valid until expiry
        # row.used_at = datetime.now(timezone.utc)

        db.session.commit()
        return jsonify({'message': 'Subscriptions updated'})
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500


@api_bp.route('/subscriptions/unsubscribe', methods=['POST'])
def unsubscribe_by_email():
    """Unsubscribe an email address from one or more teams."""
    try:
        payload = request.get_json() or {}
        email_raw = payload.get('email')
        email = (email_raw or '').strip().lower()
        team_ids = payload.get('team_ids') or []

        if not email:
            auth_email = _get_authorized_email()
            if auth_email:
                email = auth_email.strip().lower()

        if not email:
            return jsonify({'error': 'email is required'}), 400

        query = UserSubscription.query.filter_by(email=email)
        parsed_ids: set[int] = set()
        for raw in team_ids:
            try:
                parsed_ids.add(int(raw))
            except (TypeError, ValueError):
                continue
        if parsed_ids:
            query = query.filter(UserSubscription.team_id.in_(parsed_ids))

        subs = query.all()
        if not subs:
            return jsonify({'message': 'No matching subscriptions found', 'count': 0}), 200

        count = 0
        for sub in subs:
            if sub.active:
                sub.active = False
                count += 1
        db.session.commit()
        return jsonify({'message': 'Unsubscribed successfully', 'count': count})
    except Exception as e:
        try:
            db.session.rollback()
        except Exception:
            pass
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500


def _unsubscribe_subscription_by_token(token: str) -> tuple[UserSubscription | None, str, int]:
    token = (token or '').strip()
    if not token:
        return None, 'missing_token', 400

    sub = UserSubscription.query.filter_by(unsubscribe_token=token).first()
    if not sub:
        return None, 'not_found', 404

    if sub.active:
        try:
            sub.active = False
            db.session.commit()
        except Exception:
            db.session.rollback()
            raise
        return sub, 'unsubscribed', 200

    return sub, 'already_unsubscribed', 200


def _public_manage_url() -> str | None:
    base = os.getenv('PUBLIC_BASE_URL', '').rstrip('/')
    if not base:
        return None
    manage_path = os.getenv('PUBLIC_MANAGE_PATH', '/manage')
    return f"{base}{manage_path}"


@api_bp.route('/subscriptions/unsubscribe/<token>', methods=['GET', 'POST'])
def token_unsubscribe(token: str):
    """Unsubscribe a single subscription by its unsubscribe token.

    POST returns JSON for programmatic callers. GET immediately unsubscribes
    and renders a lightweight confirmation page suitable for email links.
    """
    if request.method == 'POST':
        try:
            sub, status, code = _unsubscribe_subscription_by_token(token)
        except Exception as e:
            logger.exception('Error unsubscribing via token (POST)')
            return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

        if status == 'missing_token':
            return jsonify({'error': 'token is required'}), code
        if status == 'not_found':
            return jsonify({'error': 'invalid token'}), code

        message = 'Unsubscribed successfully' if status == 'unsubscribed' else 'Subscription already inactive'
        return jsonify({'message': message}), code

    # GET: render confirmation page
    try:
        sub, status, code = _unsubscribe_subscription_by_token(token)
    except Exception as e:
        logger.exception('Error unsubscribing via token (GET)')
        error_ctx = {
            'status': 'error',
            'headline': 'Something went wrong',
            'body': 'We were unable to process your unsubscribe request. Please try again later.',
            'manage_url': _public_manage_url(),
        }
        return render_template('unsubscribe_confirmation.html', **error_ctx), 500

    manage_url = _public_manage_url()
    team_name = sub.team.name if sub and getattr(sub, 'team', None) else None

    if status == 'missing_token':
        ctx = {
            'status': 'error',
            'headline': 'Invalid unsubscribe link',
            'body': 'The unsubscribe link is missing required information. Please check the email and try again.',
            'manage_url': manage_url,
            'team_name': team_name,
        }
    elif status == 'not_found':
        ctx = {
            'status': 'error',
            'headline': 'Link expired or invalid',
            'body': 'We could not find a subscription for this link. It may have already been used or expired.',
            'manage_url': manage_url,
            'team_name': team_name,
        }
    elif status == 'unsubscribed':
        ctx = {
            'status': 'ok',
            'headline': 'You are unsubscribed',
            'body': 'You will no longer receive updates for this team. You can manage other preferences anytime.',
            'manage_url': manage_url,
            'team_name': team_name,
            'email': sub.email if sub else None,
        }
    else:  # already_unsubscribed
        ctx = {
            'status': 'ok',
            'headline': 'Already unsubscribed',
            'body': 'This email was already unsubscribed from this team. No further action is required.',
            'manage_url': manage_url,
            'team_name': team_name,
            'email': sub.email if sub else None,
        }

    return render_template('unsubscribe_confirmation.html', **ctx), code


@api_bp.route('/subscriptions/one-click-unsubscribe/<token>', methods=['POST'])
def one_click_unsubscribe(token: str):
    """RFC 8058 One-Click Unsubscribe endpoint for email clients.
    
    This endpoint is designed for email providers (Gmail, Yahoo, etc.) that 
    implement one-click unsubscribe via the List-Unsubscribe-Post header.
    
    The email client sends a POST request with body: List-Unsubscribe=One-Click
    
    Returns 200 on success (required by RFC 8058).
    """
    try:
        # RFC 8058 specifies the body should be "List-Unsubscribe=One-Click"
        # but we accept any POST to this endpoint as valid
        body = request.get_data(as_text=True) or ''
        content_type = request.content_type or ''
        
        logger.info(
            'One-click unsubscribe request: token=%s content_type=%s body_preview=%s',
            token[:8] + '...' if len(token) > 8 else token,
            content_type,
            body[:100] if body else '(empty)'
        )
        
        sub, status, code = _unsubscribe_subscription_by_token(token)
        
        if status == 'missing_token':
            # Return 200 anyway per RFC 8058 best practices
            # (some clients don't handle non-200 well)
            logger.warning('One-click unsubscribe: missing token')
            return '', 200
        
        if status == 'not_found':
            logger.warning('One-click unsubscribe: token not found - %s', token[:8] + '...')
            return '', 200
        
        if status in ('unsubscribed', 'already_unsubscribed'):
            logger.info('One-click unsubscribe successful for token %s', token[:8] + '...')
            return '', 200
        
        return '', 200
        
    except Exception as e:
        logger.exception('One-click unsubscribe failed for token')
        # Still return 200 to avoid retry loops from email clients
        return '', 200


def _build_unsubscribe_headers(unsubscribe_url: str, one_click_url: str) -> dict:
    """Build RFC 8058 compliant List-Unsubscribe headers.
    
    Args:
        unsubscribe_url: URL for the regular unsubscribe page (GET)
        one_click_url: URL for the one-click POST endpoint
        
    Returns:
        dict: Headers to include in the email
    """
    if not unsubscribe_url:
        return {}
    
    return {
        # List-Unsubscribe can include both mailto: and https: URLs
        # We provide the HTTPS URL for the unsubscribe page
        'List-Unsubscribe': f'<{unsubscribe_url}>',
        # List-Unsubscribe-Post enables one-click unsubscribe
        # The value tells the email client what to POST
        'List-Unsubscribe-Post': 'List-Unsubscribe=One-Click',
    }


@api_bp.route('/verify/request', methods=['POST'])
def request_verification_token():
    """Issue a verification token for confirming email ownership."""
    try:
        data = request.get_json() or {}
        email = data.get('email')
        if not email:
            return jsonify({'error': 'email is required'}), 400
        # 48 hours TTL for verification
        tok = _create_email_token(email=email, purpose='verify', ttl_minutes=60 * 24 * 2)
        db.session.commit()
        return jsonify({'message': 'Verification token created', 'token': tok.token, 'expires_at': tok.expires_at.isoformat()})
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/verify/<token>', methods=['POST'])
def verify_email_token(token: str):
    """Mark verification token as used; handles generic verification and subscription confirmation."""
    try:
        row = EmailToken.query.filter_by(token=token).first()
        if not row or not row.is_valid():
            return jsonify({'error': 'invalid or expired token'}), 400

        purpose = (row.purpose or '').strip().lower()
        if purpose == 'subscribe_confirm':
            meta = {}
            try:
                meta = json.loads(row.metadata_json or '{}')
            except Exception:
                meta = {}
            team_ids_raw = meta.get('team_ids') or []
            preferred_frequency = meta.get('preferred_frequency', 'weekly')
            try:
                team_ids = [int(tid) for tid in team_ids_raw]
            except Exception:
                team_ids = []
            if not team_ids:
                return jsonify({'error': 'Token metadata missing team ids'}), 400
            result = _activate_subscriptions(row.email, team_ids, preferred_frequency)
            row.used_at = datetime.now(timezone.utc)
            db.session.commit()
            status = 201 if result['created_count'] else 200
            return jsonify({
                'message': 'Subscriptions confirmed',
                'email': row.email,
                **result,
            }), status

        if purpose == 'verify':
            row.used_at = datetime.now(timezone.utc)
            db.session.commit()
            return jsonify({'message': 'Email verified', 'email': row.email})

        return jsonify({'error': f'Unsupported token purpose: {purpose or "unknown"}'}), 400
    except Exception as e:
        try:
            db.session.rollback()
        except Exception:
            pass
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/subscriptions/<int:subscription_id>', methods=['DELETE'])
def delete_subscription(subscription_id):
    """Unsubscribe from newsletter."""
    try:
        subscription = UserSubscription.query.get_or_404(subscription_id)
        subscription.active = False
        db.session.commit()
        
        return jsonify({'message': 'Unsubscribed successfully'})
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

# Statistics endpoints
@api_bp.route('/stats/overview', methods=['GET'])
def get_overview_stats():
    """Get overview statistics."""
    try:
        # current_season e.g. "2025-26"; also have start-year
        current_season_slug = api_client.current_season
        season_start_year = api_client.current_season_start_year
        if not current_season_slug and season_start_year:
            current_season_slug = f"{season_start_year}-{str(season_start_year + 1)[-2:]}"

        # Distinct teams with active loans (use correct column name)
        teams_with_active_loans = (
            db.session.query(LoanedPlayer.primary_team_id)
            .filter(LoanedPlayer.is_active.is_(True))
            .distinct()
            .count()
        )

        season_loans_count = 0
        if current_season_slug:
            season_loans_count = LoanedPlayer.query.filter(
                LoanedPlayer.window_key.like(f"{current_season_slug}%")
            ).count()

        # Count unique teams (deduplicated by team_id) to avoid counting same team across seasons
        unique_team_count = (
            db.session.query(db.func.count(db.func.distinct(Team.team_id)))
            .filter(Team.is_active.is_(True))
            .scalar() or 0
        )

        stats = {
            'total_teams': unique_team_count,
            'european_leagues': League.query.filter_by(is_european_top_league=True).count(),
            'total_active_loans': LoanedPlayer.query.filter_by(is_active=True).count(),
            'season_loans': season_loans_count,
            'early_terminations': 0,
            'teams_with_loans': teams_with_active_loans,
            'total_subscriptions': UserSubscription.query.filter_by(active=True).count() if hasattr(UserSubscription, 'active') else UserSubscription.query.count(),
            'total_newsletters': Newsletter.query.filter_by(published=True).count(),
            'current_season': current_season_slug
        }
        return jsonify(stats)
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/stats/loans', methods=['GET'])
def get_loan_stats():
    """Get detailed loan statistics."""
    try:
        current_season_slug = api_client.current_season
        season_start_year = api_client.current_season_start_year
        if not current_season_slug and season_start_year:
            current_season_slug = f"{season_start_year}-{str(season_start_year + 1)[-2:]}"

        base_q = LoanedPlayer.query
        if current_season_slug:
            base_q = base_q.filter(LoanedPlayer.window_key.like(f"{current_season_slug}%"))

        total_season = base_q.count()
        active = base_q.filter(LoanedPlayer.is_active.is_(True)).count()
        completed = base_q.filter(LoanedPlayer.is_active.is_(False)).count()

        stats = {
            'current_season': current_season_slug,
            'loan_types': [],
            'termination_reasons': [],
            'total_season_loans': total_season,
            'active_loans': active,
            'completed_loans': completed,
            'early_terminations': 0
        }
        
        return jsonify(stats)
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

# Data sync endpoints
@api_bp.route('/init-data', methods=['POST'])
def init_data():
    """Initialize sample data."""
    try:
        # This would normally sync from API-Football
        # For now, just return success
        return jsonify({
            'message': 'Data initialized successfully',
            'teams_synced': Team.query.count(),
            'leagues_synced': League.query.count()
        })
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/sync-leagues', methods=['POST'])
@require_api_key
def sync_leagues():
    """Sync European leagues from API-Football."""
    try:
        # Use current season for league sync (league metadata doesn't change much)
        season = api_client.current_season_start_year
        leagues_data = api_client.get_european_leagues(season)
        synced_count = 0
        
        for league_data in leagues_data:
            league_info = league_data.get('league', {})
            country_info = league_data.get('country', {})
            seasons = league_data.get('seasons', [])
            current_season = next((s for s in seasons if s.get('current')), seasons[0] if seasons else {})
            
            # Check if league exists
            existing = League.query.filter_by(league_id=league_info.get('id')).first()
            if existing:
                # Update existing league
                existing.name = league_info.get('name')
                existing.country = country_info.get('name')
                existing.season = current_season.get('year', api_client.current_season_start_year)
                existing.logo = league_info.get('logo')
            else:
                # Create new league
                league = League(
                    league_id=league_info.get('id'),
                    name=league_info.get('name'),
                    country=country_info.get('name'),
                    season=current_season.get('year', api_client.current_season_start_year),
                    is_european_top_league=True,
                    logo=league_info.get('logo')
                )
                db.session.add(league)
            
            synced_count += 1
        
        db.session.commit()
        return jsonify({
            'message': f'Successfully synced {synced_count} European leagues',
            'synced_leagues': synced_count,
            'current_season': api_client.current_season
        })
        
    except Exception as e:
        logger.error(f"Error syncing leagues: {e}")
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/sync-teams/<int:season>', methods=['POST'])
@require_api_key
def sync_teams(season):
    """Sync teams from API-Football."""
    try:
        # season is provided as path parameter by Flask
        if not season:
            return jsonify({'error': 'Season parameter is required'}), 400
            
        # Get all European teams
        all_teams = api_client.get_all_european_teams(season)
        synced_count = 0
        
        for team_data in all_teams:
            team_info = team_data.get('team', {})
            league_info = team_data.get('league_info', {})
            
            # Find the league
            league = League.query.filter_by(league_id=league_info.get('id')).first()
            if not league:
                continue
            
            # Check if team exists for this season
            existing = Team.query.filter_by(team_id=team_info.get('id'), season=season).first()
            if existing:
                # Update existing team
                existing.name = team_info.get('name')
                existing.country = team_info.get('country')
                existing.founded = team_info.get('founded')
                existing.logo = team_info.get('logo')
                existing.league_id = league.id
            else:
                # Create new team for this season
                team = Team(
                    team_id=team_info.get('id'),
                    name=team_info.get('name'),
                    country=team_info.get('country'),
                    founded=team_info.get('founded'),
                    logo=team_info.get('logo'),
                    league_id=league.id,
                    season=season,
                    is_active=True
                )
                db.session.add(team)
            
            synced_count += 1
        
        db.session.commit()
        return jsonify({
            'message': f'Successfully synced {synced_count} teams from European leagues for season {season}',
            'synced_teams': synced_count,
            'season': season
        })
        
    except Exception as e:
        logger.error(f"Error syncing teams: {e}")
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

# Loan Detection Endpoints

@api_bp.route('/detect-loan-candidates', methods=['POST'])
@require_api_key
def detect_loan_candidates():
    """Detect players who appear in multiple teams (potential loans)."""
    try:
        data = request.get_json() or {}
        print(f'detect_loan_candidates data: {data}')
        season = int(request.json["season"])
        _sync_season(season=season)
        
        # Default to Top-5 European leagues as recommended
        league_ids = data.get('league_ids', [39, 140, 78, 135, 61])  
        
        logger.info(f"üîç Starting loan candidate detection for season {season}")
        
        # Use the new league-level crawler to detect multi-team players
        multi_team_dict = api_client.detect_multi_team_players(
            league_ids=league_ids, 
            season=season
        )

        loan_candidates = []
        processed_count = 0
        
        for player_id, team_ids in multi_team_dict.items():
            try:
                # Get player info - we need to fetch this separately now
                player_data = api_client.get_player_by_id(player_id)

                if not player_data or 'player' not in player_data:
                    logger.warning(f"Could not fetch player info for {player_id}")
                    continue
                player_info = player_data['player']

                # Analyze transfer data using the pre-computed multi-team data
                transfer_analysis = api_client.analyze_transfer_type(
                    player_id, 
                    multi_team_dict=multi_team_dict, 
                    season=season
                )

                # Create comprehensive candidate profile
                loan_candidate = {
                    'player_id': player_id,
                    'player_name': player_info.get('name'),
                    'team_ids': team_ids,
                    'team_count': len(team_ids),
                    'season': season,
                    'transfer_analysis': transfer_analysis,
                    'loan_confidence': transfer_analysis.get('loan_confidence', 0.5),
                    'is_likely_loan': transfer_analysis.get('is_likely_loan', False),
                    'indicators': transfer_analysis.get('indicators', []),
                    'needs_review': True,
                    'detected_at': datetime.now(timezone.utc).isoformat()
                }

                loan_candidates.append(loan_candidate)
                processed_count += 1
                
                # Update player record if it exists
                existing_player = LoanedPlayer.query.filter_by(player_id=player_id).first()
                if existing_player:
                    # Don't override existing manual settings, just flag for review
                    if not hasattr(existing_player, 'loan_review_needed'):
                        # Add a simple flag - you might want to add this field to your model
                        pass
                        
            except Exception as e:
                logger.warning(f"Error processing player {player_id}: {e}")
                continue
        
        logger.info(f"‚úÖ Detected {len(loan_candidates)} loan candidates")
        
        return jsonify({
            'message': f'Successfully detected {len(loan_candidates)} loan candidates',
            'candidates': loan_candidates,
            'total_candidates': len(loan_candidates),
            'season': season,
            'processed_players': processed_count
        })
        
    except Exception as e:
        logger.error(f"Error detecting loan candidates: {e}")
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/export-loan-candidates/csv', methods=['GET'])
@require_api_key
def export_loan_candidates_csv():
    """Export detected loan candidates to CSV for manual verification."""
    try:
        warnings = []
        
        window_key = request.args.get("window_key")
        confidence_threshold = float(request.args.get("confidence_threshold", 0.4))
        season = _sync_season(window_key=window_key)
        league_ids = request.args.getlist('league_ids', type=int)
        
        if not league_ids:
            league_ids = [39, 140, 78, 135, 61]  # Default to Top-5 European leagues
        
        # Extract season from window_key for consistent API calls  
        try:
            season = int(window_key.split("::")[0].split("-")[0])
            logger.info(f"üîç window {window_key} ‚Üí season {season}")
        except (ValueError, IndexError):
            season = api_client.current_season_start_year
            logger.warning(f"Failed to parse season from window_key '{window_key}', using default: {season}")
        
        logger.info(f"üìä Exporting loan candidates for window {window_key} (confidence ‚â• {confidence_threshold})")
        
        # Set API client season from window_key to ensure consistency
        api_client.set_season_from_window_key(window_key)
        
        # Prime team name cache for efficient lookups
        api_client._prime_team_cache(season)
        
        # Method 1: Get direct loan candidates from transfer data (bypasses confidence threshold)
        direct_loan_candidates = api_client.get_direct_loan_candidates(
            window_key, league_ids, season=season
        )
        
        # Method 2: Get multi-team players using the new window-based method
        multi_team_dict = api_client.detect_multi_team_players(
            league_ids, window_key, season=season
        )
        
        logger.info(f"üîç DEBUG: Found {len(direct_loan_candidates)} direct loan candidates and {len(multi_team_dict)} multi-team players for window {window_key}")
        
        candidates = []
        processed = 0
        
        # First, add all direct loan candidates (these have loan_confidence = 1.0)
        for player_id, loan_data in direct_loan_candidates.items():
            try:
                # Get player info
                player_data = api_client.get_player_by_id(player_id)
                if not player_data or 'player' not in player_data:
                    continue
                
                player_info = player_data['player']
                
                # Create candidate from direct loan data
                candidate = {
                    'player_id': player_id,
                    'player_name': player_info.get('name', 'Unknown'),
                    'age': player_info.get('age', ''),
                    'nationality': player_info.get('nationality', 'Unknown'),
                    'primary_team_id': loan_data.get('primary_team_id', ''),
                    'primary_team_name': loan_data.get('primary_team_name', 'Unknown'),
                    'loan_team_id': loan_data.get('loan_team_id', ''),
                    'loan_team_name': loan_data.get('loan_team_name', 'Unknown'),
                    'team_ids': loan_data.get('team_ids', ''),
                    'team_count': loan_data.get('team_count', 2),
                    'loan_confidence': loan_data.get('loan_confidence', 1.0),
                    'is_likely_loan': True,
                    'indicators': f"Direct loan transfer on {loan_data.get('transfer_date', 'unknown date')}",
                    'window_key': window_key,
                    'detected_at': datetime.now(timezone.utc).isoformat(),
                    # Fields for manual verification (empty for reviewer to fill)
                    'manual_verified': '',
                    'actual_loan_status': '',
                    'legacy_parent_team_id': '',  # Legacy field - keeping for backward compatibility
                    'legacy_loan_team_id': '',    # Legacy field - keeping for backward compatibility
                    'reviewer_notes': ''
                }
                candidates.append(candidate)
                processed += 1
                

                    
            except Exception as e:
                logger.warning(f"Error processing direct loan candidate {player_id}: {e}")
                continue
        
        # Second, process multi-team players that aren't already captured as direct loans
        direct_loan_player_ids = set(direct_loan_candidates.keys())
        
        for player_id, team_ids in multi_team_dict.items():
            # Skip players already processed as direct loans
            if player_id in direct_loan_player_ids:
                logger.debug(f"Skipping player {player_id} - already processed as direct loan")
                continue
                
            try:
                # Get player info
                player_data = api_client.get_player_by_id(player_id)
                if not player_data or 'player' not in player_data:
                    continue

                player_info = player_data['player']
                
                # Get transfer analysis using pre-computed multi-team data
                transfer_analysis = api_client.analyze_transfer_type(
                    player_id, 
                    multi_team_dict=multi_team_dict, 
                    window_key=window_key
                )
                
                loan_confidence = transfer_analysis.get('loan_confidence', 0.0)
                

                
                # Only include candidates above confidence threshold
                if loan_confidence >= confidence_threshold:
                    # Extract season year from window_key for team name lookup
                    try:
                        season_slug, _ = window_key.split("::")
                        season_year = int(season_slug.split("-")[0])
                    except (ValueError, AttributeError):
                        season_year = api_client.current_season_start_year
                    
                    # Split team IDs according to new schema: [loan_team_id, primary_team_id]
                    loan_team_id, primary_team_id = (team_ids + [None, None])[:2]
                    
                    # Get human-readable team names
                    primary_team_name = "Unknown"
                    loan_team_name = "Unknown"
                    
                    if primary_team_id:
                        primary_team_name = api_client.get_team_name(primary_team_id, season_year)
                    if loan_team_id:
                        loan_team_name = api_client.get_team_name(loan_team_id, season_year)
                    
                    candidate = {
                        'player_id': player_id,
                        'player_name': player_info.get('name', 'Unknown'),
                        'age': player_info.get('age', ''),
                        'nationality': player_info.get('nationality', 'Unknown'),
                        'primary_team_id': primary_team_id or '',
                        'primary_team_name': primary_team_name,
                        'loan_team_id': loan_team_id or '',
                        'loan_team_name': loan_team_name,
                        'team_ids': ','.join(map(str, team_ids)),  # Keep for backward compatibility
                        'team_count': len(team_ids),
                        'loan_confidence': round(loan_confidence, 3),
                        'is_likely_loan': transfer_analysis.get('is_likely_loan', False),
                        'indicators': ' | '.join(transfer_analysis.get('indicators', [])),
                        'window_key': window_key,
                        'detected_at': datetime.now(timezone.utc).isoformat(),
                        # Fields for manual verification (empty for reviewer to fill)
                        'manual_verified': '',
                        'actual_loan_status': '',  # 'loan', 'permanent', 'unknown'
                        'legacy_parent_team_id': '',  # Legacy field - keeping for backward compatibility
                        'legacy_loan_team_id': '',    # Legacy field - keeping for backward compatibility
                        'reviewer_notes': ''
                    }
                    
                    candidates.append(candidate)
                    processed += 1
                    
            except Exception as e:
                logger.warning(f"Error processing player {player_id}: {e}")
                continue
        
        # Sort by confidence (highest first)
        candidates.sort(key=lambda x: x['loan_confidence'], reverse=True)
        
        direct_loan_count = len(direct_loan_candidates)
        multi_team_processed = len(multi_team_dict) - len(direct_loan_player_ids)
        
        logger.info(f"üîç DEBUG: Final results - {len(candidates)} total candidates")
        logger.info(f"   - {direct_loan_count} direct loan transfers (confidence = 1.0)")
        logger.info(f"   - {len(candidates) - direct_loan_count} from multi-team analysis (‚â• {confidence_threshold} confidence)")
        logger.info(f"   - {multi_team_processed} multi-team players analyzed (excluding direct loans)")
        
        if not candidates:
            logger.warning(f"‚ùå No loan candidates found. Direct loans: {direct_loan_count}, Multi-team players: {len(multi_team_dict)}, Threshold: {confidence_threshold}")
            return jsonify({'message': 'No loan candidates found matching criteria'}), 404
        
        # Create CSV content
        output = io.StringIO()
        fieldnames = [
            'player_id','player_name','age','nationality',
            'primary_team_id','primary_team_name','loan_team_id','loan_team_name',
            'team_ids','team_count','loan_confidence','is_likely_loan',
            'indicators','window_key','detected_at',
            'manual_verified','actual_loan_status',
            'legacy_parent_team_id','legacy_loan_team_id','reviewer_notes'
        ]
        
        writer = csv.DictWriter(output, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(candidates)
        
        csv_content = output.getvalue()
        output.close()
        
        # Generate filename
        timestamp = datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')
        # Use window_key for filename but clean it up for filesystem compatibility
        window_safe = window_key.replace("::", "_")
        filename = f"loan_candidates_{window_safe}_{timestamp}.csv"
        
        logger.info(f"‚úÖ Exported {len(candidates)} loan candidates for {window_key} ({direct_loan_count} direct loans + {len(candidates) - direct_loan_count} multi-team)")
        
        response = make_response(
            csv_content,
            200,
            {
                'Content-Type': 'text/csv',
                'Content-Disposition': f'attachment; filename={filename}'
            }
        )
        
        # Add deprecation warning header if using legacy season parameter
        if warnings:
            response.headers['X-Deprecation-Warning'] = '; '.join(warnings)
        
        return response
        
    except Exception as e:
        logger.error(f"Error exporting loan candidates CSV: {e}")
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

# Newsletter rendering helpers
try:
    # Reuse lint/enrich if available via weekly agent
    from src.agents.weekly_agent import lint_and_enrich  # type: ignore
except Exception:
    def lint_and_enrich(x: dict) -> dict:  # fallback
        return x

def _load_newsletter_json(n: Newsletter) -> dict | None:
    try:
        raw = n.structured_content or n.content or "{}"
        data = json.loads(raw)
        if isinstance(data, dict):
            try:
                data = lint_and_enrich(data)
            except Exception:
                pass
            
            # Inject YouTube links from the junction table
            try:
                youtube_links = NewsletterPlayerYoutubeLink.query.filter_by(newsletter_id=n.id).all()
                if youtube_links:
                    # Create lookup dictionary by player_id
                    links_by_player_id = {}
                    
                    for link in youtube_links:
                        if link.player_id:
                            links_by_player_id[link.player_id] = link.youtube_link
                    
                    # Inject links into player items
                    sections = data.get('sections', [])
                    if isinstance(sections, list):
                        for section in sections:
                            if isinstance(section, dict):
                                items = section.get('items', [])
                                if isinstance(items, list):
                                    for item in items:
                                        if isinstance(item, dict):
                                            # Check for tracked player
                                            player_id = item.get('player_id')
                                            if player_id and player_id in links_by_player_id:
                                                youtube_url = links_by_player_id[player_id]
                                                # Add to links array
                                                existing_links = item.get('links', [])
                                                if not isinstance(existing_links, list):
                                                    existing_links = []
                                                # Add YouTube link with title
                                                youtube_link_obj = {
                                                    'url': youtube_url,
                                                    'title': 'YouTube Highlights'
                                                }
                                                # Check if not already present
                                                if not any(
                                                    (isinstance(l, dict) and l.get('url') == youtube_url) or 
                                                    (isinstance(l, str) and l == youtube_url)
                                                    for l in existing_links
                                                ):
                                                    existing_links.insert(0, youtube_link_obj)
                                                item['links'] = existing_links
            except Exception as e:
                logger.exception('Failed to inject YouTube links into newsletter')
                pass
            
            return data
        return None
    except Exception:
        return None

def _plain_text_from_news(data: dict, meta: Newsletter) -> str:
    team = meta.team.name if meta.team else ""
    title = data.get("title") or meta.title or "Weekly Loan Update"
    rng = data.get("range") or [None, None]
    summary = data.get("summary") or ""
    lines: list[str] = []
    lines.append(f"{title}")
    if team:
        lines.append(f"Team: {team}")
    if rng and rng[0] and rng[1]:
        lines.append(f"Week: {rng[0]} ‚Äì {rng[1]}")
    if summary:
        lines.append("")
        lines.append(summary)
    highlights = data.get("highlights") or []
    if highlights:
        lines.append("")
        lines.append("Highlights:")
        for h in highlights:
            lines.append(f"- {h}")
    for sec in (data.get("sections") or []):
        if not isinstance(sec, dict):
            continue
        st = sec.get("title") or ""
        items = sec.get("items") or []
        if st:
            lines.append("")
            lines.append(st)
            lines.append("-" * len(st))
        for it in items:
            if not isinstance(it, dict):
                continue
            pname = it.get("player_name") or ""
            loan_team = it.get("loan_team") or it.get("loan_team_name") or ""
            wsum = it.get("week_summary") or ""
            stats = it.get("stats") or {}
            stat_str = (
                f"{int(stats.get('minutes', 0))}‚Äô | "
                f"{int(stats.get('goals', 0))}G {int(stats.get('assists', 0))}A | "
                f"{int(stats.get('yellows', 0))}Y {int(stats.get('reds', 0))}R"
            )
            lines.append(f"‚Ä¢ {pname} ({loan_team}) ‚Äì {wsum}")
            lines.append(f"  {stat_str}")
            # Add graph URLs for markdown (Reddit)
            if it.get("rating_graph_url"):
                graph_url = _absolute_url(it["rating_graph_url"])
                lines.append(f"  üìä [Rating Graph]({graph_url})")
            if it.get("minutes_graph_url"):
                graph_url = _absolute_url(it["minutes_graph_url"])
                lines.append(f"  üìä [Minutes Graph]({graph_url})")
            notes = it.get("match_notes") or []
            for n in notes:
                lines.append(f"  - {n}")
    return "\n".join(lines).strip() + "\n"
def _newsletter_issue_slug(n: Newsletter) -> str:
    slug_value = getattr(n, 'public_slug', None)
    if slug_value:
        return slug_value
    slug_value = compose_newsletter_public_slug(
        team_name=n.team.name if n.team else None,
        newsletter_type=n.newsletter_type,
        week_start=n.week_start_date,
        week_end=n.week_end_date,
        issue_date=n.issue_date,
        identifier=n.id,
    )
    if slug_value:
        n.public_slug = slug_value
        return slug_value
    if n.week_end_date:
        return n.week_end_date.isoformat()
    if n.issue_date:
        return n.issue_date.isoformat()
    created = _as_utc(n.created_at) if n.created_at else datetime.now(timezone.utc)
    return created.date().isoformat()


def _public_base_url(default: str | None = None) -> str:
    base = (os.getenv('PUBLIC_BASE_URL') or os.getenv('PUBLIC_API_BASE_URL') or default or '').strip()
    if base:
        return base.rstrip('/')
    try:
        return (request.url_root or '').rstrip('/')
    except RuntimeError:
        return ''


def _absolute_url(path: str) -> str:
    if not path:
        return path
    if path.startswith('http://') or path.startswith('https://'):
        return path
    base = _public_base_url()
    if not base:
        return path
    normalized = path if path.startswith('/') else f'/{path}'
    return f'{base}{normalized}'


def _static_url(rel_path: str | None) -> str | None:
    if not rel_path:
        return None
    rel = rel_path.lstrip('/')
    return _absolute_url(f'/static/{rel}')


def _truncate_plain(text: str, limit: int = 200) -> str:
    clean = sanitize_plain_text(text or '')
    stripped = clean.strip()
    if len(stripped) <= limit:
        return stripped
    truncated = stripped[:limit - 1].rstrip()
    return f"{truncated}‚Ä¶"


def _brand_logo_source() -> str:
    override = (os.getenv('GO_ON_LOAN_LOGO_PATH') or '').strip()
    if override:
        return override
    return '/static/assets/loan_army_assets/android-chrome-512x512.png'


def _load_logo_image(source: str | None):
    if not source:
        return None
    try:
        from PIL import Image, ImageFile
    except ImportError:
        return None

    ImageFile.LOAD_TRUNCATED_IMAGES = True
    src = source.strip()
    if not src:
        return None

    try:
        if src.startswith(('http://', 'https://')):
            resp = requests.get(src, timeout=6)
            resp.raise_for_status()
            with BytesIO(resp.content) as buffer:
                with Image.open(buffer) as img:
                    return img.convert('RGBA')

        candidate_paths: list[str] = []
        static_folder = getattr(current_app, 'static_folder', None)

        if src.startswith('/static/') and static_folder:
            candidate_paths.append(os.path.join(static_folder, src[len('/static/') :]))
        if src.startswith('/') and static_folder:
            candidate_paths.append(os.path.join(static_folder, src.lstrip('/')))
        if os.path.isabs(src):
            candidate_paths.append(src)
        if static_folder and not os.path.isabs(src):
            candidate_paths.append(os.path.join(static_folder, src))

        for path in candidate_paths:
            if path and os.path.exists(path):
                with Image.open(path) as img:
                    return img.convert('RGBA')
    except Exception as exc:
        logger.debug('Failed to load logo image from %s: %s', source, exc, exc_info=True)
    return None


def _ensure_newsletter_cover_image(n: Newsletter, *, team_logo: str | None) -> str | None:
    static_folder = getattr(current_app, 'static_folder', None)
    if not static_folder:
        return None

    slug = _newsletter_issue_slug(n)
    rel_dir = os.path.join('newsletters', slug)
    target_dir = os.path.join(static_folder, rel_dir)
    os.makedirs(target_dir, exist_ok=True)

    filename = 'cover.jpg'
    target_path = os.path.join(target_dir, filename)
    if os.path.isfile(target_path):
        return os.path.join(rel_dir, filename)

    try:
        from PIL import Image, ImageDraw, ImageOps
    except ImportError:
        logger.warning('Pillow not installed; falling back to static cover copy')
        fallback_src = _brand_logo_source()
        static_folder = getattr(current_app, 'static_folder', None)
        candidate = None
        if fallback_src.startswith('/static/') and static_folder:
            candidate = os.path.join(static_folder, fallback_src[len('/static/'):])
        elif os.path.isabs(fallback_src):
            candidate = fallback_src
        elif static_folder:
            candidate = os.path.join(static_folder, fallback_src)
        if candidate and os.path.exists(candidate):
            try:
                shutil.copyfile(candidate, target_path)
                return os.path.join(rel_dir, filename)
            except Exception as exc:
                logger.warning('Failed to copy fallback cover %s -> %s: %s', candidate, target_path, exc)
        return None

    canvas = Image.new('RGB', (1200, 630), '#050A1E')
    draw = ImageDraw.Draw(canvas)

    brand_logo = _load_logo_image(_brand_logo_source())
    primary_logo = _load_logo_image(team_logo)

    logos = [logo for logo in (primary_logo, brand_logo) if logo is not None]
    if not logos:
        draw.rectangle([(0, 0), (canvas.width, canvas.height)], fill='#101942')
        draw.rectangle([(80, 120), (canvas.width - 80, canvas.height - 120)], outline='#23306b', width=12)
    else:
        processed: list[Image.Image | None] = []
        for logo in (primary_logo, brand_logo):
            if logo is None:
                processed.append(None)
                continue
            img = logo.copy()
            img = ImageOps.contain(img, (420, 420))
            processed.append(img)

        spacing = 120
        centre_y = canvas.height // 2

        if processed[0] is not None and len(processed) > 1 and processed[1] is not None:
            total_width = processed[0].width + processed[1].width + spacing
            start_x = max((canvas.width - total_width) // 2, 60)
            positions = [
                (start_x, centre_y - processed[0].height // 2),
                (start_x + processed[0].width + spacing, centre_y - processed[1].height // 2),
            ]
            active = [processed[0], processed[1]]
        else:
            existing = processed[0] or (processed[1] if len(processed) > 1 else None)
            if existing is None:
                existing = logos[0]
            positions = [((canvas.width - existing.width) // 2, centre_y - existing.height // 2)]
            active = [existing]

        draw.ellipse([(-320, -80), (canvas.width * 0.8, canvas.height + 180)], fill='#0C1544', outline=None)
        draw.rectangle([(0, canvas.height - 90), (canvas.width, canvas.height)], fill='#131C4E')

        for img, (pos_x, pos_y) in zip(active, positions, strict=False):
            if img is None:
                continue
            rgba = img.convert('RGBA')
            canvas.paste(rgba, (int(pos_x), int(pos_y)), mask=rgba)

    try:
        canvas.save(target_path, format='JPEG', quality=92, optimize=True)
        return os.path.join(rel_dir, filename)
    except Exception as exc:
        logger.warning('Failed to write newsletter cover %s: %s', target_path, exc)
        return None


def _format_iso8601(dt: datetime | None) -> str | None:
    if not dt:
        return None
    as_utc = _as_utc(dt)
    if not as_utc:
        return None
    trimmed = as_utc.replace(microsecond=0)
    iso = trimmed.isoformat()
    if iso.endswith('+00:00'):
        iso = iso[:-6] + 'Z'
    return iso


def _compute_newsletter_social_meta(n: Newsletter, context: dict[str, Any]) -> dict[str, Any]:
    title = context.get('title') or n.title or 'Weekly Loan Update'
    description = context.get('summary') or ''
    description = _truncate_plain(description)
    if not description:
        team_name = context.get('team_name') or (n.team.name if n.team else 'The Academy Watch')
        description = f'{team_name} weekly loan watch from The Academy Watch.'

    canonical_slug = _newsletter_issue_slug(n)
    canonical_url = _absolute_url(f'/newsletters/{canonical_slug}')

    team_logo = context.get('team_logo')
    cover_rel = _ensure_newsletter_cover_image(n, team_logo=team_logo)
    cover_url = _static_url(cover_rel)

    if n.published_date:
        published = _format_iso8601(n.published_date)
    elif n.issue_date:
        published_dt = datetime.combine(n.issue_date, datetime.min.time(), tzinfo=timezone.utc) + timedelta(hours=10)
        published = _format_iso8601(published_dt)
    else:
        published = None

    site_name = (os.getenv('SITE_NAME') or os.getenv('PUBLIC_SITE_NAME') or 'The Academy Watch').strip() or 'The Academy Watch'
    author = (os.getenv('ARTICLE_AUTHOR_NAME') or site_name).strip() or site_name
    twitter_handle = (os.getenv('TWITTER_HANDLE') or '@goonloan').strip()

    return {
        'title': title,
        'description': description,
        'canonical_url': canonical_url,
        'slug': canonical_slug,
        'og_url': canonical_url,
        'og_image': cover_url,
        'og_image_width': '1200' if cover_url else None,
        'og_image_height': '630' if cover_url else None,
        'site_name': site_name,
        'article_author': author,
        'published_time': published,
        'twitter_handle': twitter_handle if twitter_handle else None,
    }

# --- Newsletter delivery helpers ---
def _embed_image(path):
    if not path: return ''
    if path.startswith('/static/'):
        try:
            clean_path = path.replace('/static/', '', 1)
            real_path = os.path.join(current_app.static_folder, clean_path)
            if os.path.exists(real_path):
                with open(real_path, "rb") as f:
                    encoded = base64.b64encode(f.read()).decode('utf-8')
                    return f"data:image/png;base64,{encoded}"
        except Exception as e:
            logging.error(f"Failed to embed image {path}: {e}")
    return path

def _collect_commentaries_for_newsletter(n: Newsletter) -> list[NewsletterCommentary]:
    """Return all active commentaries associated with a newsletter, including
    week-scoped entries whose newsletter_id may be null. Deduplicates by id."""
    seen: dict[int, NewsletterCommentary] = {}

    def _add(c: NewsletterCommentary | None):
        if not c or not getattr(c, 'is_active', False):
            return
        if c.id not in seen:
            seen[c.id] = c

    # Directly linked commentaries (relationship + explicit query for safety)
    for c in getattr(n, 'commentaries', []) or []:
        _add(c)
    if n.id:
        for c in NewsletterCommentary.query.filter_by(newsletter_id=n.id, is_active=True).all():
            _add(c)

    # Week-scoped commentaries by API team id (cross-season compatibility)
    api_team_id = None
    team_db_id = n.team_id
    if team_db_id:
        api_team_id = db.session.query(Team.team_id).filter(Team.id == team_db_id).scalar()

    if n.week_start_date and n.week_end_date:
        # Primary: join on API team id
        if api_team_id:
            rows = (
                NewsletterCommentary.query.join(Team)
                .filter(
                    Team.team_id == api_team_id,
                    NewsletterCommentary.week_start_date == n.week_start_date,
                    NewsletterCommentary.week_end_date == n.week_end_date,
                    NewsletterCommentary.is_active.is_(True)
                )
                .order_by(NewsletterCommentary.position.asc(), NewsletterCommentary.created_at.asc())
                .all()
            )
            for c in rows:
                _add(c)

        # Fallback: match by DB team_id when join data is missing (older rows)
        if team_db_id:
            rows = (
                NewsletterCommentary.query
                .filter(
                    NewsletterCommentary.team_id == team_db_id,
                    NewsletterCommentary.week_start_date == n.week_start_date,
                    NewsletterCommentary.week_end_date == n.week_end_date,
                    NewsletterCommentary.is_active.is_(True)
                )
                .order_by(NewsletterCommentary.position.asc(), NewsletterCommentary.created_at.asc())
                .all()
            )
            for c in rows:
                _add(c)

    # Stable ordering for presentation
    type_order = {'intro': 0, 'player': 1, 'summary': 2}
    commentaries = list(seen.values())
    commentaries.sort(key=lambda c: (
        type_order.get(getattr(c, 'commentary_type', ''), 99),
        getattr(c, 'position', 0) or 0,
        getattr(c, 'created_at', datetime.min) or datetime.min,
    ))
    return commentaries


def _newsletter_render_context(n: Newsletter) -> dict[str, Any]:
    data = _load_newsletter_json(n) or {}
    team_logo = data.get('team_logo')
    if not team_logo and n.team and getattr(n.team, 'logo', None):
        team_logo = n.team.logo

    # Generate web URL for newsletter
    canonical_slug = _newsletter_issue_slug(n)
    web_url = _absolute_url(f'/newsletters/{canonical_slug}')

    commentaries = _collect_commentaries_for_newsletter(n)
    intro_commentary = []
    summary_commentary = []
    player_commentary_map = {}

    for c in commentaries:
        if c.commentary_type == 'intro':
            intro_commentary.append(c.to_dict())
        elif c.commentary_type == 'summary':
            summary_commentary.append(c.to_dict())
        elif c.commentary_type == 'player' and c.player_id:
            player_commentary_map.setdefault(c.player_id, []).append(c.to_dict())

    # Buy Me a Coffee button URL - use official CDN image
    bmc_button_url = 'https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png'

    # Public base URL for player links in emails
    public_base_url = os.getenv('PUBLIC_BASE_URL', '').rstrip('/')

    # Fetch approved community takes for this newsletter
    community_takes = []
    takes_query = CommunityTake.query.filter_by(status='approved')
    if n.id:
        # First, get takes explicitly linked to this newsletter
        newsletter_takes = takes_query.filter_by(newsletter_id=n.id).all()
        community_takes.extend([t.to_dict() for t in newsletter_takes])

    # Also get takes linked to the team (if any) that aren't newsletter-specific
    if n.team_id and not community_takes:
        team_takes = takes_query.filter_by(team_id=n.team_id, newsletter_id=None).order_by(
            CommunityTake.created_at.desc()
        ).limit(5).all()
        community_takes.extend([t.to_dict() for t in team_takes])

    # Submit take URL for footer
    submit_take_url = f"{public_base_url}/submit-take" if public_base_url else None

    # Fetch academy appearances for players in this newsletter's date range
    academy_appearances = []
    if n.week_start_date and n.week_end_date:
        # Get players tracked for this team
        tracked_players = LoanedPlayer.query.filter(
            LoanedPlayer.is_active == True,
            LoanedPlayer.parent_team_id == n.team_id,
            LoanedPlayer.pathway_status == 'academy',
        ).all()

        if tracked_players:
            player_api_ids = [p.player_api_id for p in tracked_players if p.player_api_id]
            if player_api_ids:
                appearances = AcademyAppearance.query.filter(
                    AcademyAppearance.player_id.in_(player_api_ids),
                    AcademyAppearance.fixture_date >= n.week_start_date,
                    AcademyAppearance.fixture_date <= n.week_end_date,
                ).order_by(AcademyAppearance.fixture_date.desc()).all()
                academy_appearances = [a.to_dict() for a in appearances]

    context: dict[str, Any] = {
        'embed_image': _embed_image,
        'meta': n,
        'team_name': n.team.name if n.team else '',
        'title': data.get('title') or n.title,
        'range': data.get('range'),
        'summary': data.get('summary'),
        'highlights': data.get('highlights') or [],
        'sections': data.get('sections') or [],
        'by_numbers': data.get('by_numbers') or {},
        'fan_pulse': data.get('fan_pulse') or [],
        'team_logo': team_logo,
        'web_url': web_url,
        'public_slug': canonical_slug,
        'public_base_url': public_base_url,
        'intro_commentary': intro_commentary,
        'summary_commentary': summary_commentary,
        'player_commentary_map': player_commentary_map,
        'bmc_button_url': bmc_button_url,
        'community_takes': community_takes,
        'submit_take_url': submit_take_url,
        'academy_appearances': academy_appearances,
    }
    context['social_meta'] = _compute_newsletter_social_meta(n, context)
    return context

def _deliver_newsletter_via_webhook(
    n: Newsletter,
    *,
    recipients: list[str] | None = None,
    subject_override: str | None = None,
    webhook_url_override: str | None = None,
    http_method_override: str | None = None,
    dry_run: bool = False,
) -> dict:
    """Render newsletter to HTML/TXT and send via email service.
    Returns dict with 'status', 'http_status', and 'recipient_count'.
    
    Note: webhook_url_override and http_method_override are kept for backward
    compatibility but are ignored when using the direct email service.
    """
    # Check email service is configured
    if not email_service.is_configured():
        raise RuntimeError('Email service is not configured (set MAILGUN_* or SMTP_* env vars)')

    team_ids: list[int] = []
    if n.team_id:
        try:
            team_ids.append(int(n.team_id))
        except (TypeError, ValueError):
            pass

    team_api_id = None
    if getattr(n, 'team', None) is not None:
        team_api_id = getattr(n.team, 'team_id', None)
    if team_api_id is None and n.team_id:
        try:
            team_row = Team.query.with_entities(Team.team_id).filter(Team.id == n.team_id).first()
            if team_row:
                team_api_id = team_row[0]
        except Exception:
            team_api_id = None

    if team_api_id is not None:
        try:
            alt_ids = (
                Team.query.with_entities(Team.id)
                .filter(Team.team_id == team_api_id)
                .all()
            )
            team_ids.extend(int(row[0]) for row in alt_ids if row and row[0])
        except Exception:
            pass

    team_ids = list(dict.fromkeys(team_ids))

    if team_ids:
        subs = (
            UserSubscription.query
            .filter(UserSubscription.active.is_(True))
            .filter(UserSubscription.team_id.in_(team_ids))
            .all()
        )
    else:
        subs = []

    def _normalize_email(value: str | None) -> str:
        return (value or '').strip().lower()

    sub_lookup: dict[str, UserSubscription] = {}
    ordered_sub_emails: list[str] = []
    for s in subs:
        if s.email_bounced:
            continue
        raw_email = (s.email or '').strip()
        key = _normalize_email(raw_email)
        if not raw_email or not key:
            continue
        if key not in sub_lookup:
            sub_lookup[key] = s
            ordered_sub_emails.append(raw_email)

    # Gather recipients from active team subscriptions if not provided
    if recipients is None:
        recipients = ordered_sub_emails

    recipients = [r for r in (recipients or []) if (r or '').strip()]
    total_recipients = len(recipients)
    if total_recipients == 0:
        return {
            'status': 'no_recipients',
            'http_status': None,
            'recipient_count': 0,
            'provider': 'none',
            'response_text': '',
        }

    # Render content
    ctx = _newsletter_render_context(n)
    text_base = _plain_text_from_news(_load_newsletter_json(n) or {}, n)
    subject = subject_override or (ctx['title'] or 'Weekly Loan Update')

    from_addr = {
        'name': os.getenv('EMAIL_FROM_NAME', 'The Academy Watch'),
        'email': os.getenv('EMAIL_FROM_ADDRESS', 'no-reply@loan.army'),
    }

    # Optional public base URL for manage/unsubscribe links if the n8n flow uses it
    public_base = os.getenv('PUBLIC_BASE_URL', '').rstrip('/')
    link_base = os.getenv('NEWSLETTER_LINK_BASE_URL', '').rstrip('/')
    unsubscribe_base = (
        link_base
        or os.getenv('PUBLIC_UNSUBSCRIBE_BASE_URL', '').rstrip('/')
        or os.getenv('PUBLIC_API_BASE_URL', '').rstrip('/')
        or public_base
    )
    manage_url = _public_manage_url()

    meta_base = {
        'issue_date': n.issue_date.isoformat() if n.issue_date else None,
        'week_start': n.week_start_date.isoformat() if n.week_start_date else None,
        'week_end': n.week_end_date.isoformat() if n.week_end_date else None,
        'public_base_url': public_base or None,
        'dry_run': bool(dry_run),
    }

    delivered_count = 0
    digest_queued_count = 0
    failures: list[dict[str, Any]] = []
    last_status_code: int | None = None
    last_response_text = ''
    last_provider = 'none'

    # Import digest queue function
    from src.services.newsletter_deadline_service import queue_newsletter_for_digest

    for email in recipients:
        normalized_email = _normalize_email(email)
        subscription = sub_lookup.get(normalized_email)
        
        # Check if user prefers digest delivery
        user_account = UserAccount.query.filter_by(email=normalized_email).first()
        user_prefers_digest = (
            user_account 
            and getattr(user_account, 'email_delivery_preference', 'individual') == 'digest'
        )
        
        # If user prefers digest, queue instead of sending immediately
        if user_prefers_digest and user_account:
            try:
                queued = queue_newsletter_for_digest(user_account.id, n.id)
                if queued:
                    digest_queued_count += 1
                    logger.info(f"Queued newsletter {n.id} for digest delivery to {email}")
                else:
                    logger.debug(f"Newsletter {n.id} already queued for {email}")
                continue  # Skip sending individual email
            except Exception as queue_err:
                logger.warning(f"Failed to queue for digest, falling back to individual: {queue_err}")
                # Fall through to send individual email
        
        unsubscribe_url = None
        one_click_url = None
        email_headers = {}
        
        if subscription and subscription.unsubscribe_token:
            token = subscription.unsubscribe_token
            # Regular unsubscribe page (for link in email body)
            token_path = f"/subscriptions/unsubscribe/{token}"
            if unsubscribe_base:
                unsubscribe_url = f"{unsubscribe_base.rstrip('/')}{token_path}"
            else:
                unsubscribe_url = token_path
            
            # One-click unsubscribe endpoint (for RFC 8058 / List-Unsubscribe-Post header)
            one_click_path = f"/api/subscriptions/one-click-unsubscribe/{token}"
            if unsubscribe_base:
                one_click_url = f"{unsubscribe_base.rstrip('/')}{one_click_path}"
            
            # Build RFC 8058 compliant headers for email providers
            if one_click_url:
                email_headers = _build_unsubscribe_headers(unsubscribe_url, one_click_url)

        html = render_template(
            'newsletter_email.html',
            **ctx,
            unsubscribe_url=unsubscribe_url,
            manage_url=manage_url,
        )

        text = text_base
        if unsubscribe_url:
            text = f"{text_base}\n\nTo unsubscribe from this team, visit: {unsubscribe_url}\n"

        # Send via email service
        try:
            result = email_service.send_email(
                to=email,
                subject=subject,
                html=html,
                text=text,
                from_name=from_addr['name'],
                from_email=from_addr['email'],
                tags=['newsletter', f'newsletter_{n.id}'],
            )
            last_status_code = result.http_status or (200 if result.success else 500)
            last_response_text = result.message_id or result.error or ''
            last_provider = result.provider
            
            if result.success:
                delivered_count += 1
            else:
                failures.append({
                    'email': email,
                    'error': result.error,
                    'http_status': last_status_code,
                    'provider': result.provider,
                })
        except Exception as exc:
            last_status_code = 500
            last_response_text = str(exc)[:5000]
            last_provider = 'error'
            failures.append({
                'email': email,
                'error': str(exc),
                'http_status': last_status_code,
            })

    # Calculate status including digest queued
    total_processed = delivered_count + digest_queued_count
    status = 'ok' if total_processed == total_recipients else ('partial' if total_processed else 'error')
    result: dict[str, Any] = {
        'status': status,
        'http_status': last_status_code,
        'recipient_count': total_recipients,
        'delivered_count': delivered_count,
        'digest_queued_count': digest_queued_count,
        'provider': last_provider,
        'response_text': last_response_text,
    }
    if failures:
        result['failures'] = failures
    return result

@api_bp.route('/newsletters/<int:newsletter_id>/preview', methods=['POST'])
@require_api_key
def preview_newsletter_custom(newsletter_id: int):
    try:
        newsletter = Newsletter.query.get_or_404(newsletter_id)
        
        # Ensure we reload fresh content if structured_content is available
        data = _load_newsletter_json(newsletter) or {}
        
        # Determine active commentaries based on request
        payload = request.get_json() or {}
        journalist_ids = payload.get('journalist_ids')
        render_mode = payload.get('render_mode', 'web')  # 'web' or 'email'
        use_snippets = payload.get('use_snippets', False)
        
        # Fetch commentaries using week-based query with API Team ID (cross-season compatible)
        commentaries = []
        if newsletter.team_id and newsletter.week_start_date and newsletter.week_end_date:
            # Get the API Team ID for cross-season compatibility
            api_team_id = db.session.query(Team.team_id).filter(Team.id == newsletter.team_id).scalar()
            
            if api_team_id:
                # Query commentaries by API Team ID and week dates
                query = NewsletterCommentary.query.join(Team).filter(
                    Team.team_id == api_team_id,
                    NewsletterCommentary.week_start_date == newsletter.week_start_date,
                    NewsletterCommentary.week_end_date == newsletter.week_end_date,
                    NewsletterCommentary.is_active == True
                )
                
                # Apply journalist filtering if specified
                if journalist_ids is not None:
                    if not isinstance(journalist_ids, list):
                        journalist_ids = []
                    if len(journalist_ids) > 0:
                        query = query.filter(NewsletterCommentary.author_id.in_(journalist_ids))
                    else:
                        # Empty list means show no commentaries (unsubscribed simulation)
                        commentaries = []
                        query = None
                
                if query is not None:
                    commentaries = query.all()
                    print(f"[PREVIEW DEBUG] Found {len(commentaries)} commentaries for team API ID {api_team_id}, week {newsletter.week_start_date} to {newsletter.week_end_date}")
                    for c in commentaries:
                        print(f"  - Commentary ID {c.id}: type={c.commentary_type}, player_id={c.player_id}, author={c.author_name}")
        
        print(f"[PREVIEW DEBUG] Final commentary count after filtering: {len(commentaries)}, journalist_ids filter: {journalist_ids}")
        
        # Render
        from src.agents.weekly_agent import _render_variants_custom
        
        variants = _render_variants_custom(
            news=data,
            team_name=newsletter.team.name if newsletter.team else None,
            commentaries=commentaries,
            use_snippets=use_snippets,
            render_mode=render_mode
        )
        
        return jsonify({
            'html': variants.get(f'{render_mode}_html', ''),
            'meta': {
                'journalist_count': len(commentaries),
                'mode': render_mode,
                'snippets': use_snippets
            }
        })

    except Exception as e:
        logger.exception('Preview rendering failed')
        return jsonify(_safe_error_payload(e, 'Preview generation failed')), 500

@api_bp.route('/newsletters/<int:newsletter_id>/render.<fmt>', methods=['GET'])
@require_api_key
def render_newsletter(newsletter_id: int, fmt: str):
    try:
        n = Newsletter.query.get_or_404(newsletter_id)
        data = _load_newsletter_json(n) or {}
        context = _newsletter_render_context(n)
        if fmt in ('html', 'web'):
            html = render_template('newsletter_web.html', **context)
            return Response(html, mimetype='text/html')
        if fmt in ('email', 'email.html'):
            html = render_template('newsletter_email.html', **context)
            return Response(html, mimetype='text/html')
        if fmt in ('txt', 'text'):
            text = _plain_text_from_news(data, n)
            return Response(text, mimetype='text/plain; charset=utf-8')
        return jsonify({'error': 'Unsupported format. Use html, email, or text'}), 400
    except Exception as e:
        logger.exception('Error rendering newsletter')
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/newsletters/<int:newsletter_id>/send', methods=['POST'])
@require_api_key
def send_newsletter(newsletter_id: int):
    """Send a newsletter via n8n webhook.
    Body options:
      - test_to: string or list of emails (optional). If provided, bypasses published check and does not mark as sent.
      - subject: override subject (optional)
      - webhook_url: override webhook URL (optional)
      - dry_run: bool, forward to webhook (optional)
    """
    try:
        n = Newsletter.query.get_or_404(newsletter_id)
        payload = request.get_json(silent=True) or {}
        test_to = payload.get('test_to')
        subject_override = payload.get('subject')
        webhook_override = payload.get('webhook_url')
        dry_run = bool(payload.get('dry_run'))

        recipients: list[str] | None = None
        is_test = False
        admin_preview = False
        if test_to:
            if isinstance(test_to, str):
                sentinel = test_to.strip().lower()
                if sentinel in {'__admins__', '__admin__', 'admins'}:
                    recipients = _admin_email_list()
                    if not recipients:
                        return jsonify({
                            'error': 'admin_emails_not_configured',
                            'message': 'Set ADMIN_EMAILS to a comma-separated list before sending admin previews.',
                        }), 400
                    admin_preview = True
                else:
                    recipients = [test_to]
                is_test = True
            elif isinstance(test_to, list):
                recipients = [str(x) for x in test_to if str(x).strip()]
                is_test = True
            else:
                return jsonify({'error': 'test_to must be string or list of strings'}), 400

        if not is_test:
            # Require published before full send
            if not n.published:
                return jsonify({'error': 'newsletter must be published/approved before sending'}), 400
            if n.email_sent:
                return jsonify({'error': 'newsletter already sent'}), 400

        if recipients is not None:
            deduped: list[str] = []
            seen: set[str] = set()
            for email in recipients:
                cleaned = (email or '').strip()
                key = cleaned.lower()
                if cleaned and key not in seen:
                    seen.add(key)
                    deduped.append(cleaned)
            recipients = deduped

        # Deliver
        out = _deliver_newsletter_via_webhook(
            n,
            recipients=recipients,  # None => fetch active subscribers
            subject_override=subject_override,
            webhook_url_override=webhook_override,
            dry_run=dry_run,
        )

        if admin_preview:
            try:
                _append_run_history({
                    'kind': 'newsletter-admin-test-send',
                    'newsletter_id': n.id,
                    'team_id': n.team_id,
                    'status': out.get('status'),
                    'http_status': out.get('http_status'),
                    'recipient_count': out.get('recipient_count'),
                    'delivered_count': out.get('delivered_count'),
                    'admin_recipients': recipients,
                    'dry_run': bool(dry_run),
                    'run_by': getattr(g, 'user_email', None),
                })
            except Exception:
                pass

        # Mark sent only for non-test ok runs
        if out.get('status') == 'ok' and not is_test:
            from datetime import datetime as _dt, timezone as _tz
            # Count recipients used
            if recipients is None:
                subs = UserSubscription.query.filter_by(team_id=n.team_id, active=True).all()
                valid_subs = [s for s in subs if (s.email or '').strip() and not s.email_bounced]
                used_count = len(valid_subs)
            else:
                used_count = len(recipients)
            n.email_sent = True
            n.email_sent_date = _dt.now(_tz.utc)
            n.subscriber_count = used_count
            # Update last_email_sent for subscriptions we attempted to deliver
            try:
                ts = n.email_sent_date
                if recipients is None:
                    for s in valid_subs:
                        s.last_email_sent = ts
                else:
                    # Update only those included in recipients list
                    recip_set = set(recipients)
                    subs_sel = UserSubscription.query.filter_by(team_id=n.team_id, active=True).all()
                    for s in subs_sel:
                        if (s.email or '').strip() in recip_set:
                            s.last_email_sent = ts
            except Exception:
                pass
            db.session.commit()
        response_payload = {'newsletter_id': n.id, **out}
        if admin_preview:
            response_payload['admin_preview'] = True
            response_payload['admin_recipients'] = recipients
        return jsonify(response_payload)
    except Exception as e:
        logger.exception('send_newsletter failed')
        try:
            db.session.rollback()
        except Exception:
            pass
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500


@api_bp.route('/newsletters/<int:newsletter_id>', methods=['DELETE'])
@require_api_key
def delete_newsletter(newsletter_id: int):
    try:
        newsletter = Newsletter.query.get(newsletter_id)
        if not newsletter:
            return jsonify({'error': 'Newsletter not found'}), 404

        try:
            NewsletterComment.query.filter_by(newsletter_id=newsletter.id).delete(synchronize_session=False)
        except Exception:
            db.session.rollback()
            raise

        NewsletterDigestQueue.query.filter_by(newsletter_id=newsletter.id).delete(synchronize_session=False)

        Newsletter.query.filter_by(id=newsletter_id).delete(synchronize_session=False)
        db.session.commit()

        return jsonify({'status': 'deleted', 'newsletter_id': newsletter_id})
    except Exception as e:
        logger.exception('delete_newsletter failed')
        try:
            db.session.rollback()
        except Exception:
            pass
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500
@api_bp.route('/newsletters/latest/render.<fmt>', methods=['GET'])
@require_api_key
def render_latest_newsletter(fmt: str):
    try:
        team_id = request.args.get('team', type=int)
        if not team_id:
            return jsonify({'error': 'team query param required'}), 400
        n = (
            Newsletter.query
            .filter_by(team_id=team_id)
            .order_by(Newsletter.generated_date.desc())
            .first()
        )
        if not n:
            return jsonify({'error': 'No newsletters found for team'}), 404
        return render_newsletter(n.id, fmt)
    except Exception as e:
        logger.exception('Error rendering latest newsletter')
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/newsletters/generate-weekly-mcp-team', methods=['POST'])
@require_api_key
def generate_weekly_mcp_team():
    try:
        payload = request.get_json() or {}
        target_date = payload.get('target_date')
        team_db_id = payload.get('team_db_id')
        api_team_id = payload.get('api_team_id')
        if not (team_db_id or api_team_id):
            return jsonify({'error': 'team_db_id or api_team_id is required'}), 400
        from datetime import datetime, date as d
        tdate = datetime.strptime(target_date, "%Y-%m-%d").date() if target_date else d.today()

        # Resolve DB id if only API id provided (use inferred season from date)
        if not team_db_id and api_team_id:
            season = tdate.year if tdate.month >= 8 else tdate.year - 1
            row = Team.query.filter_by(team_id=int(api_team_id), season=season).first()
            if not row:
                return jsonify({'error': f'Team api_id={api_team_id} not found for season {season}'}), 404
            team_db_id = row.id
        from src.agents.weekly_agent import generate_weekly_newsletter_with_mcp_sync
        try:
            out = generate_weekly_newsletter_with_mcp_sync(int(team_db_id), tdate)
        except NoActiveLoaneesError as e:
            return jsonify({
                'team_db_id': team_db_id,
                'ran_for': tdate.isoformat(),
                'status': 'skipped',
                'reason': 'no_active_loanees',
                'message': str(e),
            }), 200
        return jsonify({'team_db_id': team_db_id, 'ran_for': tdate.isoformat(), 'result': out})
    except Exception as e:
        logger.exception("generate-weekly-mcp-team failed")
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

# --- Guest loan flag endpoints ---
from src.models.league import LoanFlag, AdminSetting

@api_bp.route('/loans/flags', methods=['POST'])
def create_loan_flag():
    try:
        data = request.get_json() or {}
        required = ('player_id', 'primary_team_api_id', 'reason')
        missing = [k for k in required if not str(data.get(k, '')).strip()]
        if missing:
            return jsonify({'error': f"Missing required: {', '.join(missing)}"}), 400
        lf = LoanFlag(
            player_api_id=int(data['player_id']),
            primary_team_api_id=int(data['primary_team_api_id']),
            loan_team_api_id=(int(data['loan_team_api_id']) if data.get('loan_team_api_id') else None),
            season=(int(data['season']) if data.get('season') else None),
            reason=str(data['reason']).strip(),
            email=(str(data.get('email')).strip() or None),
            ip_address=get_client_ip(),
            user_agent=request.headers.get('User-Agent')[:512] if request.headers.get('User-Agent') else None,
            status='pending'
        )
        db.session.add(lf)
        db.session.commit()
        return jsonify({'message': 'Flag submitted', 'id': lf.id}), 201
    except Exception as e:
        logger.exception('Error creating loan flag')
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/loans/flags/pending', methods=['GET'])
@require_api_key
def list_pending_flags():
    try:
        rows = LoanFlag.query.filter_by(status='pending').order_by(LoanFlag.created_at.desc()).all()
        return jsonify([{
            'id': r.id,
            'player_api_id': r.player_api_id,
            'primary_team_api_id': r.primary_team_api_id,
            'loan_team_api_id': r.loan_team_api_id,
            'season': r.season,
            'reason': r.reason,
            'email': r.email,
            'created_at': r.created_at.isoformat() if r.created_at else None
        } for r in rows])
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/loans/flags/<int:flag_id>/resolve', methods=['POST'])
@require_api_key
def resolve_flag(flag_id: int):
    try:
        row = LoanFlag.query.get_or_404(flag_id)
        data = request.get_json() or {}
        action = (data.get('action') or '').strip()
        note = (data.get('note') or '').strip()

        # Optional: deactivate corresponding loan if requested
        deactivated = 0
        if action == 'deactivate_loan':
            season = row.season
            # Map API ids to Team DB ids
            parent_team = Team.query.filter_by(team_id=row.primary_team_api_id, season=season).first()
            loan_team = Team.query.filter_by(team_id=row.loan_team_api_id, season=season).first() if row.loan_team_api_id else None
            q = LoanedPlayer.query.filter(LoanedPlayer.player_id == row.player_api_id)
            if parent_team:
                q = q.filter(LoanedPlayer.primary_team_id == parent_team.id)
            if loan_team:
                q = q.filter(LoanedPlayer.loan_team_id == loan_team.id)
            for loan in q.all():
                loan.is_active = False
                deactivated += 1
            db.session.commit()
        row.status = 'resolved'
        row.admin_note = note or row.admin_note
        from datetime import datetime as _dt, timezone as _tz
        row.resolved_at = _dt.now(_tz.utc)
        db.session.commit()
        return jsonify({'message': 'Flag resolved', 'deactivated_loans': deactivated})
    except Exception as e:
        logger.exception('Error resolving loan flag')
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

# --- Admin config & run control ---

def _get_admin_bool(key: str, default: bool = False) -> bool:
    try:
        row = AdminSetting.query.filter_by(key=key).first()
        if row and row.value_json is not None:
            v = row.value_json.strip().lower()
            return v in ('1', 'true', 'yes', 'y')
    except Exception:
        pass
    return default

def _set_admin_values(kv: dict[str, str]):
    for k, v in kv.items():
        row = AdminSetting.query.filter_by(key=k).first()
        if not row:
            row = AdminSetting(key=k, value_json=str(v))
            db.session.add(row)
        else:
            row.value_json = str(v)
    db.session.commit()

@api_bp.route('/admin/config', methods=['GET'])
@require_api_key
def get_admin_config():
    try:
        rows = AdminSetting.query.all()
        return jsonify({r.key: r.value_json for r in rows})
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/admin/config', methods=['POST'])
@require_api_key
def update_admin_config():
    try:
        payload = request.get_json() or {}
        settings = payload.get('settings') or {}
        if not isinstance(settings, dict):
            return jsonify({'error': 'settings must be an object'}), 400
        # store as stringified booleans/values
        to_store = {k: ('true' if bool(v) else 'false') if isinstance(v, bool) else str(v) for k, v in settings.items()}
        _set_admin_values(to_store)
        return jsonify({'message': 'Updated', 'updated': list(settings.keys())})
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/admin/run-status', methods=['GET'])
@require_api_key
def get_run_status():
    try:
        paused = _get_admin_bool('runs_paused', False)
        return jsonify({'runs_paused': paused})
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/admin/run-status', methods=['POST'])
@require_api_key
def set_run_status():
    try:
        payload = request.get_json() or {}
        paused = bool(payload.get('runs_paused', False))
        _set_admin_values({'runs_paused': 'true' if paused else 'false'})
        return jsonify({'message': 'Run status updated', 'runs_paused': paused})
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

# --- Admin: Loans management ---
@api_bp.route('/admin/loans', methods=['GET'])
@require_api_key
def admin_list_loans():
    try:
        primary_team_api_id = request.args.get('primary_team_api_id', type=int)
        primary_team_db_id = request.args.get('primary_team_db_id', type=int)
        season = request.args.get('season', type=int)
        active_only = request.args.get('active_only', 'true').lower() in ('true','1','yes','y')

        q = LoanedPlayer.query
        # Filter by primary team
        if primary_team_db_id:
            q = q.filter(LoanedPlayer.primary_team_id == primary_team_db_id)
        elif primary_team_api_id:
            # Resolve DB id from API id (requires season)
            if season is None:
                return jsonify({'error': 'season is required when filtering by primary_team_api_id'}), 400
            row = Team.query.filter_by(team_id=primary_team_api_id, season=season).first()
            if not row:
                return jsonify({'error': f'Primary team api_id={primary_team_api_id} not found for season {season}'}), 404
            q = q.filter(LoanedPlayer.primary_team_id == row.id)

        if active_only:
            q = q.filter(LoanedPlayer.is_active.is_(True))

        # Optional: basic search by player_id or name
        player_id = request.args.get('player_id', type=int)
        if player_id:
            q = q.filter(LoanedPlayer.player_id == player_id)
        player_name = request.args.get('player_name')
        if player_name:
            q = q.filter(LoanedPlayer.player_name.ilike(f"%{player_name}%"))

        loans = q.order_by(LoanedPlayer.updated_at.desc()).all()
        return jsonify([l.to_dict() for l in loans])
    except Exception as e:
        logger.exception('admin_list_loans failed')
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

def _ensure_team_admin(api_team_id: int, season_start_year: int) -> Team | None:
    """
    Ensure a Team row exists for the given API team id and season.

    Improvement: attach the correct League (Top‚Äë5) for the season when creating
    a new Team, so the admin UI can group teams by league instead of "Other".
    """
    try:
        if not api_team_id:
            return None

        # 1) Existing row for this season?
        t = Team.query.filter_by(team_id=api_team_id, season=season_start_year).first()
        if t:
            return t

        # 2) Fetch minimal team info for naming
        tdata = api_client.get_team_by_id(api_team_id, season_start_year)
        ti = (tdata or {}).get('team') or {}
        team_name = ti.get('name') or f'Team {api_team_id}'
        team_code = ti.get('code')
        team_country = ti.get('country') or 'Unknown'
        founded = ti.get('founded')
        national = bool(ti.get('national', False))
        logo = ti.get('logo')

        # 3) Try to resolve league from Top‚Äë5 mapping for this season
        league_fk_id = None
        try:
            teams_map = api_client.get_teams_with_leagues_for_season(season_start_year)  # {api_team_id: {...}}
            meta = teams_map.get(api_team_id)
            if meta:
                league_api_id = meta.get('league_id')
                league_name = meta.get('league_name')
                league_country = meta.get('country') or 'Unknown'
                if league_api_id and league_name:
                    league_row = League.query.filter_by(league_id=league_api_id).first()
                    if not league_row:
                        league_row = League(
                            league_id=league_api_id,
                            name=league_name,
                            country=league_country,
                            season=season_start_year,
                            is_european_top_league=True,
                        )
                        db.session.add(league_row)
                        db.session.flush()
                    league_fk_id = league_row.id
        except Exception:
            # Non‚Äëfatal; leave as None if we cannot resolve
            pass

        # 4) Create team row with resolved league (if found)
        team = Team(
            team_id=api_team_id,
            name=team_name,
            code=team_code,
            country=team_country,
            founded=founded,
            national=national,
            logo=logo,
            season=season_start_year or api_client.current_season_start_year,
            is_active=True,
            league_id=league_fk_id,
        )
        db.session.add(team)
        db.session.flush()
        return team
    except Exception:
        return None

@api_bp.route('/admin/loans', methods=['POST'])
@require_api_key
def admin_create_loan():
    try:
        data = request.get_json() or {}
        player_id = int(data.get('player_id') or 0)
        if not player_id:
            return jsonify({'error': 'player_id is required'}), 400
        player_name = (data.get('player_name') or '').strip() or f'Player {player_id}'
        season = data.get('season')
        window_key = (data.get('window_key') or '').strip() or None
        if season is None and window_key:
            try:
                season = int(window_key.split('::')[0].split('-')[0])
            except Exception:
                season = None
        season = int(season) if season is not None else api_client.current_season_start_year

        # Resolve or create teams from API ids
        pt_api = data.get('primary_team_api_id')
        lt_api = data.get('loan_team_api_id')
        pt_db = data.get('primary_team_db_id')
        lt_db = data.get('loan_team_db_id')
        if not (pt_db or pt_api) or not (lt_db or lt_api):
            return jsonify({'error': 'primary_team_* and loan_team_* are required (db_id or api_id)'}), 400

        parent_team = Team.query.get(int(pt_db)) if pt_db else _ensure_team_admin(int(pt_api), season)
        loan_team = Team.query.get(int(lt_db)) if lt_db else _ensure_team_admin(int(lt_api), season)
        if not parent_team or not loan_team:
            return jsonify({'error': 'Unable to resolve teams. Provide valid db ids or api ids with season.'}), 400

        # Names fallback
        primary_team_name = (data.get('primary_team_name') or parent_team.name)
        loan_team_name = (data.get('loan_team_name') or loan_team.name)
        reviewer_notes = (data.get('reviewer_notes') or '').strip() or None

        # Enforce uniqueness by key; reactivate if an inactive row exists
        any_row = LoanedPlayer.query.filter_by(
            player_id=player_id,
            primary_team_id=parent_team.id,
            loan_team_id=loan_team.id,
            window_key=window_key,
        ).first()
        if any_row:
            if any_row.is_active:
                return jsonify({'error': 'duplicate loan for same player/teams/window'}), 409
            # Reactivate existing record
            any_row.is_active = True
            any_row.player_name = player_name or any_row.player_name
            any_row.primary_team_name = primary_team_name or any_row.primary_team_name
            any_row.loan_team_name = loan_team_name or any_row.loan_team_name
            any_row.reviewer_notes = reviewer_notes or any_row.reviewer_notes
            db.session.commit()
            return jsonify({'message': 'reactivated', 'loan': any_row.to_dict()}), 200

        loan = LoanedPlayer(
            player_id=player_id,
            player_name=player_name,
            primary_team_id=parent_team.id,
            primary_team_name=primary_team_name,
            loan_team_id=loan_team.id,
            loan_team_name=loan_team_name,
            window_key=window_key,
            reviewer_notes=reviewer_notes,
            is_active=True,
        )
        db.session.add(loan)
        db.session.commit()
        return jsonify({'message': 'created', 'loan': loan.to_dict()}), 201
    except Exception as e:
        logger.exception('admin_create_loan failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/admin/loans/<int:loan_id>', methods=['PUT'])
@require_api_key
def admin_update_loan(loan_id: int):
    try:
        loan = LoanedPlayer.query.get_or_404(loan_id)
        data = request.get_json() or {}

        # Move between teams if provided
        season = data.get('season')
        if season is not None:
            try:
                season = int(season)
            except Exception:
                season = api_client.current_season_start_year
        else:
            season = api_client.current_season_start_year

        def _maybe_move_team(kind: str):
            api_id = data.get(f'{kind}_team_api_id')
            db_id = data.get(f'{kind}_team_db_id')
            name = data.get(f'{kind}_team_name')
            if db_id or api_id:
                team = Team.query.get(int(db_id)) if db_id else _ensure_team_admin(int(api_id), season)
                if not team:
                    raise ValueError(f"Unable to resolve {kind} team")
                if kind == 'primary':
                    new_primary_id = team.id
                    new_loan_id = loan.loan_team_id
                else:
                    new_primary_id = loan.primary_team_id
                    new_loan_id = team.id
                # Pre-check for uniqueness conflict against another row
                exists = LoanedPlayer.query.filter(
                    LoanedPlayer.id != loan.id,
                    LoanedPlayer.player_id == loan.player_id,
                    LoanedPlayer.primary_team_id == new_primary_id,
                    LoanedPlayer.loan_team_id == new_loan_id,
                    LoanedPlayer.window_key == loan.window_key,
                ).first()
                if exists:
                    raise ValueError('update would duplicate an existing loan row')
                if kind == 'primary':
                    loan.primary_team_id = new_primary_id
                    if name:
                        loan.primary_team_name = name
                else:
                    loan.loan_team_id = new_loan_id
                    if name:
                        loan.loan_team_name = name
            elif name:
                if kind == 'primary':
                    loan.primary_team_name = name
                else:
                    loan.loan_team_name = name

        _maybe_move_team('primary')
        _maybe_move_team('loan')

        if 'is_active' in data:
            loan.is_active = bool(data.get('is_active'))
        if 'player_name' in data:
            loan.player_name = (data.get('player_name') or '').strip() or loan.player_name
        if 'window_key' in data:
            loan.window_key = (data.get('window_key') or '').strip() or None
        if 'reviewer_notes' in data:
            loan.reviewer_notes = (data.get('reviewer_notes') or '').strip() or None
        if 'youtube_link' in data:
            loan.youtube_link = data.get('youtube_link')

        # Pathway tracking fields (Academy Watch)
        if 'pathway_status' in data:
            valid_statuses = ['academy', 'on_loan', 'first_team', 'released']
            status = data.get('pathway_status')
            if status in valid_statuses:
                loan.pathway_status = status
            elif status:
                raise ValueError(f"Invalid pathway_status: {status}. Must be one of: {valid_statuses}")

        if 'current_level' in data:
            valid_levels = ['U18', 'U21', 'U23', 'Reserve', 'Senior', None, '']
            level = data.get('current_level')
            if level in valid_levels or level is None:
                loan.current_level = level if level else None
            else:
                raise ValueError(f"Invalid current_level: {level}. Must be one of: U18, U21, U23, Reserve, Senior")

        if 'data_depth' in data:
            valid_depths = ['full_stats', 'events_only', 'profile_only']
            depth = data.get('data_depth')
            if depth in valid_depths:
                loan.data_depth = depth
            elif depth:
                raise ValueError(f"Invalid data_depth: {depth}. Must be one of: {valid_depths}")

        db.session.commit()
        return jsonify({'message': 'updated', 'loan': loan.to_dict()})
    except Exception as e:
        logger.exception('admin_update_loan failed')
        db.session.rollback()
        # Uniqueness conflict should return 409
        msg = str(e)
        if 'duplicate' in msg or 'unique' in msg or 'would duplicate' in msg:
            return jsonify({'error': msg}), 409
        return jsonify({'error': msg}), 500

@api_bp.route('/admin/loans/cleanup-duplicates', methods=['POST'])
@require_api_key
def admin_cleanup_duplicate_loans():
    """
    Remove duplicate LoanedPlayer rows sharing (player_id, primary_team_id, loan_team_id, window_key).
    Optional JSON body: { "season": 2025 } to limit by season.
    Keeps the most recently updated row (prefer active), deletes the rest.
    """
    try:
        payload = request.get_json(silent=True) or {}
        season = payload.get('season')
        deleted = 0
        groups = {}
        q = LoanedPlayer.query
        if season:
            slug = f"{int(season)}-{str(int(season) + 1)[-2:]}"
            q = q.filter(LoanedPlayer.window_key.like(f"{slug}%"))
        rows = q.all()
        for r in rows:
            key = (r.player_id, r.primary_team_id, r.loan_team_id, r.window_key)
            groups.setdefault(key, []).append(r)
        for key, lst in groups.items():
            if len(lst) <= 1:
                continue
            # Pick canonical row: active first, then newest updated_at
            lst_sorted = sorted(lst, key=lambda x: ((1 if x.is_active else 0), (x.updated_at or x.created_at)), reverse=True)
            keep = lst_sorted[0]
            to_delete = [r for r in lst_sorted[1:]]
            for r in to_delete:
                try:
                    db.session.delete(r)
                    deleted += 1
                except Exception:
                    db.session.rollback()
                    continue
        if deleted:
            db.session.commit()
        try:
            _append_run_history({'kind': 'cleanup-duplicates', 'season': season, 'deleted': deleted})
        except Exception:
            pass
        return jsonify({'deleted': deleted, 'season': season}), 200
    except Exception as e:
        logger.exception('admin_cleanup_duplicate_loans failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/admin/loans/purge-except', methods=['POST'])
@require_api_key
def admin_purge_loans_except():
    """
    Delete ALL loaned players except those from specified primary (parent) teams.
    Also deletes associated fixture_player_stats.
    
    Body:
    - keep_team_ids: list of team database IDs to KEEP (delete all others)
    - keep_team_api_ids: list of team API IDs to KEEP (alternative to keep_team_ids)
    - dry_run: if true, just return counts without deleting
    
    Example: { "keep_team_ids": [1], "dry_run": false }
    """
    try:
        from src.models.weekly import FixturePlayerStats
        
        data = request.get_json() or {}
        keep_team_ids = data.get('keep_team_ids', [])
        keep_team_api_ids = data.get('keep_team_api_ids', [])
        dry_run = data.get('dry_run', True)
        
        # Convert API IDs to database IDs if needed
        if keep_team_api_ids and not keep_team_ids:
            teams_to_keep = Team.query.filter(Team.team_id.in_(keep_team_api_ids)).all()
            keep_team_ids = [t.id for t in teams_to_keep]
        
        if not keep_team_ids:
            return jsonify({'error': 'Must specify keep_team_ids or keep_team_api_ids'}), 400
        
        # Get loans to delete (where primary_team_id NOT IN keep_team_ids)
        loans_to_delete = LoanedPlayer.query.filter(
            ~LoanedPlayer.primary_team_id.in_(keep_team_ids)
        ).all()
        
        player_api_ids = list(set(l.player_id for l in loans_to_delete))
        
        # Get fixture stats to delete
        fixture_stats_count = 0
        if player_api_ids:
            fixture_stats_count = FixturePlayerStats.query.filter(
                FixturePlayerStats.player_api_id.in_(player_api_ids)
            ).count()
        
        summary = {
            'dry_run': dry_run,
            'keep_team_ids': keep_team_ids,
            'loans_to_delete': len(loans_to_delete),
            'fixture_stats_to_delete': fixture_stats_count,
            'teams_affected': list(set(l.primary_team_name for l in loans_to_delete)),
        }
        
        if dry_run:
            summary['message'] = 'Dry run - no data was deleted'
            return jsonify(summary)
        
        # Actually delete
        if player_api_ids:
            FixturePlayerStats.query.filter(
                FixturePlayerStats.player_api_id.in_(player_api_ids)
            ).delete(synchronize_session=False)
        
        for loan in loans_to_delete:
            db.session.delete(loan)
        
        db.session.commit()
        
        summary['message'] = f'Successfully deleted {len(loans_to_delete)} loans and {fixture_stats_count} fixture stats'
        return jsonify(summary)
        
    except Exception as e:
        logger.exception('admin_purge_loans_except failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to purge loans')), 500


@api_bp.route('/admin/loans/<int:loan_id>/deactivate', methods=['POST'])
@require_api_key
def admin_deactivate_loan(loan_id: int):
    try:
        loan = LoanedPlayer.query.get_or_404(loan_id)
        loan.is_active = False
        db.session.commit()
        return jsonify({'message': 'deactivated', 'loan': loan.to_dict()})
    except Exception as e:
        logger.exception('admin_deactivate_loan failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500


@api_bp.route('/admin/loans/<int:loan_id>/transition', methods=['POST'])
@require_api_key
def admin_transition_loan(loan_id: int):
    """End current loan and optionally create a new loan for the same player.

    Body: {
        new_loan_team_db_id?: int,      # DB ID of new loan club
        new_loan_team_api_id?: int,     # API ID of new loan club (will create/find Team)
        new_loan_team_name?: str,       # Custom team name if not in DB
        new_primary_team_db_id?: int,   # Optionally change parent club
        window_key?: str,               # Window for new loan (defaults to current loan's window)
        deactivate_only?: bool          # If true, just deactivate without creating new
    }
    """
    try:
        data = request.get_json() or {}

        # Get existing loan
        old_loan = LoanedPlayer.query.get_or_404(loan_id)

        deactivate_only = bool(data.get('deactivate_only', False))

        # Deactivate the old loan
        old_loan.is_active = False
        old_loan.updated_at = datetime.now(timezone.utc)

        result = {
            'old_loan_id': old_loan.id,
            'old_loan_deactivated': True,
            'player_name': old_loan.player_name,
            'player_id': old_loan.player_id
        }

        if not deactivate_only:
            # Resolve new loan team
            new_loan_team = None
            new_loan_team_name = data.get('new_loan_team_name', '').strip()

            if data.get('new_loan_team_db_id'):
                new_loan_team = Team.query.get(int(data['new_loan_team_db_id']))
            elif data.get('new_loan_team_api_id'):
                # Try to find or create team
                api_id = int(data['new_loan_team_api_id'])
                new_loan_team = Team.query.filter_by(team_id=api_id).first()
                if not new_loan_team:
                    # Create team from API data
                    try:
                        season = int(old_loan.window_key.split('-')[0]) if old_loan.window_key else 2025
                        new_loan_team = _ensure_team_admin(api_id, season)
                    except Exception:
                        pass

            if not new_loan_team and not new_loan_team_name:
                db.session.rollback()
                return jsonify({'error': 'new_loan_team_db_id, new_loan_team_api_id, or new_loan_team_name required when not deactivate_only'}), 400

            # Resolve parent team (default to same as old loan)
            parent_team = Team.query.get(old_loan.primary_team_id) if old_loan.primary_team_id else None
            if data.get('new_primary_team_db_id'):
                parent_team = Team.query.get(int(data['new_primary_team_db_id']))

            # Use window_key from request or default to old loan's window
            window_key = data.get('window_key', '').strip() or old_loan.window_key

            # Create new loan
            new_loan = LoanedPlayer(
                player_id=old_loan.player_id,
                player_name=old_loan.player_name,
                age=old_loan.age,
                nationality=old_loan.nationality,
                primary_team_id=parent_team.id if parent_team else None,
                primary_team_name=parent_team.name if parent_team else old_loan.primary_team_name,
                loan_team_id=new_loan_team.id if new_loan_team else None,
                loan_team_name=new_loan_team.name if new_loan_team else new_loan_team_name,
                window_key=window_key,
                is_active=True,
                data_source='manual',  # Mark as manual to protect from API seeding
                can_fetch_stats=old_loan.can_fetch_stats,
                stats_coverage=old_loan.stats_coverage,
                reviewer_notes=f'Transitioned from loan #{old_loan.id}',
                created_at=datetime.now(timezone.utc)
            )
            db.session.add(new_loan)
            db.session.flush()  # Get ID before commit

            result['new_loan_id'] = new_loan.id
            result['new_loan_team'] = new_loan.loan_team_name
            result['new_loan_created'] = True

        db.session.commit()
        return jsonify(result)

    except Exception as e:
        logger.exception('admin_transition_loan failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500


@api_bp.route('/admin/loans/bulk-deactivate', methods=['POST'])
@require_api_key
def admin_bulk_deactivate_loans():
    """Deactivate multiple loans at once.

    Body: {
        loan_ids: [int],    # List of loan IDs to deactivate
        note?: str          # Optional note to append to reviewer_notes
    }
    """
    try:
        data = request.get_json() or {}
        loan_ids = data.get('loan_ids', [])
        note = data.get('note', '').strip()

        if not loan_ids:
            return jsonify({'error': 'loan_ids is required'}), 400

        deactivated = 0
        skipped = 0
        details = []

        for loan_id in loan_ids:
            try:
                loan = LoanedPlayer.query.get(int(loan_id))
                if not loan:
                    skipped += 1
                    details.append({'loan_id': loan_id, 'status': 'not_found'})
                    continue
                if not loan.is_active:
                    skipped += 1
                    details.append({'loan_id': loan_id, 'status': 'already_inactive'})
                    continue

                loan.is_active = False
                loan.updated_at = datetime.now(timezone.utc)
                if note:
                    loan.reviewer_notes = f"{loan.reviewer_notes or ''}\n[Bulk deactivated] {note}".strip()

                deactivated += 1
                details.append({'loan_id': loan_id, 'status': 'deactivated', 'player_name': loan.player_name})
            except Exception as ex:
                skipped += 1
                details.append({'loan_id': loan_id, 'status': f'error: {ex}'})

        db.session.commit()

        return jsonify({
            'message': 'bulk_deactivate_complete',
            'deactivated': deactivated,
            'skipped': skipped,
            'details': details
        })

    except Exception as e:
        logger.exception('admin_bulk_deactivate_loans failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500


@api_bp.route('/admin/loans/bulk-transition', methods=['POST'])
@require_api_key
def admin_bulk_transition_loans():
    """Transition multiple loans to new clubs.

    Body: {
        transitions: [
            {
                loan_id: int,
                new_loan_team_db_id?: int,
                new_loan_team_name?: str,
                deactivate_only?: bool
            }
        ]
    }
    """
    try:
        data = request.get_json() or {}
        transitions = data.get('transitions', [])

        if not transitions:
            return jsonify({'error': 'transitions is required'}), 400

        transitioned = 0
        deactivated_only = 0
        skipped = 0
        details = []

        for t in transitions:
            try:
                loan_id = t.get('loan_id')
                if not loan_id:
                    skipped += 1
                    details.append({'status': 'missing_loan_id'})
                    continue

                old_loan = LoanedPlayer.query.get(int(loan_id))
                if not old_loan:
                    skipped += 1
                    details.append({'loan_id': loan_id, 'status': 'not_found'})
                    continue

                # Deactivate old loan
                old_loan.is_active = False
                old_loan.updated_at = datetime.now(timezone.utc)

                deactivate_only = bool(t.get('deactivate_only', False))

                if deactivate_only:
                    deactivated_only += 1
                    details.append({
                        'loan_id': loan_id,
                        'status': 'deactivated_only',
                        'player_name': old_loan.player_name
                    })
                    continue

                # Resolve new loan team
                new_loan_team = None
                new_loan_team_name = t.get('new_loan_team_name', '').strip()

                if t.get('new_loan_team_db_id'):
                    new_loan_team = Team.query.get(int(t['new_loan_team_db_id']))

                if not new_loan_team and not new_loan_team_name:
                    skipped += 1
                    details.append({
                        'loan_id': loan_id,
                        'status': 'missing_new_team',
                        'player_name': old_loan.player_name
                    })
                    continue

                # Create new loan
                new_loan = LoanedPlayer(
                    player_id=old_loan.player_id,
                    player_name=old_loan.player_name,
                    age=old_loan.age,
                    nationality=old_loan.nationality,
                    primary_team_id=old_loan.primary_team_id,
                    primary_team_name=old_loan.primary_team_name,
                    loan_team_id=new_loan_team.id if new_loan_team else None,
                    loan_team_name=new_loan_team.name if new_loan_team else new_loan_team_name,
                    window_key=old_loan.window_key,
                    is_active=True,
                    data_source='manual',
                    can_fetch_stats=old_loan.can_fetch_stats,
                    stats_coverage=old_loan.stats_coverage,
                    reviewer_notes=f'Bulk transitioned from loan #{old_loan.id}',
                    created_at=datetime.now(timezone.utc)
                )
                db.session.add(new_loan)
                db.session.flush()  # Get ID before commit

                transitioned += 1
                details.append({
                    'loan_id': loan_id,
                    'status': 'transitioned',
                    'player_name': old_loan.player_name,
                    'new_loan_id': new_loan.id,
                    'new_loan_team': new_loan.loan_team_name,
                    'primary_team_id': old_loan.primary_team_id,
                    'primary_team_name': old_loan.primary_team_name,
                    'player_id': old_loan.player_id,
                    'window_key': old_loan.window_key
                })

            except Exception as ex:
                skipped += 1
                details.append({'loan_id': t.get('loan_id'), 'status': f'error: {ex}'})

        db.session.commit()

        return jsonify({
            'message': 'bulk_transition_complete',
            'transitioned': transitioned,
            'deactivated_only': deactivated_only,
            'skipped': skipped,
            'details': details
        })

    except Exception as e:
        logger.exception('admin_bulk_transition_loans failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500


@api_bp.route('/admin/loans/preview-sync', methods=['POST'])
@require_api_key
def admin_preview_sync_loans():
    """Preview what API has vs what we have in the database.

    Returns a diff showing:
    - new: Loans API has that we don't
    - matches_manual: Manual loans that API now has (confirmed)
    - already_tracked: Loans we already have from API

    Body: {
        season: int,
        team_db_id?: int,       # Filter to specific parent team
        team_api_id?: int,      # Or use API team ID
        window_key?: str        # Window to check (defaults to FULL)
    }
    """
    try:
        data = request.get_json() or {}
        season = int(data.get('season') or 0)
        if not season:
            return jsonify({'error': 'season is required'}), 400

        # Compute window_key
        window_key = (data.get('window_key') or '').strip()
        if not window_key:
            end_two = str((season + 1) % 100).zfill(2)
            window_key = f"{season}-{end_two}::FULL"

        # Initialize API client
        api_client.set_season_year(season)

        # Clear transfer cache to get fresh data
        if hasattr(api_client._resolve(), '_cached_transfers'):
            api_client._resolve()._cached_transfers.cache_clear()

        # Resolve team filter
        parent_api_id = None
        if data.get('team_db_id'):
            team = Team.query.get(int(data['team_db_id']))
            if team:
                parent_api_id = team.team_id
        elif data.get('team_api_id'):
            parent_api_id = int(data['team_api_id'])

        # Get API loan candidates
        league_ids = [39, 140, 78, 135, 61]  # Top-5 leagues

        if parent_api_id:
            # Single team mode
            direct = api_client.get_direct_loan_candidates(window_key, league_ids, season=season) or {}
            # Filter to parent team
            direct = {pid: info for pid, info in direct.items() if info.get('primary_team_id') == parent_api_id}
        else:
            # All teams mode
            direct = api_client.get_direct_loan_candidates(window_key, league_ids, season=season) or {}

        # Get existing loans from DB - filter by season using window_key prefix
        season_prefix = f"{season}-"
        existing_query = LoanedPlayer.query.filter(
            LoanedPlayer.is_active.is_(True),
            LoanedPlayer.window_key.like(f"{season_prefix}%")
        )
        if parent_api_id:
            parent_team = Team.query.filter_by(team_id=parent_api_id).first()
            if parent_team:
                existing_query = existing_query.filter(LoanedPlayer.primary_team_id == parent_team.id)

        existing_loans = existing_query.all()
        existing_by_player_id = {loan.player_id: loan for loan in existing_loans}

        # Categorize results
        new_loans = []
        matches_manual = []
        already_tracked = []

        for player_id, api_data in direct.items():
            existing = existing_by_player_id.get(int(player_id))

            if not existing:
                # Fetch player name from API
                player_name = 'Unknown'
                try:
                    player_info = api_client.get_player_by_id(int(player_id))
                    if player_info and player_info.get('player'):
                        player_name = player_info['player'].get('name', 'Unknown')
                except Exception:
                    pass

                # New loan from API
                new_loans.append({
                    'player_id': player_id,
                    'player_name': player_name,
                    'primary_team_name': api_data.get('primary_team_name'),
                    'primary_team_id': api_data.get('primary_team_id'),
                    'loan_team_name': api_data.get('loan_team_name'),
                    'loan_team_id': api_data.get('loan_team_id'),
                    'transfer_date': api_data.get('transfer_date')
                })
            elif existing.data_source == 'manual':
                # Manual loan now confirmed by API
                matches_manual.append({
                    'loan_id': existing.id,
                    'player_id': player_id,
                    'player_name': existing.player_name,
                    'loan_team_name': existing.loan_team_name,
                    'api_loan_team_name': api_data.get('loan_team_name'),
                    'api_transfer_date': api_data.get('transfer_date'),
                    'already_confirmed': existing.api_confirmed_at is not None
                })
            else:
                # Already tracked from API
                already_tracked.append({
                    'loan_id': existing.id,
                    'player_id': player_id,
                    'player_name': existing.player_name,
                    'loan_team_name': existing.loan_team_name
                })

        return jsonify({
            'season': season,
            'window_key': window_key,
            'parent_team_api_id': parent_api_id,
            'summary': {
                'new': len(new_loans),
                'matches_manual': len(matches_manual),
                'already_tracked': len(already_tracked)
            },
            'new': new_loans,
            'matches_manual': matches_manual,
            'already_tracked': already_tracked
        })

    except Exception as e:
        logger.exception('admin_preview_sync_loans failed')
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500


@api_bp.route('/admin/loans/seed-top5', methods=['POST'])
@require_api_key
def admin_seed_top5_loans():
    """Seed LoanedPlayer rows for Top-5 European leagues for a given season.

    Body: { season: int, window_key?: str, league_ids?: [int], dry_run?: bool, background?: bool }
    - season: starting year (e.g., 2025 for 2025-26)
    - window_key default: "{season}-{(season+1)%100:02d}::FULL"
    - league_ids default: [39, 140, 78, 135, 61]
    - background: if true, run in background and return job ID
    """
    from flask import copy_current_request_context
    
    data = request.get_json() or {}
    season = int(data.get('season') or 0)
    if not season:
        return jsonify({'error': 'season is required'}), 400
    
    background = bool(data.get('background', False))
    
    if background:
        # Start background job
        job_id = _create_background_job('seed_top5')
        
        @copy_current_request_context
        def run_seed_in_background():
            try:
                result = _run_seed_top5_logic(data, job_id)
                _update_job(job_id, status='completed', results=result, completed_at=datetime.now(timezone.utc).isoformat())
            except Exception as e:
                logger.exception(f'Background seed job {job_id} failed')
                _update_job(job_id, status='failed', error=str(e), completed_at=datetime.now(timezone.utc).isoformat())
        
        thread = threading.Thread(target=run_seed_in_background)
        thread.start()
        
        return jsonify({
            'message': 'Seed Top 5 job started in background',
            'job_id': job_id,
            'status': 'running',
            'check_status_url': f'/api/admin/jobs/{job_id}'
        })
    
    # Synchronous mode
    try:
        result = _run_seed_top5_logic(data)
        return jsonify(result)
    except Exception as e:
        logger.exception('admin_seed_top5_loans failed')
        try:
            db.session.rollback()
        except Exception:
            logger.warning('db.session.rollback failed during admin_seed_top5_loans error handling')
        return jsonify(_safe_error_payload(e, 'Failed to seed top five leagues. Please try again later.', include_detail=True)), 500


def _run_seed_top5_logic(data: dict, job_id: str = None) -> dict:
    """Core logic for seeding Top 5 leagues. Can be run sync or in background."""
    try:
        season = int(data.get('season') or 0)
        league_ids = data.get('league_ids') or [39, 140, 78, 135, 61]
        dry_run = bool(data.get('dry_run'))
        overwrite = bool(data.get('overwrite'))

        logger.info(
            'Admin seed-top5 logic season=%s dry_run=%s overwrite=%s leagues=%s',
            season,
            dry_run,
            overwrite,
            league_ids,
        )

        # Compute default window_key (e.g., 2025-26::FULL)
        window_key = (data.get('window_key') or '').strip()
        if not window_key:
            end_two = str((season + 1) % 100).zfill(2)
            window_key = f"{season}-{end_two}::FULL"

        # Update job status
        if job_id:
            _update_job(job_id, progress=0, current_player='Syncing season data...')

        # Ensure season data in local DB
        _sync_season(season=season)
        api_client.set_season_year(season)
        api_client._prime_team_cache(season)

        # Clear stale transfer cache to ensure fresh API data (critical for mid-window seeding)
        if hasattr(api_client._resolve(), '_cached_transfers'):
            api_client._resolve()._cached_transfers.cache_clear()
            logger.info("üóëÔ∏è Cleared _cached_transfers LRU cache for fresh data")

        if job_id:
            _update_job(job_id, current_player='Fetching loan candidates...')

        created = 0
        skipped = 0
        candidates_total = 0
        details = []

        # Collect candidates from two sources: direct transfers and multi-team detection
        direct = api_client.get_direct_loan_candidates(window_key, league_ids, season=season) or {}
        multi_team = api_client.detect_multi_team_players(league_ids, window_key, season=season) or {}

        # Merge keys
        player_ids = set(direct.keys()) | set(multi_team.keys())
        candidates_total = len(player_ids)

        if job_id:
            _update_job(job_id, total=candidates_total, progress=0, current_player=f'Processing {candidates_total} candidates...')

        # Track candidate triplets to support overwrite/prune
        candidate_triplets: set[tuple[int,int,int]] = set()

        for idx, player_id in enumerate(player_ids):
            # Update progress for background jobs
            if job_id and idx % 10 == 0:
                _update_job(job_id, progress=idx)
            try:
                # Derive teams
                d = direct.get(player_id) or {}
                mt = multi_team.get(player_id) or []
                # multi_team format often [loan_team_id, primary_team_id]
                loan_team_api_id = d.get('loan_team_id') or (mt[0] if len(mt) > 0 else None)
                primary_team_api_id = d.get('primary_team_id') or (mt[1] if len(mt) > 1 else None)
                if not (loan_team_api_id and primary_team_api_id):
                    skipped += 1
                    details.append({'player_id': player_id, 'status': 'skip_missing_teams'})
                    continue

                # Fetch player info (name)
                info = api_client.get_player_by_id(player_id) or {}
                player_info = info.get('player') or {}
                player_name = (player_info.get('name') or f'Player {player_id}')

                # Resolve Team DB rows (create if needed)
                parent_team = _ensure_team_admin(int(primary_team_api_id), season)
                loan_team = _ensure_team_admin(int(loan_team_api_id), season)
                if not parent_team or not loan_team:
                    skipped += 1
                    details.append({'player_id': player_id, 'status': 'skip_unresolved_team'})
                    continue

                # üõ°Ô∏è MANUAL OVERRIDE: Skip players who already have a manual loan
                # This ensures manually-managed loans are never overwritten by API seeding
                existing_manual = LoanedPlayer.query.filter(
                    LoanedPlayer.player_id == int(player_id),
                    LoanedPlayer.is_active.is_(True),
                    LoanedPlayer.data_source == 'manual'
                ).first()
                if existing_manual:
                    # Update api_confirmed_at to show API now has this data
                    existing_manual.api_confirmed_at = datetime.now(timezone.utc)
                    skipped += 1
                    details.append({
                        'player_id': player_id,
                        'status': 'skip_manual_override',
                        'manual_loan_id': existing_manual.id,
                        'message': f'Manual loan exists: {existing_manual.player_name} at {existing_manual.loan_team_name}'
                    })
                    continue

                # üîÑ VERIFY player ID via fixtures to avoid ID mismatch issues
                # API-Football sometimes uses different IDs in squad vs fixture APIs
                verified_player_id, verification_method = api_client.verify_player_id_via_fixtures(
                    candidate_player_id=int(player_id),
                    player_name=player_name,
                    loan_team_id=int(loan_team_api_id),
                    season=season,
                    max_fixtures=3  # Check last 3 fixtures
                )
                
                if verified_player_id != player_id:
                    logger.info(f"üîÑ Using fixture-verified ID {verified_player_id} instead of {player_id} for {player_name}")
                    player_id = verified_player_id
                
                # üìä Check stats coverage for the loan team's league
                coverage_info = api_client.check_team_stats_coverage(int(loan_team_api_id), season)
                stats_coverage = coverage_info.get('coverage_level', 'full')

                # Record candidate triplet for potential pruning
                candidate_triplets.add((int(player_id), int(parent_team.id), int(loan_team.id)))

                # Deactivate ALL old active loans for this player before creating new one
                # This ensures a player only has ONE active loan at a time
                if not dry_run:
                    old_loans = LoanedPlayer.query.filter(
                        LoanedPlayer.player_id == int(player_id),
                        LoanedPlayer.is_active.is_(True),
                    ).all()
                    for old_loan in old_loans:
                        # Don't deactivate if it's the exact same loan we're about to create/reactivate
                        if old_loan.loan_team_id == loan_team.id and old_loan.window_key == window_key:
                            continue
                        old_loan.is_active = False
                        old_loan.updated_at = datetime.now(timezone.utc)

                # Duplicate handling: prefer reactivation over new row
                any_row = LoanedPlayer.query.filter_by(
                    player_id=int(player_id),
                    primary_team_id=parent_team.id,
                    loan_team_id=loan_team.id,
                    window_key=window_key,
                ).first()
                if any_row:
                    if any_row.is_active:
                        skipped += 1
                        details.append({'player_id': player_id, 'status': 'skip_duplicate_active'})
                        continue
                    if dry_run:
                        details.append({'player_id': player_id, 'status': 'would_reactivate'})
                        continue
                    any_row.is_active = True
                    any_row.player_name = player_name or any_row.player_name
                    any_row.primary_team_name = parent_team.name
                    any_row.loan_team_name = loan_team.name
                    details.append({'player_id': player_id, 'status': 'reactivated'})
                else:
                    if dry_run:
                        details.append({'player_id': player_id, 'status': 'dry_run'})
                        continue
                    loan = LoanedPlayer(
                        player_id=int(player_id),
                        player_name=player_name,
                        primary_team_id=parent_team.id,
                        primary_team_name=parent_team.name,
                        loan_team_id=loan_team.id,
                        loan_team_name=loan_team.name,
                        window_key=window_key,
                        reviewer_notes='Seeded via /admin/loans/seed-top5',
                        is_active=True,
                        stats_coverage=stats_coverage,  # 'full', 'limited', or 'none'
                    )
                    db.session.add(loan)
                    created += 1
                    details.append({'player_id': player_id, 'status': 'created', 'stats_coverage': stats_coverage})
            except Exception as ex:
                skipped += 1
                details.append({'player_id': player_id, 'status': f'error: {ex}'})

        if not dry_run:
            # Mark all parent teams that now have loans as tracked
            if created > 0:
                tracked_team_ids = set()
                for detail in details:
                    if detail.get('status') in ('created', 'reactivated'):
                        pid = detail.get('player_id')
                        d = direct.get(pid) or {}
                        mt = multi_team.get(pid) or []
                        primary_api_id = d.get('primary_team_id') or (mt[1] if len(mt) > 1 else None)
                        if primary_api_id:
                            tracked_team_ids.add(primary_api_id)
                
                for api_id in tracked_team_ids:
                    try:
                        team = Team.query.filter_by(team_id=api_id, season=season).first()
                        if team:
                            team.is_tracked = True
                    except Exception:
                        pass
            db.session.commit()

        # Optional pruning of stale seeded loans for this season
        pruned = 0
        if overwrite and not dry_run:
            try:
                # Deactivate active rows seeded via seed-top5 for same season not present in new candidates
                existing_rows = LoanedPlayer.query.filter(
                    LoanedPlayer.is_active.is_(True)
                ).all()
                for row in existing_rows:
                    try:
                        if not row.window_key or not str(row.window_key).startswith(str(season)):
                            continue
                        # üõ°Ô∏è NEVER prune manual entries - they are protected from auto-management
                        if row.data_source == 'manual':
                            continue
                        # Only prune rows created by top5 seeding to avoid touching hand-entered or team‚Äëseeded items
                        if not row.reviewer_notes or 'seed-top5' not in row.reviewer_notes:
                            continue
                        triplet = (int(row.player_id), int(row.primary_team_id), int(row.loan_team_id))
                        if triplet not in candidate_triplets:
                            row.is_active = False
                            pruned += 1
                    except Exception:
                        continue
                if pruned:
                    db.session.commit()
            except Exception:
                db.session.rollback()

        # Ensure teams for this season have leagues assigned (idempotent backfill)
        if not dry_run:
            try:
                team_map = api_client.get_teams_with_leagues_for_season(season) or {}
                existing_league_fk_by_api_id: dict[int, int] = {}
                for row in Team.query.filter(Team.league_id.isnot(None)).all():
                    existing_league_fk_by_api_id[row.team_id] = row.league_id
                updated = 0
                created_leagues = 0
                for t in Team.query.filter_by(season=season).filter(Team.league_id.is_(None)).all():
                    meta = team_map.get(t.team_id)
                    league_row = None
                    if meta:
                        league_api_id = meta.get('league_id')
                        league_name = meta.get('league_name')
                        league_country = meta.get('country') or 'Unknown'
                        if league_api_id and league_name:
                            league_row = League.query.filter_by(league_id=league_api_id).first()
                            if not league_row:
                                league_row = League(
                                    league_id=league_api_id,
                                    name=league_name,
                                    country=league_country,
                                    season=season,
                                    is_european_top_league=True,
                                )
                                db.session.add(league_row)
                                db.session.flush()
                                created_leagues += 1
                    if league_row is None:
                        fk = existing_league_fk_by_api_id.get(t.team_id)
                        if fk:
                            t.league_id = fk
                            updated += 1
                            continue
                    if league_row is None:
                        continue
                    t.league_id = league_row.id
                    updated += 1
                if updated or created_leagues:
                    db.session.commit()
            except Exception:
                db.session.rollback()
                pass

        try:
            _append_run_history({
                'kind': 'seed-top5-dry' if dry_run else 'seed-top5',
                'season': season,
                'window_key': window_key,
                'created': created,
                'skipped': skipped,
                'candidates': candidates_total,
                'dry_run': dry_run,
                'pruned': pruned if overwrite and not dry_run else 0,
            })
        except Exception:
            pass

        summary_payload = {
            'message': 'seed_complete' if not dry_run else 'dry_run_complete',
            'season': season,
            'window_key': window_key,
            'candidates': candidates_total,
            'created': created,
            'skipped': skipped,
            'pruned': pruned if overwrite and not dry_run else 0,
            'dry_run': dry_run,
            'details': details[:200],  # return a sample to limit payload
        }
        logger.info(
            'Admin seed-top5 completed season=%s dry_run=%s overwrite=%s created=%s skipped=%s pruned=%s',
            season,
            dry_run,
            overwrite,
            summary_payload['created'],
            summary_payload['skipped'],
            summary_payload['pruned'],
        )
        return summary_payload
    except Exception as e:
        logger.exception('_run_seed_top5_logic failed')
        try:
            db.session.rollback()
        except Exception:
            logger.warning('db.session.rollback failed during _run_seed_top5_logic error handling')
        raise

@api_bp.route('/admin/loans/seed-team', methods=['POST'])
@require_api_key
def admin_seed_team_loans():
    """Seed LoanedPlayer rows for a single parent (primary) team for a given season.

    Body: { season: int, team_db_id?: int, api_team_id?: int, window_key?: str, dry_run?: bool, overwrite?: bool }
    - season: starting year (e.g., 2025 for 2025-26)
    - Provide either team_db_id or api_team_id (API-Football id)
    - overwrite: if true, deactivates existing active loans for this player/primary team in the same season before creating new
    """
    try:
        data = request.get_json() or {}
        season = int(data.get('season') or 0)
        if not season:
            return jsonify({'error': 'season is required'}), 400
        team_db_id = data.get('team_db_id')
        api_team_id = data.get('api_team_id')
        dry_run = bool(data.get('dry_run'))
        overwrite = bool(data.get('overwrite'))

        if not (team_db_id or api_team_id):
            return jsonify({'error': 'team_db_id or api_team_id required'}), 400

        # Resolve parent team and api id
        parent_row = Team.query.get(int(team_db_id)) if team_db_id else _ensure_team_admin(int(api_team_id), season)
        if not parent_row:
            return jsonify({'error': 'Unable to resolve parent team'}), 400
        parent_api_id = int(parent_row.team_id)

        # Compute window_key if not provided
        window_key = (data.get('window_key') or '').strip()
        if not window_key:
            end_two = str((season + 1) % 100).zfill(2)
            window_key = f"{season}-{end_two}::FULL"

        _sync_season(season=season)
        api_client.set_season_year(season)
        api_client._prime_team_cache(season)

        # Clear stale transfer cache to ensure fresh API data (critical for mid-window seeding)
        if hasattr(api_client._resolve(), '_cached_transfers'):
            api_client._resolve()._cached_transfers.cache_clear()
            logger.info("üóëÔ∏è Cleared _cached_transfers LRU cache for fresh data")

        # Default to Top-5 leagues; results will be filtered to parent_api_id
        league_ids = data.get('league_ids') or [39, 140, 78, 135, 61]

        direct = api_client.get_direct_loan_candidates(window_key, league_ids, season=season) or {}
        multi_team = api_client.detect_multi_team_players(league_ids, window_key, season=season) or {}

        # Filter to this parent team
        filtered_direct = {pid: info for pid, info in direct.items() if info.get('primary_team_id') == parent_api_id}
        filtered_multi = {pid: tids for pid, tids in multi_team.items() if (tids + [None, None])[1] == parent_api_id}

        player_ids = set(filtered_direct.keys()) | set(filtered_multi.keys())

        created = 0
        skipped = 0
        details = []

        for player_id in player_ids:
            try:
                d = filtered_direct.get(player_id) or {}
                mt = filtered_multi.get(player_id) or []
                loan_team_api_id = d.get('loan_team_id') or (mt[0] if len(mt) > 0 else None)
                primary_team_api_id = d.get('primary_team_id') or parent_api_id
                if not (loan_team_api_id and primary_team_api_id):
                    skipped += 1
                    details.append({'player_id': player_id, 'status': 'skip_missing_teams'})
                    continue

                info = api_client.get_player_by_id(player_id) or {}
                player_info = info.get('player') or {}
                player_name = (player_info.get('name') or f'Player {player_id}')

                parent_team = _ensure_team_admin(int(primary_team_api_id), season)
                loan_team = _ensure_team_admin(int(loan_team_api_id), season)
                if not parent_team or not loan_team:
                    skipped += 1
                    details.append({'player_id': player_id, 'status': 'skip_unresolved_team'})
                    continue

                # üõ°Ô∏è MANUAL OVERRIDE: Skip players who already have a manual loan
                # This ensures manually-managed loans are never overwritten by API seeding
                existing_manual = LoanedPlayer.query.filter(
                    LoanedPlayer.player_id == int(player_id),
                    LoanedPlayer.is_active.is_(True),
                    LoanedPlayer.data_source == 'manual'
                ).first()
                if existing_manual:
                    # Update api_confirmed_at to show API now has this data
                    existing_manual.api_confirmed_at = datetime.now(timezone.utc)
                    skipped += 1
                    details.append({
                        'player_id': player_id,
                        'status': 'skip_manual_override',
                        'manual_loan_id': existing_manual.id,
                        'message': f'Manual loan exists: {existing_manual.player_name} at {existing_manual.loan_team_name}'
                    })
                    continue

                # üîÑ VERIFY player ID via fixtures to avoid ID mismatch issues
                # API-Football sometimes uses different IDs in squad vs fixture APIs
                verified_player_id, verification_method = api_client.verify_player_id_via_fixtures(
                    candidate_player_id=int(player_id),
                    player_name=player_name,
                    loan_team_id=int(loan_team_api_id),
                    season=season,
                    max_fixtures=3  # Check last 3 fixtures
                )

                if verified_player_id != player_id:
                    logger.info(f"üîÑ Using fixture-verified ID {verified_player_id} instead of {player_id} for {player_name}")
                    player_id = verified_player_id

                # üìä Check stats coverage for the loan team's league
                coverage_info = api_client.check_team_stats_coverage(int(loan_team_api_id), season)
                stats_coverage = coverage_info.get('coverage_level', 'full')

                if overwrite and not dry_run:
                    # Deactivate any existing active loans for this player at this parent in this season
                    season_start = season
                    # Deactivate ALL old active loans for this player (regardless of parent team)
                    # This ensures a player only has ONE active loan at a time
                    existing_rows = LoanedPlayer.query.filter(
                        LoanedPlayer.player_id == int(player_id),
                        LoanedPlayer.is_active.is_(True),
                    ).all()
                    for row in existing_rows:
                        try:
                            # Don't deactivate if it's the exact same loan we're about to create/reactivate
                            if row.loan_team_id == loan_team.id and row.window_key == window_key:
                                continue
                            row.is_active = False
                            row.updated_at = datetime.now(timezone.utc)
                        except Exception:
                            continue

                # Duplicate handling: reuse/reactivate instead of creating duplicates
                any_row = LoanedPlayer.query.filter_by(
                    player_id=int(player_id),
                    primary_team_id=parent_team.id,
                    loan_team_id=loan_team.id,
                    window_key=window_key,
                ).first()
                if any_row:
                    if any_row.is_active:
                        skipped += 1
                        details.append({'player_id': player_id, 'status': 'skip_duplicate_active'})
                        continue
                    if dry_run:
                        details.append({'player_id': player_id, 'status': 'would_reactivate'})
                        continue
                    any_row.is_active = True
                    any_row.player_name = player_name or any_row.player_name
                    any_row.primary_team_name = parent_team.name
                    any_row.loan_team_name = loan_team.name
                    details.append({'player_id': player_id, 'status': 'reactivated'})
                else:
                    if dry_run:
                        details.append({'player_id': player_id, 'status': 'dry_run'})
                        continue
                    loan = LoanedPlayer(
                        player_id=int(player_id),
                        player_name=player_name,
                        primary_team_id=parent_team.id,
                        primary_team_name=parent_team.name,
                        loan_team_id=loan_team.id,
                        loan_team_name=loan_team.name,
                        window_key=window_key,
                        reviewer_notes='Seeded via /admin/loans/seed-team',
                        is_active=True,
                        stats_coverage=stats_coverage,  # 'full', 'limited', or 'none'
                    )
                    db.session.add(loan)
                    created += 1
                    details.append({'player_id': player_id, 'status': 'created', 'stats_coverage': stats_coverage})
            except Exception as ex:
                skipped += 1
                details.append({'player_id': player_id, 'status': f'error: {ex}'})

        if not dry_run:
            # Mark parent team as tracked since we're adding loans
            if created > 0 and parent_row:
                parent_row.is_tracked = True
            db.session.commit()

        try:
            _append_run_history({
                'kind': 'seed-team',
                'season': season,
                'team_db_id': parent_row.id,
                'api_team_id': parent_api_id,
                'created': created,
                'skipped': skipped,
                'dry_run': dry_run,
            })
        except Exception:
            pass

        return jsonify({
            'message': 'seed_team_complete' if not dry_run else 'seed_team_dry_run_complete',
            'season': season,
            'team_db_id': parent_row.id,
            'api_team_id': parent_api_id,
            'created': created,
            'skipped': skipped,
            'details': details[:200],
            'dry_run': dry_run,
        })
    except Exception as e:
        logger.exception('admin_seed_team_loans failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500


@api_bp.route('/admin/resync-goalkeeper-saves', methods=['POST'])
@require_api_key
def admin_resync_goalkeeper_saves():
    """
    Re-sync goalkeeper saves data from API-Football.
    Finds goalkeeper fixtures missing saves data and fetches from API.
    
    Request body (optional):
    {
        "dry_run": true,      // Preview mode (default: false)
        "player_id": 284361,  // Filter to specific player (optional)
        "limit": 50           // Max fixtures to process (default: 50)
    }
    """
    import time
    from src.models.weekly import FixturePlayerStats, Fixture
    from src.api_football_client import APIFootballClient
    
    try:
        data = request.get_json(force=True) if request.data else {}
        dry_run = data.get('dry_run', False)
        player_id_filter = data.get('player_id')
        limit = min(data.get('limit', 50), 200)  # Cap at 200 to avoid timeout
        
        logger.info(f"Admin resync-goalkeeper-saves: dry_run={dry_run}, player_id={player_id_filter}, limit={limit}")
        
        # Find goalkeeper stats with missing saves data
        query = db.session.query(
            FixturePlayerStats, Fixture
        ).join(
            Fixture, FixturePlayerStats.fixture_id == Fixture.id
        ).filter(
            FixturePlayerStats.position == 'G',
            FixturePlayerStats.saves.is_(None),
            FixturePlayerStats.minutes > 0
        )
        
        if player_id_filter:
            query = query.filter(FixturePlayerStats.player_api_id == player_id_filter)
        
        results = query.order_by(Fixture.date_utc.desc()).limit(limit).all()
        
        if not results:
            return jsonify({
                'message': 'No goalkeeper fixtures found with missing saves data',
                'dry_run': dry_run,
                'processed': 0,
            })
        
        api_client = APIFootballClient()
        
        updated = 0
        skipped = 0
        errors = 0
        details = []
        
        for stats, fixture in results:
            fixture_id_api = fixture.fixture_id_api
            player_api_id = stats.player_api_id
            season = fixture.season or datetime.now(timezone.utc).year
            
            try:
                player_stats = api_client.get_player_stats_for_fixture(player_api_id, season, fixture_id_api)
                
                if player_stats and player_stats.get('statistics'):
                    stat_list = player_stats['statistics']
                    if stat_list:
                        st = stat_list[0] if isinstance(stat_list, list) else stat_list
                        # Goalkeeper saves are in the 'goals' block in API-Football response
                        goals_block = st.get('goals', {}) or {}
                        saves = goals_block.get('saves')
                        goals_conceded = goals_block.get('conceded')
                        
                        if saves is not None:
                            if not dry_run:
                                stats.saves = saves
                                # Also update goals_conceded if missing
                                if goals_conceded is not None and stats.goals_conceded is None:
                                    stats.goals_conceded = goals_conceded
                                db.session.commit()
                            
                            details.append({
                                'player_id': player_api_id,
                                'fixture_id': fixture_id_api,
                                'saves': saves,
                                'goals_conceded': goals_conceded,
                                'status': 'updated' if not dry_run else 'would_update'
                            })
                            updated += 1
                        else:
                            skipped += 1
                    else:
                        skipped += 1
                else:
                    skipped += 1
                
                # Rate limiting - brief pause between API calls
                time.sleep(0.2)
                
            except Exception as e:
                logger.warning(f"Error resyncing saves for player {player_api_id} fixture {fixture_id_api}: {e}")
                errors += 1
        
        return jsonify({
            'message': 'Goalkeeper saves resync complete',
            'dry_run': dry_run,
            'found': len(results),
            'updated': updated,
            'skipped': skipped,
            'errors': errors,
            'details': details[:50],  # Limit response size
        })
        
    except Exception as e:
        logger.exception('admin_resync_goalkeeper_saves failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to resync goalkeeper saves')), 500


@api_bp.route('/admin/sync-limited-stats', methods=['POST'])
@require_api_key
def admin_sync_limited_stats():
    """
    Sync stats for players with limited coverage (e.g., National League).
    
    For leagues without full player stats, this fetches appearances/goals/assists
    from lineup and events data and stores them in the LoanedPlayer record.
    
    Request body (optional):
    {
        "dry_run": true,       // Preview mode (default: false)
        "player_id": 298062,   // Filter to specific player (optional)
        "team_api_id": 1834,   // Filter to specific team (optional)
        "force": false         // Re-sync even if stats already exist (default: false)
    }
    """
    import time
    from src.api_football_client import APIFootballClient
    
    try:
        data = request.get_json(force=True) if request.data else {}
        dry_run = data.get('dry_run', False)
        player_id_filter = data.get('player_id')
        team_api_id_filter = data.get('team_api_id')
        force = data.get('force', False)
        
        logger.info(f"Admin sync-limited-stats: dry_run={dry_run}, player_id={player_id_filter}, force={force}")
        
        # Debug: Check all unique stats_coverage values
        all_coverages = db.session.query(LoanedPlayer.stats_coverage).distinct().all()
        logger.info(f"DEBUG: All stats_coverage values in DB: {[c[0] for c in all_coverages]}")
        
        # Debug: Count by coverage
        limited_count_raw = LoanedPlayer.query.filter(LoanedPlayer.stats_coverage == 'limited').count()
        logger.info(f"DEBUG: Raw count of stats_coverage='limited': {limited_count_raw}")
        
        # Find players with limited stats coverage
        query = LoanedPlayer.query.filter(
            LoanedPlayer.stats_coverage == 'limited',
            LoanedPlayer.is_active.is_(True),
            LoanedPlayer.player_id > 0,  # Exclude manual entries
        )
        
        if player_id_filter:
            query = query.filter(LoanedPlayer.player_id == player_id_filter)
        
        limited_players = query.all()
        logger.info(f"DEBUG: Found {len(limited_players)} limited players after all filters")
        
        if not limited_players:
            return jsonify({
                'message': 'No players with limited stats coverage found',
                'dry_run': dry_run,
                'processed': 0,
            })
        
        api_client = APIFootballClient()
        
        # Determine season
        now_utc = datetime.now(timezone.utc)
        current_year = now_utc.year
        current_month = now_utc.month
        season = current_year if current_month >= 8 else current_year - 1
        
        updated = 0
        skipped = 0
        errors = 0
        details = []
        
        for loan in limited_players:
            try:
                # Get loan team API ID
                loan_team = Team.query.get(loan.loan_team_id)
                if not loan_team or not loan_team.team_id:
                    skipped += 1
                    details.append({
                        'player_id': loan.player_id,
                        'player_name': loan.player_name,
                        'status': 'skipped_no_team'
                    })
                    continue
                
                team_api_id = loan_team.team_id
                
                # Apply team filter if specified
                if team_api_id_filter and team_api_id != team_api_id_filter:
                    continue
                
                # Skip if already has stats (unless force=true)
                if not force and loan.appearances and loan.appearances > 0:
                    skipped += 1
                    details.append({
                        'player_id': loan.player_id,
                        'player_name': loan.player_name,
                        'status': 'skipped_has_stats',
                        'appearances': loan.appearances,
                    })
                    continue
                
                # Fetch limited stats from API
                limited_stats = api_client.get_player_limited_stats(
                    player_id=loan.player_id,
                    player_name=loan.player_name,
                    team_api_id=team_api_id,
                    season=season,
                    max_fixtures=50
                )
                
                if dry_run:
                    details.append({
                        'player_id': loan.player_id,
                        'player_name': loan.player_name,
                        'status': 'would_update',
                        'new_stats': {
                            'appearances': limited_stats['appearances'],
                            'goals': limited_stats['goals'],
                            'assists': limited_stats['assists'],
                            'yellows': limited_stats['yellows'],
                            'reds': limited_stats['reds'],
                        }
                    })
                else:
                    # Update the loan record
                    loan.appearances = limited_stats['appearances']
                    loan.goals = limited_stats['goals']
                    loan.assists = limited_stats['assists']
                    loan.yellows = limited_stats['yellows']
                    loan.reds = limited_stats['reds']
                    loan.updated_at = datetime.now(timezone.utc)
                    db.session.add(loan)
                    
                    details.append({
                        'player_id': loan.player_id,
                        'player_name': loan.player_name,
                        'status': 'updated',
                        'stats': {
                            'appearances': limited_stats['appearances'],
                            'goals': limited_stats['goals'],
                            'assists': limited_stats['assists'],
                        }
                    })
                    updated += 1
                
                # Rate limiting
                time.sleep(0.3)
                
            except Exception as e:
                logger.warning(f"Error syncing limited stats for player {loan.player_id}: {e}")
                errors += 1
                details.append({
                    'player_id': loan.player_id,
                    'player_name': loan.player_name,
                    'status': f'error: {str(e)}'
                })
        
        if not dry_run and updated > 0:
            db.session.commit()
        
        return jsonify({
            'message': 'Limited stats sync complete',
            'dry_run': dry_run,
            'found': len(limited_players),
            'updated': updated,
            'skipped': skipped,
            'errors': errors,
            'details': details,
        })
        
    except Exception as e:
        logger.exception('admin_sync_limited_stats failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to sync limited stats')), 500


@api_bp.route('/admin/loans/fix-miscategorized', methods=['POST'])
@require_api_key
def admin_fix_miscategorized_loans():
    """
    Fix miscategorized loans by re-verifying against API-Football transfer data.
    
    This fetches the actual transfer history for each player and verifies the loan
    direction matches what's recorded. If there's a mismatch (e.g., a loan return
    was misidentified as a new loan), it fixes the record.
    
    Body: { 
        dry_run?: bool (default: true),
        limit?: int (default: 50, use 0 for all),
        window_key?: str (filter to specific window, e.g. '2024-25::FULL'),
        background?: bool (default: false) - run in background and return job ID
    }
    """
    from flask import copy_current_request_context
    
    data = request.get_json() or {}
    background = bool(data.get('background', False))
    
    if background:
        # Start background job
        job_id = _create_background_job('fix_miscategorized')
        
        @copy_current_request_context
        def run_fix_in_background():
            try:
                result = _run_fix_miscategorized_logic(data, job_id)
                _update_job(job_id, status='completed', results=result, completed_at=datetime.now(timezone.utc).isoformat())
            except Exception as e:
                logger.exception(f'Background fix job {job_id} failed')
                _update_job(job_id, status='failed', error=str(e), completed_at=datetime.now(timezone.utc).isoformat())
        
        thread = threading.Thread(target=run_fix_in_background)
        thread.start()
        
        return jsonify({
            'message': 'Fix miscategorized job started in background',
            'job_id': job_id,
            'status': 'running',
            'check_status_url': f'/api/admin/jobs/{job_id}'
        })
    
    # Synchronous mode
    try:
        result = _run_fix_miscategorized_logic(data)
        return jsonify(result)
    except Exception as e:
        logger.exception('admin_fix_miscategorized_loans failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to verify/fix loans')), 500


def _run_fix_miscategorized_logic(data: dict, job_id: str = None) -> dict:
    """Core logic for fixing miscategorized loans. Can be run sync or in background."""
    from src.api_football_client import is_new_loan_transfer
    
    try:
        dry_run = bool(data.get('dry_run', True))
        limit_param = int(data.get('limit', 50))
        process_all = limit_param == 0
        limit = 10000 if process_all else min(limit_param, 200)
        window_filter = data.get('window_key')
        
        # Build query for active loans
        query = LoanedPlayer.query.filter(
            LoanedPlayer.is_active.is_(True),
            LoanedPlayer.can_fetch_stats.is_(True),
            LoanedPlayer.player_id > 0
        )
        
        if window_filter:
            query = query.filter(LoanedPlayer.window_key == window_filter)
        
        if not process_all:
            query = query.limit(limit)
        
        loans_to_check = query.order_by(LoanedPlayer.updated_at.desc()).all()
        total_to_process = len(loans_to_check)
        
        # Update job with total count if running in background
        if job_id:
            _update_job(job_id, total=total_to_process, progress=0)
        
        fixed = 0
        verified_correct = 0
        no_loan_found = 0
        api_errors = 0
        details = []
        
        for idx, loan in enumerate(loans_to_check):
            # Update progress for background jobs
            if job_id and idx % 5 == 0:
                _update_job(job_id, progress=idx, current_player=loan.player_name)
            try:
                player_id = loan.player_id
                
                # Get the team API IDs
                primary_team = Team.query.get(loan.primary_team_id)
                loan_team = Team.query.get(loan.loan_team_id)
                
                if not primary_team or not loan_team:
                    details.append({
                        'id': loan.id,
                        'player_name': loan.player_name,
                        'status': 'skipped_missing_team',
                    })
                    continue
                
                primary_api_id = primary_team.team_id
                loan_api_id = loan_team.team_id
                
                # Fetch player's transfer history from API-Football
                transfers_resp = api_client.get_player_transfers(player_id)
                if not transfers_resp:
                    api_errors += 1
                    details.append({
                        'id': loan.id,
                        'player_name': loan.player_name,
                        'status': 'api_error',
                    })
                    continue
                
                # Parse window dates for filtering
                try:
                    window_start, window_end = api_client._parse_window_key(loan.window_key)
                except:
                    window_start, window_end = None, None
                
                # Find the actual loan transfer for this player in this window
                actual_loan_found = False
                correct_primary_id = None
                correct_loan_id = None
                transfer_date = None
                
                for transfer_block in transfers_resp:
                    for t in transfer_block.get('transfers', []):
                        transfer_type = t.get('type', '')
                        t_date = t.get('date', '')
                        
                        # Only consider NEW loans (not returns)
                        if not is_new_loan_transfer(transfer_type):
                            continue
                        
                        # Check if transfer is in the window
                        if window_start and window_end and t_date:
                            try:
                                from datetime import datetime as dt
                                t_dt = dt.strptime(t_date, '%Y-%m-%d').date()
                                if not (window_start <= t_dt <= window_end):
                                    continue
                            except:
                                pass
                        
                        teams_data = t.get('teams', {})
                        out_team = teams_data.get('out', {})
                        in_team = teams_data.get('in', {})
                        
                        out_id = out_team.get('id')
                        in_id = in_team.get('id')
                        
                        # Check if this transfer involves our recorded teams
                        if {out_id, in_id} == {primary_api_id, loan_api_id}:
                            actual_loan_found = True
                            # In API-Football: out = parent club, in = loan destination
                            correct_primary_id = out_id
                            correct_loan_id = in_id
                            transfer_date = t_date
                            break
                    
                    if actual_loan_found:
                        break
                
                if not actual_loan_found:
                    no_loan_found += 1
                    details.append({
                        'id': loan.id,
                        'player_name': loan.player_name,
                        'recorded_parent': loan.primary_team_name,
                        'recorded_loan': loan.loan_team_name,
                        'status': 'no_matching_loan_in_api',
                    })
                    continue
                
                # Check if the direction matches
                is_correct = (correct_primary_id == primary_api_id and correct_loan_id == loan_api_id)
                
                if is_correct:
                    verified_correct += 1
                    details.append({
                        'id': loan.id,
                        'player_name': loan.player_name,
                        'parent': loan.primary_team_name,
                        'loan': loan.loan_team_name,
                        'status': 'verified_correct',
                    })
                else:
                    # Direction is wrong - need to swap
                    old_primary = loan.primary_team_name
                    old_loan = loan.loan_team_name
                    old_primary_id = loan.primary_team_id
                    old_loan_id = loan.loan_team_id
                    
                    if not dry_run:
                        loan.primary_team_id = old_loan_id
                        loan.primary_team_name = old_loan
                        loan.loan_team_id = old_primary_id
                        loan.loan_team_name = old_primary
                        loan.reviewer_notes = (loan.reviewer_notes or '') + f' | FIXED: Teams swapped (verified via API, transfer date: {transfer_date})'
                        loan.updated_at = datetime.now(timezone.utc)
                    
                    fixed += 1
                    details.append({
                        'id': loan.id,
                        'player_name': loan.player_name,
                        'old_parent': old_primary,
                        'old_loan': old_loan,
                        'new_parent': old_loan,
                        'new_loan': old_primary,
                        'transfer_date': transfer_date,
                        'status': 'fixed' if not dry_run else 'would_fix',
                    })
                
                # Rate limiting
                time.sleep(0.15)
                
            except Exception as e:
                logger.warning(f"Error checking loan {loan.id}: {e}")
                api_errors += 1
                details.append({
                    'id': loan.id,
                    'player_name': loan.player_name,
                    'status': 'error',
                    'error': str(e)
                })
        
        if not dry_run and fixed > 0:
            db.session.commit()
        
        logger.info(f"Fix miscategorized loans: dry_run={dry_run}, checked={len(loans_to_check)}, fixed={fixed}, correct={verified_correct}")
        
        return {
            'message': 'Loan verification complete',
            'dry_run': dry_run,
            'checked': len(loans_to_check),
            'verified_correct': verified_correct,
            'fixed': fixed,
            'no_loan_found': no_loan_found,
            'api_errors': api_errors,
            'details': details,
        }
        
    except Exception as e:
        logger.exception('_run_fix_miscategorized_logic failed')
        db.session.rollback()
        raise


@api_bp.route('/admin/jobs/<job_id>', methods=['GET'])
@require_api_key
def get_job_status(job_id: str):
    """Get the status of a background job."""
    job = _get_job(job_id)
    if not job:
        return jsonify({'error': 'Job not found'}), 404
    return jsonify(job)


@api_bp.route('/admin/loans/sync-denormalized-stats', methods=['POST'])
@require_api_key
def admin_sync_denormalized_stats():
    """
    Sync aggregated stats from fixture_player_stats to loaned_players.
    
    This updates the denormalized appearances, goals, assists columns in loaned_players
    by aggregating from fixture_player_stats.
    
    Body: { dry_run?: bool (default: false) }
    """
    from src.models.weekly import FixturePlayerStats
    from sqlalchemy import func
    
    try:
        data = request.get_json() or {}
        dry_run = bool(data.get('dry_run', False))
        
        # Get all active loans
        active_loans = LoanedPlayer.query.filter(
            LoanedPlayer.is_active.is_(True),
            LoanedPlayer.player_id > 0
        ).all()
        
        updated = 0
        details = []
        
        for loan in active_loans:
            # Get the loan team's API ID
            loan_team = Team.query.get(loan.loan_team_id)
            if not loan_team:
                continue
            
            # Aggregate stats from fixture_player_stats
            stats = db.session.query(
                func.count(FixturePlayerStats.id).label('appearances'),
                func.coalesce(func.sum(FixturePlayerStats.goals), 0).label('goals'),
                func.coalesce(func.sum(FixturePlayerStats.assists), 0).label('assists'),
                func.coalesce(func.sum(FixturePlayerStats.minutes), 0).label('minutes'),
                func.coalesce(func.sum(FixturePlayerStats.saves), 0).label('saves'),
                func.coalesce(func.sum(FixturePlayerStats.yellows), 0).label('yellows'),
                func.coalesce(func.sum(FixturePlayerStats.reds), 0).label('reds')
            ).filter(
                FixturePlayerStats.player_api_id == loan.player_id,
                FixturePlayerStats.team_api_id == loan_team.team_id
            ).first()
            
            if stats and stats.appearances > 0:
                old_apps = loan.appearances
                old_goals = loan.goals
                old_assists = loan.assists
                old_saves = loan.saves or 0
                
                if not dry_run:
                    loan.appearances = stats.appearances
                    loan.goals = stats.goals
                    loan.assists = stats.assists
                    loan.minutes_played = stats.minutes
                    loan.saves = stats.saves
                    loan.yellows = stats.yellows
                    loan.reds = stats.reds
                    loan.updated_at = datetime.now(timezone.utc)
                
                if stats.appearances != old_apps or stats.goals != old_goals or stats.assists != old_assists or stats.saves != old_saves:
                    updated += 1
                    details.append({
                        'player_name': loan.player_name,
                        'loan_team': loan.loan_team_name,
                        'old_stats': f'{old_apps} apps, {old_goals} g, {old_assists} a, {old_saves} saves',
                        'new_stats': f'{stats.appearances} apps, {stats.goals} g, {stats.assists} a, {stats.saves} saves'
                    })
        
        if not dry_run and updated > 0:
            db.session.commit()
        
        logger.info(f"Sync denormalized stats: dry_run={dry_run}, checked={len(active_loans)}, updated={updated}")
        
        return jsonify({
            'message': 'Stats sync complete',
            'dry_run': dry_run,
            'checked': len(active_loans),
            'updated': updated,
            'details': details[:100]  # Limit to 100 for response size
        })
        
    except Exception as e:
        logger.exception('admin_sync_denormalized_stats failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to sync stats')), 500


@api_bp.route('/admin/loans/reconcile-ids', methods=['POST'])
@require_api_key
def admin_reconcile_player_ids():
    """
    Detect and fix player ID mismatches AND sync missing stats.
    
    Uses a hybrid approach:
    1. Check recent fixtures (last 10) first
    2. If not found, check ALL season fixtures
    3. If still not found, verify via team squad API
    
    For players found:
    - If ID mismatches -> reconcile the ID
    - If ID matches -> sync their stats
    - If not in fixtures but in squad -> verify ID or mark as no appearances
    - If not in squad -> may have left club
    
    Body: { 
        dry_run?: bool (default: true),
        limit?: int (default: 50, use 0 for all),
        background?: bool (default: false) - run in background and return job ID
    }
    """
    from src.models.weekly import FixturePlayerStats, Fixture
    from flask import copy_current_request_context
    
    data = request.get_json() or {}
    background = bool(data.get('background', False))
    
    if background:
        # Start background job
        job_id = _create_background_job('reconcile_ids')
        
        @copy_current_request_context
        def run_reconcile_in_background():
            try:
                result = _run_reconcile_ids_logic(data, job_id)
                _update_job(job_id, status='completed', results=result, completed_at=datetime.now(timezone.utc).isoformat())
            except Exception as e:
                logger.exception(f'Background reconcile job {job_id} failed')
                _update_job(job_id, status='failed', error=str(e), completed_at=datetime.now(timezone.utc).isoformat())
        
        thread = threading.Thread(target=run_reconcile_in_background)
        thread.start()
        
        return jsonify({
            'message': 'Reconcile job started in background',
            'job_id': job_id,
            'status': 'running',
            'check_status_url': f'/api/admin/jobs/{job_id}'
        })
    
    # Synchronous mode
    try:
        result = _run_reconcile_ids_logic(data)
        return jsonify(result)
    except Exception as e:
        logger.exception('admin_reconcile_player_ids failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to reconcile player IDs')), 500


def _run_reconcile_ids_logic(data: dict, job_id: str = None) -> dict:
    """Core logic for reconciling player IDs. Can be run sync or in background."""
    from src.models.weekly import FixturePlayerStats, Fixture
    
    def _sync_player_stats_from_fixture(fixture_api_id: int, player_api_id: int, team_api_id: int, player_stats: dict) -> dict | None:
        """Create or update fixture_player_stats record from API data."""
        fixture = Fixture.query.filter_by(fixture_id_api=fixture_api_id).first()
        if not fixture:
            return None
        
        existing = FixturePlayerStats.query.filter_by(
            fixture_id=fixture.id,
            player_api_id=player_api_id,
            team_api_id=team_api_id
        ).first()
        
        if existing:
            return None  # Already synced
        
        stats = player_stats.get('statistics', [{}])[0] if player_stats.get('statistics') else {}
        games = stats.get('games', {})
        goals_data = stats.get('goals', {})
        passes = stats.get('passes', {})
        shots = stats.get('shots', {})
        cards = stats.get('cards', {})
        
        new_stat = FixturePlayerStats(
            fixture_id=fixture.id,
            player_api_id=player_api_id,
            team_api_id=team_api_id,
            minutes=games.get('minutes') or 0,
            position=games.get('position'),
            number=games.get('number'),
            rating=float(games.get('rating')) if games.get('rating') else None,
            captain=games.get('captain', False),
            substitute=games.get('substitute', False),
            goals=goals_data.get('total') or 0,
            assists=goals_data.get('assists') or 0,
            goals_conceded=goals_data.get('conceded'),
            saves=goals_data.get('saves'),
            yellows=cards.get('yellow') or 0,
            reds=cards.get('red') or 0,
            shots_total=shots.get('total'),
            shots_on=shots.get('on'),
            passes_total=passes.get('total'),
        )
        db.session.add(new_stat)
        return {
            'fixture_id': fixture_api_id,
            'minutes': new_stat.minutes,
            'goals': new_stat.goals,
            'assists': new_stat.assists
        }
    
    def _name_matches(api_name: str, db_name: str) -> bool:
        """Check if player names match (handles initials like 'J. Moorhouse' vs 'Jack Moorhouse')."""
        if not api_name or not db_name:
            return False
        
        api_lower = api_name.lower().strip()
        db_lower = db_name.lower().strip()
        
        # Exact match
        if api_lower == db_lower:
            return True
        
        # Last name match with first initial
        db_parts = db_lower.split()
        api_parts = api_lower.split()
        
        if len(db_parts) >= 2 and len(api_parts) >= 2:
            # Check if last names match
            if db_parts[-1] in api_lower or api_parts[-1] in db_lower:
                # Check if first initials match
                if db_lower[0] == api_lower[0]:
                    return True
        
        return False
    
    def _search_fixtures_for_player(fixtures: list, team_id: int, player_name: str, old_player_id: int):
        """
        Search fixtures for a player by name.
        Returns (found_different_id, found_same_id, player_fixtures_data)
        """
        found_player_id = None
        found_same_id = False
        player_fixtures_data = []
        
        for fixture in fixtures:
            fixture_id = fixture.get('fixture', {}).get('id')
            if not fixture_id:
                continue
            
            # Get player stats for this fixture
            fixture_players = api_client._make_request('fixtures/players', {
                'fixture': fixture_id
            }).get('response', [])
            
            for team_data in fixture_players:
                if team_data.get('team', {}).get('id') != team_id:
                    continue
                
                for player_data in team_data.get('players', []):
                    player_info = player_data.get('player', {})
                    api_player_name = player_info.get('name', '')
                    api_player_id = player_info.get('id')
                    
                    if _name_matches(api_player_name, player_name):
                        if api_player_id != old_player_id:
                            # ID mismatch found
                            found_player_id = api_player_id
                        else:
                            # Same ID - collect for stats sync
                            found_same_id = True
                            player_fixtures_data.append({
                                'fixture_id': fixture_id,
                                'player_data': player_data
                            })
                        break
                
                if found_player_id:
                    break
            
            if found_player_id:
                break
            
            # Rate limiting
            time.sleep(0.12)
        
        return found_player_id, found_same_id, player_fixtures_data
    
    try:
        dry_run = bool(data.get('dry_run', True))
        limit_param = int(data.get('limit', 50))
        # limit=0 means process ALL players
        process_all = limit_param == 0
        limit = 10000 if process_all else min(limit_param, 100)
        
        # Find active loans with 0 fixture stats OR only "ghost" stats (0 total minutes)
        # Ghost stats occur when API-Football uses different player IDs in squad vs fixture data
        loans_with_no_stats = []
        query = LoanedPlayer.query.filter(
            LoanedPlayer.is_active.is_(True),
            LoanedPlayer.can_fetch_stats.is_(True),
            LoanedPlayer.player_id > 0
        )
        if not process_all:
            query = query.limit(limit * 2)
        active_loans = query.all()
        
        for loan in active_loans:
            loan_team = Team.query.get(loan.loan_team_id)
            if not loan_team:
                continue
            
            # Check both count and total minutes to catch "ghost" stats
            # Ghost stats: stat_count > 0 but total_minutes == 0 (wrong player ID in API-Football)
            stats_result = db.session.query(
                db.func.count(FixturePlayerStats.id).label('stat_count'),
                db.func.coalesce(db.func.sum(FixturePlayerStats.minutes), 0).label('total_minutes')
            ).filter(
                FixturePlayerStats.player_api_id == loan.player_id,
                FixturePlayerStats.team_api_id == loan_team.team_id
            ).first()
            
            stat_count = stats_result.stat_count if stats_result else 0
            total_minutes = stats_result.total_minutes if stats_result else 0
            
            # Include if no stats OR has ghost stats (stats exist but 0 total minutes)
            needs_reconcile = stat_count == 0 or (stat_count > 0 and total_minutes == 0)
            
            if needs_reconcile:
                loans_with_no_stats.append({
                    'loan': loan,
                    'loan_team': loan_team,
                    'player_id': loan.player_id,
                    'player_name': loan.player_name,
                    'has_ghost_stats': stat_count > 0 and total_minutes == 0
                })
            
            if len(loans_with_no_stats) >= limit:
                break
        
        id_reconciled = 0
        id_reconciled_via_squad = 0
        stats_synced = 0
        verified_no_appearances = 0
        loan_destination_changed = 0
        player_left_club_count = 0
        duplicate_detected = 0
        not_in_squad = 0
        details = []
        total_to_process = len(loans_with_no_stats)
        
        # Update job with total count if running in background
        if job_id:
            _update_job(job_id, total=total_to_process, progress=0)
        
        for idx, item in enumerate(loans_with_no_stats):
            loan = item['loan']
            loan_team = item['loan_team']
            player_name = item['player_name']
            old_player_id = item['player_id']
            
            # Update progress for background jobs
            if job_id and idx % 5 == 0:  # Update every 5 players
                _update_job(job_id, progress=idx, current_player=player_name)
            
            try:
                # STEP 1: Check recent fixtures (last 10)
                recent_fixtures = api_client._make_request('fixtures', {
                    'team': loan_team.team_id,
                    'season': 2025,
                    'last': 10
                }).get('response', [])
                
                found_player_id, found_same_id, player_fixtures_data = _search_fixtures_for_player(
                    recent_fixtures, loan_team.team_id, player_name, old_player_id
                )
                
                # STEP 2: If not found in recent, check ALL season fixtures
                if not found_player_id and not found_same_id:
                    logger.debug(f"Player {player_name} not in recent fixtures, checking full season...")
                    
                    all_fixtures = api_client._make_request('fixtures', {
                        'team': loan_team.team_id,
                        'season': 2025,
                        'status': 'FT'  # Only finished matches
                    }).get('response', [])
                    
                    # Filter out fixtures we already checked
                    recent_ids = {f.get('fixture', {}).get('id') for f in recent_fixtures}
                    remaining_fixtures = [f for f in all_fixtures if f.get('fixture', {}).get('id') not in recent_ids]
                    
                    if remaining_fixtures:
                        found_player_id, found_same_id, player_fixtures_data = _search_fixtures_for_player(
                            remaining_fixtures, loan_team.team_id, player_name, old_player_id
                        )
                
                # Process results
                has_ghost_stats = item.get('has_ghost_stats', False)
                
                if found_player_id:
                    # Case 1: ID mismatch found in fixtures - reconcile
                    # Also delete ghost stats (0-minute records with wrong player ID)
                    ghost_stats_deleted = 0
                    if has_ghost_stats and not dry_run:
                        ghost_stats_deleted = FixturePlayerStats.query.filter(
                            FixturePlayerStats.player_api_id == old_player_id,
                            FixturePlayerStats.team_api_id == loan_team.team_id,
                            FixturePlayerStats.minutes == 0
                        ).delete()
                        logger.info(f"Deleted {ghost_stats_deleted} ghost stat records for player {player_name} (old ID {old_player_id})")
                    
                    detail = {
                        'loan_id': loan.id,
                        'player_name': player_name,
                        'loan_team': loan.loan_team_name,
                        'old_player_id': old_player_id,
                        'new_player_id': found_player_id,
                        'action': 'id_reconcile',
                        'had_ghost_stats': has_ghost_stats,
                        'ghost_stats_deleted': ghost_stats_deleted if not dry_run else ('would_delete' if has_ghost_stats else 0),
                        'status': 'would_reconcile' if dry_run else 'reconciled'
                    }
                    
                    if not dry_run:
                        loan.player_id = found_player_id
                        loan.reviewer_notes = (loan.reviewer_notes or '') + f' | ID reconciled: {old_player_id} ‚Üí {found_player_id}'
                        if has_ghost_stats:
                            loan.reviewer_notes += f' (deleted {ghost_stats_deleted} ghost stats)'
                        loan.updated_at = datetime.now(timezone.utc)
                    
                    id_reconciled += 1
                    details.append(detail)
                    
                elif found_same_id and player_fixtures_data:
                    # Case 2: ID correct, sync stats from fixtures
                    synced_fixtures = []
                    
                    if not dry_run:
                        for fx_data in player_fixtures_data:
                            result = _sync_player_stats_from_fixture(
                                fx_data['fixture_id'],
                                old_player_id,
                                loan_team.team_id,
                                fx_data['player_data']
                            )
                            if result:
                                synced_fixtures.append(result)
                    
                    detail = {
                        'loan_id': loan.id,
                        'player_name': player_name,
                        'loan_team': loan.loan_team_name,
                        'player_id': old_player_id,
                        'action': 'stats_sync',
                        'fixtures_found': len(player_fixtures_data),
                        'fixtures_synced': len(synced_fixtures) if not dry_run else len(player_fixtures_data),
                        'status': 'would_sync' if dry_run else 'synced'
                    }
                    
                    stats_synced += 1
                    details.append(detail)
                    
                else:
                    # STEP 3: Not found in ANY fixtures - check team squad
                    logger.debug(f"Player {player_name} not in any fixtures, checking squad...")
                    
                    squad_response = api_client._make_request('players/squads', {
                        'team': loan_team.team_id
                    }).get('response', [])
                    
                    squad_players = squad_response[0].get('players', []) if squad_response else []
                    
                    squad_match = None
                    for squad_player in squad_players:
                        squad_name = squad_player.get('name', '')
                        squad_id = squad_player.get('id')
                        
                        if _name_matches(squad_name, player_name):
                            squad_match = {
                                'id': squad_id,
                                'name': squad_name,
                                'position': squad_player.get('position'),
                                'number': squad_player.get('number')
                            }
                            break
                    
                    if squad_match:
                        if squad_match['id'] != old_player_id:
                            # Case 3a: ID mismatch found via squad
                            # Also delete ghost stats if present
                            ghost_stats_deleted = 0
                            if has_ghost_stats and not dry_run:
                                ghost_stats_deleted = FixturePlayerStats.query.filter(
                                    FixturePlayerStats.player_api_id == old_player_id,
                                    FixturePlayerStats.team_api_id == loan_team.team_id,
                                    FixturePlayerStats.minutes == 0
                                ).delete()
                                logger.info(f"Deleted {ghost_stats_deleted} ghost stat records for player {player_name} via squad (old ID {old_player_id})")
                            
                            detail = {
                                'loan_id': loan.id,
                                'player_name': player_name,
                                'loan_team': loan.loan_team_name,
                                'old_player_id': old_player_id,
                                'new_player_id': squad_match['id'],
                                'action': 'id_reconcile_via_squad',
                                'had_ghost_stats': has_ghost_stats,
                                'ghost_stats_deleted': ghost_stats_deleted if not dry_run else ('would_delete' if has_ghost_stats else 0),
                                'status': 'would_reconcile' if dry_run else 'reconciled'
                            }
                            
                            if not dry_run:
                                loan.player_id = squad_match['id']
                                loan.reviewer_notes = (loan.reviewer_notes or '') + f' | ID reconciled via squad: {old_player_id} ‚Üí {squad_match["id"]}'
                                if has_ghost_stats:
                                    loan.reviewer_notes += f' (deleted {ghost_stats_deleted} ghost stats)'
                                loan.updated_at = datetime.now(timezone.utc)
                            
                            id_reconciled_via_squad += 1
                            details.append(detail)
                        else:
                            # Case 3b: ID correct, player in squad but no appearances
                            detail = {
                                'loan_id': loan.id,
                                'player_name': player_name,
                                'loan_team': loan.loan_team_name,
                                'player_id': old_player_id,
                                'action': 'verified_no_appearances',
                                'squad_position': squad_match.get('position'),
                                'squad_number': squad_match.get('number'),
                                'status': 'verified'
                            }
                            
                            verified_no_appearances += 1
                            details.append(detail)
                    else:
                        # Case 4: Not found in squad - check for consecutive loan (moved to different team)
                        logger.debug(f"Player {player_name} not in squad, checking for consecutive loan...")
                        
                        # Get player's transfer history to check for newer loan
                        transfers = api_client.get_player_transfers(old_player_id)
                        
                        newer_loan = None
                        player_left_club = None
                        # Use created_at as approximate loan start date
                        current_loan_date = loan.created_at.date() if loan.created_at else None
                        primary_team = Team.query.get(loan.primary_team_id)
                        primary_team_api_id = primary_team.team_id if primary_team else None
                        
                        # Check for free agent / released / permanent transfer out
                        for transfer in transfers:
                            for t in transfer.get('transfers', []):
                                transfer_type = t.get('type', '').lower()
                                transfer_date_str = t.get('date', '')
                                teams_out = t.get('teams', {}).get('out', {})
                                teams_in = t.get('teams', {}).get('in', {})
                                
                                # Check if player left the parent club permanently
                                if teams_out.get('id') == primary_team_api_id:
                                    if transfer_type in ['free agent', 'free', 'n/a', ''] or teams_in.get('id') is None:
                                        try:
                                            transfer_date = date.fromisoformat(transfer_date_str) if transfer_date_str else None
                                        except:
                                            transfer_date = None
                                        
                                        if not current_loan_date or not transfer_date or transfer_date > current_loan_date:
                                            player_left_club = {
                                                'transfer_type': transfer_type or 'released',
                                                'transfer_date': transfer_date_str,
                                                'destination': teams_in.get('name') or 'Free agent'
                                            }
                                            break
                            if player_left_club:
                                break
                        
                        # Collect all loan transfers to find the most recent one to a different team
                        loan_transfers = []
                        if not player_left_club:
                            for transfer in transfers:
                                for t in transfer.get('transfers', []):
                                    transfer_type = t.get('type', '').lower()
                                    transfer_date_str = t.get('date', '')
                                    
                                    # Only look for loan transfers (not loan returns)
                                    if transfer_type != 'loan':
                                        continue
                                    
                                    teams_out = t.get('teams', {}).get('out', {})
                                    teams_in = t.get('teams', {}).get('in', {})
                                    
                                    # Must be from parent club or current loan team
                                    if teams_out.get('id') not in [primary_team_api_id, loan_team.team_id]:
                                        continue
                                    
                                    # Must be to a DIFFERENT team than current loan team
                                    if teams_in.get('id') == loan_team.team_id:
                                        continue
                                    
                                    try:
                                        transfer_date = date.fromisoformat(transfer_date_str) if transfer_date_str else None
                                    except:
                                        transfer_date = None
                                    
                                    loan_transfers.append({
                                        'new_team_id': teams_in.get('id'),
                                        'new_team_name': teams_in.get('name'),
                                        'transfer_date': transfer_date,
                                        'transfer_date_str': transfer_date_str,
                                        'old_team_name': loan.loan_team_name
                                    })
                        
                        # Find the most recent loan transfer (if any)
                        if loan_transfers:
                            # Sort by date (most recent first), handling None dates
                            loan_transfers.sort(key=lambda x: x['transfer_date'] or date.min, reverse=True)
                            newest = loan_transfers[0]
                            
                            # Only use it if it's after our recorded loan date (or if we can't compare)
                            if not current_loan_date or not newest['transfer_date'] or newest['transfer_date'] > current_loan_date:
                                newer_loan = {
                                    'new_team_id': newest['new_team_id'],
                                    'new_team_name': newest['new_team_name'],
                                    'transfer_date': newest['transfer_date_str'],
                                    'old_team_name': newest['old_team_name']
                                }
                        
                        if player_left_club:
                            # Player was released/transferred permanently - deactivate loan
                            detail = {
                                'loan_id': loan.id,
                                'player_name': player_name,
                                'loan_team': loan.loan_team_name,
                                'player_id': old_player_id,
                                'transfer_type': player_left_club['transfer_type'],
                                'transfer_date': player_left_club['transfer_date'],
                                'destination': player_left_club['destination'],
                                'action': 'player_left_club',
                                'status': 'would_deactivate' if dry_run else 'deactivated'
                            }
                            
                            if not dry_run:
                                loan.is_active = False
                                loan.reviewer_notes = (loan.reviewer_notes or '') + f' | Left club: {player_left_club["transfer_type"]} on {player_left_club["transfer_date"]}'
                                loan.updated_at = datetime.now(timezone.utc)
                            
                            player_left_club_count += 1
                            details.append(detail)
                            
                        elif newer_loan:
                            # Found a consecutive loan - update to new destination
                            new_team = Team.query.filter_by(team_id=newer_loan['new_team_id']).first()
                            
                            detail = {
                                'loan_id': loan.id,
                                'player_name': player_name,
                                'old_loan_team': newer_loan['old_team_name'],
                                'new_loan_team': newer_loan['new_team_name'],
                                'new_team_id': newer_loan['new_team_id'],
                                'transfer_date': newer_loan['transfer_date'],
                                'player_id': old_player_id,
                                'action': 'loan_destination_changed',
                                'status': 'would_update' if dry_run else 'updated'
                            }
                            
                            if not dry_run and new_team:
                                # Update loan to new destination
                                loan.loan_team_id = new_team.id
                                loan.loan_team_name = newer_loan['new_team_name']
                                loan.reviewer_notes = (loan.reviewer_notes or '') + f' | Consecutive loan: {newer_loan["old_team_name"]} ‚Üí {newer_loan["new_team_name"]} on {newer_loan["transfer_date"]}'
                                loan.updated_at = datetime.now(timezone.utc)
                            
                            loan_destination_changed += 1
                            details.append(detail)
                        else:
                            # Check if there's a duplicate record with same player name at a different team
                            # Match by last name AND same parent club (by name, since IDs may differ)
                            last_name = player_name.split()[-1].lower()
                            duplicate_record = LoanedPlayer.query.filter(
                                LoanedPlayer.id != loan.id,
                                LoanedPlayer.is_active.is_(True),
                                db.or_(
                                    LoanedPlayer.primary_team_id == loan.primary_team_id,
                                    LoanedPlayer.primary_team_name == loan.primary_team_name
                                ),
                                db.func.lower(LoanedPlayer.player_name).like(f'%{last_name}%')
                            ).first()
                            
                            if duplicate_record and duplicate_record.loan_team_id != loan.loan_team_id:
                                # Found a duplicate - this is likely the same player with different ID
                                detail = {
                                    'loan_id': loan.id,
                                    'player_name': player_name,
                                    'loan_team': loan.loan_team_name,
                                    'player_id': old_player_id,
                                    'duplicate_name': duplicate_record.player_name,
                                    'duplicate_team': duplicate_record.loan_team_name,
                                    'duplicate_id': duplicate_record.player_id,
                                    'action': 'duplicate_detected',
                                    'status': 'would_deactivate' if dry_run else 'deactivated'
                                }
                                
                                if not dry_run:
                                    loan.is_active = False
                                    loan.reviewer_notes = (loan.reviewer_notes or '') + f' | Duplicate: newer record exists as {duplicate_record.player_name} at {duplicate_record.loan_team_name}'
                                    loan.updated_at = datetime.now(timezone.utc)
                                
                                duplicate_detected += 1
                                details.append(detail)
                            else:
                                # No newer loan found - truly not in squad
                                detail = {
                                    'loan_id': loan.id,
                                    'player_name': player_name,
                                    'loan_team': loan.loan_team_name,
                                    'player_id': old_player_id,
                                    'action': 'not_in_squad',
                                    'status': 'not_found'
                                }
                                
                                not_in_squad += 1
                                details.append(detail)
                
            except Exception as e:
                logger.warning(f"Error processing player {loan.player_id}: {e}")
                details.append({
                    'loan_id': loan.id,
                    'player_name': player_name,
                    'status': 'error',
                    'error': str(e)
                })
        
        if not dry_run:
            db.session.commit()
        
        total_id_fixed = id_reconciled + id_reconciled_via_squad
        logger.info(f"Reconcile & sync: dry_run={dry_run}, checked={len(loans_with_no_stats)}, "
                   f"id_reconciled={id_reconciled}, id_via_squad={id_reconciled_via_squad}, "
                   f"stats_synced={stats_synced}, verified_no_appearances={verified_no_appearances}, "
                   f"loan_destination_changed={loan_destination_changed}, player_left={player_left_club_count}, "
                   f"duplicates={duplicate_detected}, not_in_squad={not_in_squad}")
        
        return {
            'message': 'Player ID reconciliation and stats sync complete',
            'dry_run': dry_run,
            'checked': len(loans_with_no_stats),
            'id_reconciled': id_reconciled,
            'id_reconciled_via_squad': id_reconciled_via_squad,
            'stats_synced': stats_synced,
            'verified_no_appearances': verified_no_appearances,
            'loan_destination_changed': loan_destination_changed,
            'player_left_club': player_left_club_count,
            'duplicate_detected': duplicate_detected,
            'not_in_squad': not_in_squad,
            'details': details,
        }
        
    except Exception as e:
        logger.exception('_run_reconcile_ids_logic failed')
        db.session.rollback()
        raise


# --- Admin: Missing names helpers ---
def _is_placeholder_name(name: str | None) -> bool:
    if not name:
        return True
    s = str(name).strip()
    if not s:
        return True
    low = s.lower()
    return low.startswith('player ') or low.startswith('unknown')


def _is_placeholder_team_name(name: str | None) -> bool:
    if not name:
        return True
    s = str(name).strip()
    if not s:
        return True
    return s.lower().startswith('team ')


def _update_team_name_if_missing(team_row, *, season: int, dry_run: bool = False) -> dict:
    """Update a Team row's name when it is a placeholder.

    Returns a dict with status and optional new_name/error for logging/testing.
    """
    if not team_row:
        return {'status': 'no_team_row'}

    current_name = getattr(team_row, 'name', None)
    api_team_id = getattr(team_row, 'team_id', None)

    if not _is_placeholder_team_name(current_name):
        return {'status': 'ok_existing', 'name': current_name}

    if not api_team_id:
        return {'status': 'missing_api_id'}

    try:
        info = api_client.get_team_by_id(int(api_team_id), season)
        new_name = (info.get('team') or {}).get('name') if isinstance(info, dict) else None
    except Exception as exc:  # pragma: no cover - network failures
        return {'status': 'error', 'error': str(exc)}

    if not new_name or _is_placeholder_team_name(new_name):
        return {'status': 'no_name_found'}

    if dry_run:
        return {'status': 'would_update', 'new_name': new_name}

    team_row.name = new_name
    return {'status': 'updated', 'new_name': new_name}

@api_bp.route('/admin/loans/missing-names', methods=['GET'])
@require_api_key
def admin_list_missing_player_names():
    """List loans whose player_name looks like a placeholder.

    Query params:
      - season: int (filters by window_key prefix)
      - primary_team_api_id: int (requires season)
      - primary_team_db_id: int
      - active_only: bool (default true)
      - limit: int (default 200)
    """
    try:
        season = request.args.get('season', type=int)
        primary_team_api_id = request.args.get('primary_team_api_id', type=int)
        primary_team_db_id = request.args.get('primary_team_db_id', type=int)
        active_only = request.args.get('active_only', 'true').lower() in ('true','1','yes','y')
        limit = request.args.get('limit', type=int) or 200

        q = LoanedPlayer.query
        if season is not None:
            slug = f"{season}-{str(season + 1)[-2:]}"
            q = q.filter(LoanedPlayer.window_key.like(f"{slug}%"))

        if primary_team_db_id:
            q = q.filter(LoanedPlayer.primary_team_id == int(primary_team_db_id))
        elif primary_team_api_id:
            if season is None:
                return jsonify({'error': 'season is required when using primary_team_api_id'}), 400
            row = Team.query.filter_by(team_id=primary_team_api_id, season=season).first()
            if not row:
                return jsonify({'error': f'Primary team api_id={primary_team_api_id} not found for season {season}'}), 404
            q = q.filter(LoanedPlayer.primary_team_id == row.id)

        if active_only:
            q = q.filter(LoanedPlayer.is_active.is_(True))

        # DB-side placeholder filter
        q = q.filter(
            or_(
                LoanedPlayer.player_name.is_(None),
                LoanedPlayer.player_name == '',
                LoanedPlayer.player_name.ilike('Player %'),
                LoanedPlayer.player_name.ilike('Unknown%'),
            )
        ).order_by(LoanedPlayer.updated_at.desc()).limit(limit)

        rows = q.all()
        return jsonify([r.to_dict() for r in rows])
    except Exception as e:
        logger.exception('admin_list_missing_player_names failed')
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/admin/loans/backfill-names', methods=['POST'])
@require_api_key
def admin_backfill_player_names():
    """Backfill player_name for placeholder rows using API-Football fallbacks.

    Body JSON options:
      - season: int (required to resolve primary_team_api_id)
      - primary_team_api_id: int (optional)
      - primary_team_db_id: int (optional)
      - active_only: bool (default true)
      - limit: int (default 200)
      - dry_run: bool (default false)
    """
    try:
        data = request.get_json() or {}
        season = data.get('season')
        season = int(season) if season is not None else api_client.current_season_start_year
        primary_team_api_id = data.get('primary_team_api_id')
        primary_team_db_id = data.get('primary_team_db_id')
        active_only = bool(data.get('active_only', True))
        limit = int(data.get('limit') or 200)
        dry_run = bool(data.get('dry_run'))

        q = LoanedPlayer.query
        if season is not None:
            slug = f"{season}-{str(season + 1)[-2:]}"
            q = q.filter(LoanedPlayer.window_key.like(f"{slug}%"))

        if primary_team_db_id:
            q = q.filter(LoanedPlayer.primary_team_id == int(primary_team_db_id))
        elif primary_team_api_id:
            row = Team.query.filter_by(team_id=int(primary_team_api_id), season=season).first()
            if not row:
                return jsonify({'error': f'Primary team api_id={primary_team_api_id} not found for season {season}'}), 404
            q = q.filter(LoanedPlayer.primary_team_id == row.id)

        if active_only:
            q = q.filter(LoanedPlayer.is_active.is_(True))

        q = q.filter(
            or_(
                LoanedPlayer.player_name.is_(None),
                LoanedPlayer.player_name == '',
                LoanedPlayer.player_name.ilike('Player %'),
                LoanedPlayer.player_name.ilike('Unknown%'),
            )
        ).order_by(LoanedPlayer.updated_at.desc()).limit(limit)

        rows = q.all()

        updated, skipped = 0, 0
        details = []
        team_updates = 0
        team_details = []

        # Make sure API client season aligns for lookups
        try:
            api_client.set_season_year(season)
        except Exception:
            pass

        for r in rows:
            try:
                info = api_client.get_player_by_id(int(r.player_id), season=season) or {}
                p = (info.get('player') or {}) if isinstance(info, dict) else {}
                name = p.get('name') or (f"{p.get('firstname','').strip()} {p.get('lastname','').strip()}".strip())
                if not name or _is_placeholder_name(name):
                    skipped += 1
                    details.append({'loan_id': r.id, 'player_id': r.player_id, 'status': 'no_name_found'})
                    continue
                if dry_run:
                    updated += 1
                    details.append({'loan_id': r.id, 'player_id': r.player_id, 'new_name': name, 'status': 'would_update'})
                else:
                    r.player_name = name
                    updated += 1
                    details.append({'loan_id': r.id, 'player_id': r.player_id, 'new_name': name, 'status': 'updated'})

                # Backfill team names (parent and loan) when missing
                primary_team = Team.query.get(r.primary_team_id) if r.primary_team_id else None
                if primary_team:
                    primary_result = _update_team_name_if_missing(primary_team, season=season, dry_run=dry_run)
                    if primary_result.get('status') in {'updated', 'would_update'}:
                        team_updates += 1
                        team_details.append({
                            'team_id': getattr(primary_team, 'team_id', None),
                            'db_id': getattr(primary_team, 'id', None),
                            'role': 'primary',
                            **{k: v for k, v in primary_result.items() if k != 'status'},
                            'status': primary_result['status'],
                        })
                        if not dry_run and primary_result.get('new_name') and _is_placeholder_team_name(r.primary_team_name):
                            r.primary_team_name = primary_result['new_name']

                loan_team = Team.query.get(r.loan_team_id) if r.loan_team_id else None
                if loan_team:
                    loan_result = _update_team_name_if_missing(loan_team, season=season, dry_run=dry_run)
                    if loan_result.get('status') in {'updated', 'would_update'}:
                        team_updates += 1
                        team_details.append({
                            'team_id': getattr(loan_team, 'team_id', None),
                            'db_id': getattr(loan_team, 'id', None),
                            'role': 'loan',
                            **{k: v for k, v in loan_result.items() if k != 'status'},
                            'status': loan_result['status'],
                        })
                        if not dry_run and loan_result.get('new_name') and _is_placeholder_team_name(r.loan_team_name):
                            r.loan_team_name = loan_result['new_name']
            except Exception as ex:
                skipped += 1
                details.append({'loan_id': r.id, 'player_id': r.player_id, 'status': f'error: {ex}'})

        if not dry_run and updated:
            db.session.commit()

        try:
            _append_run_history({
                'kind': 'backfill-player-names',
                'season': season,
                'team_api_id': int(primary_team_api_id) if primary_team_api_id else None,
                'updated': updated,
                'skipped': skipped,
                'dry_run': dry_run,
                'team_updates': team_updates,
            })
        except Exception:
            pass

        return jsonify({
            'season': season,
            'updated': updated,
            'skipped': skipped,
            'dry_run': dry_run,
            'processed': len(rows),
            'team_updates': team_updates,
            'team_details': team_details[:200],
            'details': details[:200]
        })
    except Exception as e:
        logger.exception('admin_backfill_player_names failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/admin/backfill-team-leagues/<int:season>', methods=['POST'])
@require_api_key
def admin_backfill_team_leagues(season: int):
    """
    Backfill missing Team.league_id for a given season using API‚ÄëFootball Top‚Äë5
    league mapping. Helpful if teams were created via admin seeding before
    syncing leagues/teams for that season.
    """
    try:
        if not season:
            return jsonify({'error': 'season is required'}), 400

        # Map: API team id -> { name, league_name, league_id, country }
        team_map = api_client.get_teams_with_leagues_for_season(season) or {}

        # Build an internal fallback mapping from existing rows (any season)
        # api_team_id -> existing league FK id
        existing_league_fk_by_api_id: dict[int, int] = {}
        for row in Team.query.filter(Team.league_id.isnot(None)).all():
            existing_league_fk_by_api_id[row.team_id] = row.league_id

        updated = 0
        created_leagues = 0
        examined = 0

        rows = Team.query.filter_by(season=season).all()
        for t in rows:
            examined += 1
            if t.league_id:
                continue
            meta = team_map.get(t.team_id)
            league_row = None
            if meta:
                league_api_id = meta.get('league_id')
                league_name = meta.get('league_name')
                league_country = meta.get('country') or 'Unknown'
                if league_api_id and league_name:
                    league_row = League.query.filter_by(league_id=league_api_id).first()
                    if not league_row:
                        league_row = League(
                            league_id=league_api_id,
                            name=league_name,
                            country=league_country,
                            season=season,
                            is_european_top_league=True,
                        )
                        db.session.add(league_row)
                        db.session.flush()
                        created_leagues += 1
            # Fallback: copy league FK from any season if we have one
            if league_row is None:
                fallback_fk = existing_league_fk_by_api_id.get(t.team_id)
                if fallback_fk:
                    t.league_id = fallback_fk
                    updated += 1
                    continue
            if league_row is None:
                continue
            t.league_id = league_row.id
            updated += 1

        db.session.commit()
        try:
            _append_run_history({
                'kind': 'backfill-team-leagues',
                'season': season,
                'updated': updated,
                'created_leagues': created_leagues,
                'message': f'Backfilled leagues for season {season}: updated {updated}, created {created_leagues}'
            })
        except Exception:
            pass
        return jsonify({
            'season': season,
            'examined': examined,
            'updated_teams': updated,
            'created_leagues': created_leagues,
        })
    except Exception as e:
        logger.exception('admin_backfill_team_leagues failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/admin/backfill-team-leagues', methods=['POST'])
@require_api_key
def admin_backfill_team_leagues_all():
    """
    Backfill Team.league_id across multiple seasons.

    Body (optional): { "seasons": [2023, 2024, ...] }
    If not provided, operates on all distinct Team.season values present.
    """
    try:
        payload = request.get_json() or {}
        seasons = payload.get('seasons')
        if not seasons:
            seasons = [row[0] for row in db.session.query(Team.season).distinct().all()]

        summary = []
        total_updated = 0
        total_created_leagues = 0
        total_examined = 0

        for season in seasons:
            try:
                season = int(season)
                team_map = api_client.get_teams_with_leagues_for_season(season) or {}
                # Build fallback from existing rows (any season)
                existing_league_fk_by_api_id: dict[int, int] = {}
                for row in Team.query.filter(Team.league_id.isnot(None)).all():
                    existing_league_fk_by_api_id[row.team_id] = row.league_id
                updated = 0
                created_leagues = 0
                examined = 0
                rows = Team.query.filter_by(season=season).all()
                for t in rows:
                    examined += 1
                    if t.league_id:
                        continue
                    meta = team_map.get(t.team_id)
                    league_row = None
                    if meta:
                        league_api_id = meta.get('league_id')
                        league_name = meta.get('league_name')
                        league_country = meta.get('country') or 'Unknown'
                        if league_api_id and league_name:
                            league_row = League.query.filter_by(league_id=league_api_id).first()
                            if not league_row:
                                league_row = League(
                                    league_id=league_api_id,
                                    name=league_name,
                                    country=league_country,
                                    season=season,
                                    is_european_top_league=True,
                                )
                                db.session.add(league_row)
                                db.session.flush()
                                created_leagues += 1
                    # Fallback: copy league FK from any season
                    if league_row is None:
                        fallback_fk = existing_league_fk_by_api_id.get(t.team_id)
                        if fallback_fk:
                            t.league_id = fallback_fk
                            updated += 1
                            continue
                    if league_row is None:
                        continue
                    t.league_id = league_row.id
                    updated += 1
                db.session.commit()
                summary.append({
                    'season': season,
                    'examined': examined,
                    'updated_teams': updated,
                    'created_leagues': created_leagues,
                })
                total_updated += updated
                total_created_leagues += created_leagues
                total_examined += examined
            except Exception:
                db.session.rollback()
                summary.append({'season': int(season), 'error': 'failed'})

        try:
            _append_run_history({
                'kind': 'backfill-team-leagues-all',
                'seasons': seasons,
                'updated': total_updated,
                'created_leagues': total_created_leagues,
                'message': f'Backfilled all seasons ({len(seasons)}): updated {total_updated}, created leagues {total_created_leagues}'
            })
        except Exception:
            pass
        return jsonify({
            'summary': summary,
            'totals': {
                'seasons': len(seasons),
                'examined': total_examined,
                'updated_teams': total_updated,
                'created_leagues': total_created_leagues,
            }
        })
    except Exception as e:
        logger.exception('admin_backfill_team_leagues_all failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/admin/players/<int:player_id>/sync-fixtures', methods=['POST'])
@require_api_key
def admin_sync_player_fixtures(player_id: int):
    """
    Sync/backfill all fixtures for a player from API-Football.
    Fetches the player's fixtures for their loan team in the current season
    and stores any missing fixture stats in the database.
    """
    try:
        from src.api_football_client import APIFootballClient
        from src.models.weekly import Fixture, FixturePlayerStats
        from src.models.league import LoanedPlayer
        
        data = request.get_json() or {}
        dry_run = data.get('dry_run', False)
        
        # Get current season
        now_utc = datetime.now(timezone.utc)
        current_year = now_utc.year
        current_month = now_utc.month
        season = data.get('season', current_year if current_month >= 8 else current_year - 1)
        
        # Find the player's MOST RECENT loan team (order by updated_at to get current loan)
        loaned = LoanedPlayer.query.filter_by(player_id=player_id, is_active=True).order_by(LoanedPlayer.updated_at.desc()).first()
        if not loaned:
            loaned = LoanedPlayer.query.filter_by(player_id=player_id).order_by(LoanedPlayer.updated_at.desc()).first()
        
        if not loaned or not loaned.loan_team_id:
            return jsonify({'error': 'No loan record found for this player'}), 404
        
        loan_team = Team.query.get(loaned.loan_team_id)
        if not loan_team:
            return jsonify({'error': 'Loan team not found'}), 404
        
        loan_team_api_id = loan_team.team_id
        
        api_client = APIFootballClient()
        
        # Fetch all fixtures for this team in the season
        season_start = f"{season}-08-01"
        season_end = f"{season + 1}-06-30"
        
        logger.info(f"Syncing fixtures for player {player_id} ({loaned.player_name}) at team {loan_team_api_id} ({loan_team.name})")
        
        fixtures = api_client.get_fixtures_for_team(
            loan_team_api_id, 
            season, 
            season_start, 
            season_end
        )
        
        synced = 0
        skipped = 0
        errors = []
        
        for fx in fixtures:
            fixture_info = fx.get('fixture', {})
            fixture_id_api = fixture_info.get('id')
            fixture_status = fixture_info.get('status', {}).get('short', '')
            
            # Only process finished games
            if fixture_status not in ('FT', 'AET', 'PEN'):
                skipped += 1
                continue
            
            # Check if we already have this fixture
            existing_fixture = Fixture.query.filter_by(fixture_id_api=fixture_id_api).first()
            
            if not existing_fixture:
                # Create the fixture
                if not dry_run:
                    teams = fx.get('teams', {})
                    goals = fx.get('goals', {})
                    league = fx.get('league', {})
                    
                    existing_fixture = Fixture(
                        fixture_id_api=fixture_id_api,
                        date_utc=datetime.fromisoformat(fixture_info.get('date', '').replace('Z', '+00:00')) if fixture_info.get('date') else None,
                        season=season,
                        competition_name=league.get('name'),
                        home_team_api_id=teams.get('home', {}).get('id'),
                        away_team_api_id=teams.get('away', {}).get('id'),
                        home_goals=goals.get('home'),
                        away_goals=goals.get('away'),
                    )
                    db.session.add(existing_fixture)
                    db.session.flush()
            
            # Check if we have player stats for this fixture
            if existing_fixture:
                existing_stats = FixturePlayerStats.query.filter_by(
                    fixture_id=existing_fixture.id,
                    player_api_id=player_id
                ).first()
                
                if existing_stats:
                    skipped += 1
                    continue
            
            # Fetch player stats for this fixture
            try:
                player_stats = api_client.get_player_stats_for_fixture(player_id, season, fixture_id_api)
                
                if player_stats and player_stats.get('statistics'):
                    # statistics is a LIST, get first element
                    stat_list = player_stats['statistics']
                    if not stat_list:
                        skipped += 1
                        continue
                    st = stat_list[0] if isinstance(stat_list, list) else stat_list
                    
                    # Extract stats from the nested structure
                    games = st.get('games', {}) or {}
                    goals_block = st.get('goals', {}) or {}
                    cards = st.get('cards', {}) or {}
                    shots = st.get('shots', {}) or {}
                    passes = st.get('passes', {}) or {}
                    tackles = st.get('tackles', {}) or {}
                    duels = st.get('duels', {}) or {}
                    dribbles = st.get('dribbles', {}) or {}
                    fouls = st.get('fouls', {}) or {}
                    penalty = st.get('penalty', {}) or {}
                    
                    minutes = games.get('minutes', 0) or 0
                    
                    # Only add if player actually played
                    if minutes and minutes > 0 and not dry_run and existing_fixture:
                        fps = FixturePlayerStats(
                            fixture_id=existing_fixture.id,
                            player_api_id=player_id,
                            team_api_id=loan_team_api_id,
                            minutes=minutes,
                            position=games.get('position'),
                            rating=games.get('rating'),
                            goals=goals_block.get('total', 0) or 0,
                            assists=goals_block.get('assists', 0) or 0,
                            yellows=cards.get('yellow', 0) or 0,
                            reds=cards.get('red', 0) or 0,
                            shots_total=shots.get('total'),
                            shots_on=shots.get('on'),
                            passes_total=passes.get('total'),
                            passes_key=passes.get('key'),
                            tackles_total=tackles.get('total'),
                            duels_won=duels.get('won'),
                            duels_total=duels.get('total'),
                            dribbles_success=dribbles.get('success'),
                            # Goalkeeper stats - saves and conceded are in goals block
                            saves=goals_block.get('saves'),
                            goals_conceded=goals_block.get('conceded'),
                            # Additional stats
                            fouls_drawn=fouls.get('drawn'),
                            fouls_committed=fouls.get('committed'),
                            penalty_saved=penalty.get('saved'),
                        )
                        db.session.add(fps)
                        synced += 1
                    elif minutes and minutes > 0:
                        synced += 1  # Dry run counts this as would-sync
                    else:
                        skipped += 1
                else:
                    skipped += 1
                    
            except Exception as e:
                errors.append(f"Fixture {fixture_id_api}: {str(e)}")
        
        if not dry_run:
            db.session.commit()
            
            # Sync denormalized stats for this player
            _sync_denormalized_stats_for_player(loaned)
        
        return jsonify({
            'player_id': player_id,
            'player_name': loaned.player_name,
            'loan_team': loan_team.name,
            'season': season,
            'dry_run': dry_run,
            'fixtures_found': len(fixtures),
            'synced': synced,
            'skipped': skipped,
            'errors': errors[:10],  # Limit error list
        })
        
    except Exception as e:
        logger.error(f"Error syncing fixtures for player {player_id}: {e}")
        import traceback
        traceback.print_exc()
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to sync player fixtures')), 500

@api_bp.route('/admin/teams/<int:team_id>/sync-all-fixtures', methods=['POST'])
@require_api_key
def admin_sync_team_fixtures(team_id: int):
    """
    Sync/backfill all fixtures for ALL active players loaned from a specific team.
    This goes through each player loaned FROM the team (where team is primary_team)
    and re-fetches their fixture stats from API-Football.
    
    Supports background processing for large teams.
    
    Body:
    - background: true/false (default: false)
    - dry_run: true/false (default: false)
    - season: int (default: current season)
    """
    try:
        data = request.get_json() or {}
        background = bool(data.get('background', False))
        job_id = str(uuid4()) if background else None
        
        if background:
            _create_background_job('team_fixtures_sync')
            # Override job_id from uuid() to use the one from _create_background_job
            def run_sync_in_background():
                try:
                    result = _run_team_fixtures_sync(team_id, data, job_id)
                    _update_job(job_id, status='completed', results=result, completed_at=datetime.now(timezone.utc).isoformat())
                except Exception as e:
                    logger.exception(f'Background team sync job {job_id} failed')
                    _update_job(job_id, status='failed', error=str(e), completed_at=datetime.now(timezone.utc).isoformat())
            
            thread = threading.Thread(target=run_sync_in_background)
            thread.start()
            return jsonify({'message': 'Team fixture sync started in background', 'job_id': job_id}), 202
        else:
            result = _run_team_fixtures_sync(team_id, data)
            return jsonify(result), 200
            
    except Exception as e:
        logger.exception(f"admin_sync_team_fixtures failed for team {team_id}")
        return jsonify(_safe_error_payload(e, 'Failed to sync team fixtures')), 500


@api_bp.route('/admin/fixtures/backfill-raw-json', methods=['POST'])
@require_api_key
def admin_backfill_fixture_raw_json():
    """
    Backfill raw_json for fixtures that are missing it.
    
    This fetches the full fixture data from API-Football and stores it,
    which enables team name extraction for older fixtures.
    
    Body:
    - player_id: (optional) Only backfill fixtures for this player
    - team_api_id: (optional) Only backfill fixtures involving this team
    - limit: (optional) Max fixtures to process (default 50)
    - dry_run: (optional) If true, don't actually update DB
    """
    try:
        from src.api_football_client import APIFootballClient
        from src.models.weekly import Fixture, FixturePlayerStats
        import json
        
        data = request.get_json() or {}
        player_id = data.get('player_id')
        team_api_id = data.get('team_api_id')
        limit = min(data.get('limit', 50), 200)  # Cap at 200 to avoid API abuse
        dry_run = data.get('dry_run', False)
        
        # Build query for fixtures missing raw_json
        query = Fixture.query.filter(Fixture.raw_json.is_(None))
        
        # Filter by player if specified
        if player_id:
            fixture_ids_subq = db.session.query(FixturePlayerStats.fixture_id).filter(
                FixturePlayerStats.player_api_id == player_id
            ).subquery()
            query = query.filter(Fixture.id.in_(fixture_ids_subq))
        
        # Filter by team if specified
        if team_api_id:
            query = query.filter(
                db.or_(
                    Fixture.home_team_api_id == team_api_id,
                    Fixture.away_team_api_id == team_api_id
                )
            )
        
        # Order by most recent first, limit results
        fixtures_to_update = query.order_by(Fixture.date_utc.desc()).limit(limit).all()
        
        if not fixtures_to_update:
            return jsonify({
                'message': 'No fixtures found with missing raw_json',
                'updated': 0
            })
        
        api_client = APIFootballClient()
        updated = 0
        errors = []
        
        for fixture in fixtures_to_update:
            try:
                # Fetch fixture data from API
                resp = api_client._make_request('fixtures', {'id': fixture.fixture_id_api})
                api_fixtures = resp.get('response', [])
                
                if api_fixtures:
                    # Store the full fixture object as raw_json
                    raw_json_str = json.dumps(api_fixtures[0])
                    
                    if not dry_run:
                        fixture.raw_json = raw_json_str
                        db.session.add(fixture)
                    
                    updated += 1
                    logger.info(f"Backfilled raw_json for fixture {fixture.fixture_id_api}")
                else:
                    errors.append({
                        'fixture_id_api': fixture.fixture_id_api,
                        'error': 'No data returned from API'
                    })
            except Exception as e:
                errors.append({
                    'fixture_id_api': fixture.fixture_id_api,
                    'error': str(e)
                })
        
        if not dry_run:
            db.session.commit()
        
        return jsonify({
            'message': f"{'Would update' if dry_run else 'Updated'} {updated} fixtures",
            'updated': updated,
            'total_found': len(fixtures_to_update),
            'errors': errors[:10] if errors else [],
            'dry_run': dry_run
        })
        
    except Exception as e:
        logger.exception("admin_backfill_fixture_raw_json failed")
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to backfill fixture raw_json')), 500


def _run_team_fixtures_sync(team_id: int, data: dict, job_id: str = None) -> dict:
    """Run the team fixture sync logic, optionally with progress updates."""
    from src.api_football_client import APIFootballClient
    from src.models.weekly import Fixture, FixturePlayerStats
    
    try:
        dry_run = data.get('dry_run', False)
        
        # Get current season
        now_utc = datetime.now(timezone.utc)
        current_year = now_utc.year
        current_month = now_utc.month
        season = data.get('season', current_year if current_month >= 8 else current_year - 1)
        
        team = Team.query.get(team_id)
        if not team:
            result = {'error': f'Team {team_id} not found'}
            return result
        
        # Get all active players loaned FROM this team
        players = LoanedPlayer.query.filter_by(
            primary_team_id=team_id, 
            is_active=True
        ).all()
        
        total_players = len(players)
        if job_id:
            _update_job(job_id, total=total_players, progress=0, current_player=f'Syncing {total_players} players from {team.name}...')
        
        api_client = APIFootballClient()
        
        results = []
        total_synced = 0
        total_skipped = 0
        total_errors = 0
        
        for idx, loaned in enumerate(players):
            player_result = {
                'player_id': loaned.player_id,
                'player_name': loaned.player_name,
                'loan_team': loaned.loan_team_name,
                'synced': 0,
                'skipped': 0,
                'errors': []
            }
            
            try:
                loan_team = Team.query.get(loaned.loan_team_id)
                if not loan_team:
                    player_result['errors'].append('Loan team not found')
                    results.append(player_result)
                    total_errors += 1
                    continue
                
                loan_team_api_id = loan_team.team_id
                
                # Fetch all fixtures for the loan team this season
                season_start = f"{season}-08-01"
                season_end = f"{season + 1}-06-30"
                
                fixtures = api_client.get_fixtures_for_team(
                    loan_team_api_id, 
                    season, 
                    season_start, 
                    season_end
                )
                
                for fx in fixtures:
                    fixture_info = fx.get('fixture', {})
                    fixture_id_api = fixture_info.get('id')
                    fixture_status = fixture_info.get('status', {}).get('short', '')
                    
                    # Only process finished games
                    if fixture_status not in ('FT', 'AET', 'PEN'):
                        player_result['skipped'] += 1
                        continue
                    
                    # Check if we already have this fixture
                    existing_fixture = Fixture.query.filter_by(fixture_id_api=fixture_id_api).first()
                    
                    if not existing_fixture:
                        # Create the fixture
                        if not dry_run:
                            teams = fx.get('teams', {})
                            goals = fx.get('goals', {})
                            league = fx.get('league', {})
                            
                            existing_fixture = Fixture(
                                fixture_id_api=fixture_id_api,
                                date_utc=datetime.fromisoformat(fixture_info.get('date', '').replace('Z', '+00:00')) if fixture_info.get('date') else None,
                                season=season,
                                competition_name=league.get('name'),
                                home_team_api_id=teams.get('home', {}).get('id'),
                                away_team_api_id=teams.get('away', {}).get('id'),
                                home_goals=goals.get('home'),
                                away_goals=goals.get('away'),
                            )
                            db.session.add(existing_fixture)
                            db.session.flush()
                    
                    # Check if we have player stats for this fixture
                    if existing_fixture:
                        existing_stats = FixturePlayerStats.query.filter_by(
                            fixture_id=existing_fixture.id,
                            player_api_id=loaned.player_id
                        ).first()
                        
                        if existing_stats:
                            player_result['skipped'] += 1
                            continue
                    
                    # Fetch player stats for this fixture
                    try:
                        player_stats = api_client.get_player_stats_for_fixture(loaned.player_id, season, fixture_id_api)
                        
                        if player_stats and player_stats.get('statistics'):
                            stat_list = player_stats['statistics']
                            if not stat_list:
                                player_result['skipped'] += 1
                                continue
                            st = stat_list[0] if isinstance(stat_list, list) else stat_list
                            
                            # Extract stats
                            games = st.get('games', {}) or {}
                            goals_block = st.get('goals', {}) or {}
                            cards = st.get('cards', {}) or {}
                            shots = st.get('shots', {}) or {}
                            passes = st.get('passes', {}) or {}
                            tackles = st.get('tackles', {}) or {}
                            duels = st.get('duels', {}) or {}
                            dribbles = st.get('dribbles', {}) or {}
                            fouls = st.get('fouls', {}) or {}
                            penalty = st.get('penalty', {}) or {}
                            
                            minutes = games.get('minutes', 0) or 0
                            
                            if minutes and minutes > 0 and not dry_run and existing_fixture:
                                fps = FixturePlayerStats(
                                    fixture_id=existing_fixture.id,
                                    player_api_id=loaned.player_id,
                                    player_name=loaned.player_name,
                                    team_api_id=loan_team_api_id,
                                    minutes=minutes,
                                    position=games.get('position'),
                                    rating=games.get('rating'),
                                    goals=goals_block.get('total', 0) or 0,
                                    assists=goals_block.get('assists', 0) or 0,
                                    yellows=cards.get('yellow', 0) or 0,
                                    reds=cards.get('red', 0) or 0,
                                    shots_total=shots.get('total'),
                                    shots_on=shots.get('on'),
                                    passes_total=passes.get('total'),
                                    passes_key=passes.get('key'),
                                    tackles_total=tackles.get('total'),
                                    duels_won=duels.get('won'),
                                    duels_total=duels.get('total'),
                                    dribbles_success=dribbles.get('success'),
                                    saves=goals_block.get('saves'),
                                    goals_conceded=goals_block.get('conceded'),
                                    fouls_drawn=fouls.get('drawn'),
                                    fouls_committed=fouls.get('committed'),
                                    penalty_saved=penalty.get('saved'),
                                )
                                db.session.add(fps)
                                player_result['synced'] += 1
                            elif minutes and minutes > 0:
                                player_result['synced'] += 1  # Dry run counts this
                            else:
                                player_result['skipped'] += 1
                        else:
                            player_result['skipped'] += 1
                            
                    except Exception as e:
                        player_result['errors'].append(f"Fixture {fixture_id_api}: {str(e)[:50]}")
                
                if not dry_run:
                    db.session.commit()
                    
            except Exception as e:
                player_result['errors'].append(str(e)[:100])
                total_errors += 1
            
            total_synced += player_result['synced']
            total_skipped += player_result['skipped']
            results.append(player_result)
            
            if job_id and idx % 5 == 0:
                _update_job(job_id, progress=idx + 1, current_player=f"{loaned.player_name} ({player_result['synced']} new)")
        
        # Update denormalized stats after syncing
        if not dry_run:
            _sync_denormalized_stats_for_team(team_id)
        
        final_result = {
            'team_id': team_id,
            'team_name': team.name,
            'season': season,
            'dry_run': dry_run,
            'players_processed': total_players,
            'total_synced': total_synced,
            'total_skipped': total_skipped,
            'total_errors': total_errors,
            'details': results[:50],  # Limit details for response size
        }
        
        # Note: completion status is handled by the wrapper function for background jobs
        return final_result
        
    except Exception as e:
        logger.exception(f"_run_team_fixtures_sync failed for team {team_id}")
        db.session.rollback()
        return {'error': str(e)}


def _sync_denormalized_stats_for_player(loan: LoanedPlayer):
    """Update denormalized stats in loaned_players for a specific player."""
    from src.models.weekly import FixturePlayerStats
    from sqlalchemy import func
    
    loan_team = Team.query.get(loan.loan_team_id)
    if not loan_team:
        return
    
    # Aggregate stats from fixture_player_stats
    stats = db.session.query(
        func.count().label('appearances'),
        func.sum(FixturePlayerStats.goals).label('goals'),
        func.sum(FixturePlayerStats.assists).label('assists'),
        func.sum(FixturePlayerStats.minutes).label('minutes'),
        func.sum(FixturePlayerStats.saves).label('saves')
    ).filter(
        FixturePlayerStats.player_api_id == loan.player_id,
        FixturePlayerStats.team_api_id == loan_team.team_id
    ).first()
    
    if stats:
        loan.appearances = stats.appearances or 0
        loan.goals = stats.goals or 0
        loan.assists = stats.assists or 0
        loan.minutes_played = stats.minutes or 0
        loan.saves = stats.saves or 0
        db.session.commit()


def _sync_denormalized_stats_for_team(team_id: int):
    """Update denormalized stats in loaned_players for a specific team."""
    from src.models.weekly import FixturePlayerStats
    from sqlalchemy import func
    
    # Get all active loans for this team
    loans = LoanedPlayer.query.filter_by(primary_team_id=team_id, is_active=True).all()
    
    for loan in loans:
        loan_team = Team.query.get(loan.loan_team_id)
        if not loan_team:
            continue
        
        # Aggregate stats from fixture_player_stats
        stats = db.session.query(
            func.count().label('appearances'),
            func.sum(FixturePlayerStats.goals).label('goals'),
            func.sum(FixturePlayerStats.assists).label('assists'),
            func.sum(FixturePlayerStats.minutes).label('minutes'),
            func.sum(FixturePlayerStats.saves).label('saves')
        ).filter(
            FixturePlayerStats.player_api_id == loan.player_id,
            FixturePlayerStats.team_api_id == loan_team.team_id
        ).first()
        
        if stats:
            loan.appearances = stats.appearances or 0
            loan.goals = stats.goals or 0
            loan.assists = stats.assists or 0
            loan.minutes_played = stats.minutes or 0
            loan.saves = stats.saves or 0
    
    db.session.commit()


# --- Admin: Flags management (list/update) ---
@api_bp.route('/admin/flags', methods=['GET'])
@require_api_key
def admin_list_flags():
    try:
        status = (request.args.get('status') or 'all').strip().lower()
        q = LoanFlag.query
        if status in ('pending', 'resolved'):
            q = q.filter(LoanFlag.status == status)
        rows = q.order_by(LoanFlag.created_at.desc()).all()
        return jsonify([{
            'id': r.id,
            'player_api_id': r.player_api_id,
            'primary_team_api_id': r.primary_team_api_id,
            'loan_team_api_id': r.loan_team_api_id,
            'season': r.season,
            'reason': r.reason,
            'email': r.email,
            'status': r.status,
            'admin_note': r.admin_note,
            'created_at': r.created_at.isoformat() if r.created_at else None,
            'resolved_at': r.resolved_at.isoformat() if r.resolved_at else None,
        } for r in rows])
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/admin/flags/<int:flag_id>', methods=['POST'])
@require_api_key
def admin_update_flag(flag_id: int):
    try:
        row = LoanFlag.query.get_or_404(flag_id)
        data = request.get_json() or {}
        status = (data.get('status') or '').strip().lower()
        note = (data.get('note') or '').strip()
        if status in ('pending', 'resolved'):
            row.status = status
            if status == 'resolved' and not row.resolved_at:
                from datetime import datetime as _dt, timezone as _tz
                row.resolved_at = _dt.now(_tz.utc)
        if note:
            row.admin_note = note
        db.session.commit()
        return jsonify({'message': 'updated'})
    except Exception as e:
        logger.exception('admin_update_flag failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500


# --- Admin: Team Data Management ---

@api_bp.route('/admin/teams/<int:team_id>/data', methods=['DELETE'])
@require_api_key
def admin_delete_team_data(team_id: int):
    """
    Delete all tracking data for a team while keeping the team record.
    
    This removes:
    - All LoanedPlayer records where this team is the primary (parent) team
    - All newsletters for this team
    - All weekly loan reports for this team
    - All user subscriptions for this team
    - All journalist assignments for this team
    - All newsletter commentaries for this team
    - Related fixture player stats
    
    The team record itself is preserved but marked as is_tracked=False.
    
    Query params:
    - dry_run: If 'true', only return what would be deleted without actually deleting
    """
    try:
        from src.models.weekly import WeeklyLoanReport, WeeklyLoanAppearance, FixturePlayerStats, Fixture
        
        team = Team.query.get_or_404(team_id)
        dry_run = request.args.get('dry_run', 'false').lower() in ('true', '1', 'yes')
        
        # Collect all data to delete
        summary = {
            'team_id': team.id,
            'team_name': team.name,
            'team_api_id': team.team_id,
            'dry_run': dry_run,
            'deleted': {}
        }
        
        # 1. Get loans where this team is the primary team
        loans = LoanedPlayer.query.filter_by(primary_team_id=team_id).all()
        loan_ids = [l.id for l in loans]
        player_api_ids = [l.player_id for l in loans]
        summary['deleted']['loaned_players'] = len(loans)
        
        # 2. Get newsletters for this team
        newsletters = Newsletter.query.filter_by(team_id=team_id).all()
        newsletter_ids = [n.id for n in newsletters]
        summary['deleted']['newsletters'] = len(newsletters)
        
        # 3. Get weekly loan reports for this team
        weekly_reports = WeeklyLoanReport.query.filter_by(parent_team_id=team_id).all()
        report_ids = [r.id for r in weekly_reports]
        summary['deleted']['weekly_reports'] = len(weekly_reports)
        
        # 4. Get weekly loan appearances for these reports
        appearances_count = 0
        if report_ids:
            appearances_count = WeeklyLoanAppearance.query.filter(
                WeeklyLoanAppearance.weekly_report_id.in_(report_ids)
            ).count()
        summary['deleted']['weekly_appearances'] = appearances_count
        
        # 5. Get user subscriptions for this team
        subscriptions = UserSubscription.query.filter_by(team_id=team_id).all()
        summary['deleted']['subscriptions'] = len(subscriptions)
        
        # 6. Get journalist assignments for this team
        assignments = JournalistTeamAssignment.query.filter_by(team_id=team_id).all()
        summary['deleted']['journalist_assignments'] = len(assignments)
        
        # 7. Get newsletter commentaries for this team
        commentaries = NewsletterCommentary.query.filter_by(team_id=team_id).all()
        # Also get commentaries attached to newsletters
        if newsletter_ids:
            newsletter_commentaries = NewsletterCommentary.query.filter(
                NewsletterCommentary.newsletter_id.in_(newsletter_ids)
            ).all()
            commentaries = list(set(commentaries + newsletter_commentaries))
        summary['deleted']['commentaries'] = len(commentaries)
        
        # 8. Get newsletter comments for these newsletters
        comments_count = 0
        if newsletter_ids:
            comments_count = NewsletterComment.query.filter(
                NewsletterComment.newsletter_id.in_(newsletter_ids)
            ).count()
        summary['deleted']['newsletter_comments'] = comments_count
        
        # 9. Get YouTube links for these newsletters
        youtube_links_count = 0
        if newsletter_ids:
            youtube_links_count = NewsletterPlayerYoutubeLink.query.filter(
                NewsletterPlayerYoutubeLink.newsletter_id.in_(newsletter_ids)
            ).count()
        summary['deleted']['youtube_links'] = youtube_links_count
        
        # 10. Get fixture player stats for loan players (optional, expensive)
        fixture_stats_count = 0
        if player_api_ids:
            fixture_stats_count = FixturePlayerStats.query.filter(
                FixturePlayerStats.player_api_id.in_(player_api_ids)
            ).count()
        summary['deleted']['fixture_player_stats'] = fixture_stats_count
        
        if dry_run:
            summary['message'] = 'Dry run complete. No data was deleted.'
            return jsonify(summary)
        
        # Actually delete the data in correct order (respecting foreign keys)
        
        # Delete fixture player stats
        if player_api_ids:
            FixturePlayerStats.query.filter(
                FixturePlayerStats.player_api_id.in_(player_api_ids)
            ).delete(synchronize_session=False)
        
        # Delete YouTube links
        if newsletter_ids:
            NewsletterPlayerYoutubeLink.query.filter(
                NewsletterPlayerYoutubeLink.newsletter_id.in_(newsletter_ids)
            ).delete(synchronize_session=False)
        
        # Delete newsletter comments
        if newsletter_ids:
            NewsletterComment.query.filter(
                NewsletterComment.newsletter_id.in_(newsletter_ids)
            ).delete(synchronize_session=False)
        
        # Delete commentaries
        for commentary in commentaries:
            db.session.delete(commentary)
        
        # Delete journalist assignments
        for assignment in assignments:
            db.session.delete(assignment)
        
        # Delete user subscriptions
        for sub in subscriptions:
            db.session.delete(sub)
        
        # Delete weekly appearances first (foreign key to reports)
        if report_ids:
            WeeklyLoanAppearance.query.filter(
                WeeklyLoanAppearance.weekly_report_id.in_(report_ids)
            ).delete(synchronize_session=False)
        
        # Delete weekly reports
        for report in weekly_reports:
            db.session.delete(report)
        
        # Delete newsletters
        for newsletter in newsletters:
            db.session.delete(newsletter)
        
        # Delete loaned players
        for loan in loans:
            db.session.delete(loan)
        
        # Mark team as not tracked
        team.is_tracked = False
        team.newsletters_active = False
        
        db.session.commit()
        
        summary['message'] = f'Successfully deleted all tracking data for {team.name}'
        return jsonify(summary)
        
    except Exception as e:
        logger.exception('admin_delete_team_data failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to delete team data')), 500


@api_bp.route('/admin/teams/<int:team_id>/tracking', methods=['POST'])
@require_api_key
def admin_update_team_tracking(team_id: int):
    """
    Update tracking status for a team.
    
    Body: { "is_tracked": true/false }
    """
    try:
        team = Team.query.get_or_404(team_id)
        data = request.get_json() or {}
        
        if 'is_tracked' in data:
            team.is_tracked = bool(data['is_tracked'])
        
        db.session.commit()
        return jsonify({
            'message': 'updated',
            'team_id': team.id,
            'team_name': team.name,
            'is_tracked': team.is_tracked
        })
    except Exception as e:
        logger.exception('admin_update_team_tracking failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to update team tracking')), 500


@api_bp.route('/admin/teams/<int:team_id>/name', methods=['PUT'])
@require_api_key
def admin_update_team_name(team_id: int):
    """
    Update the name for a team. Useful for correcting placeholder names like "Team 12345".
    
    Body: { "name": "Correct Team Name" }
    """
    try:
        team = Team.query.get_or_404(team_id)
        data = request.get_json() or {}
        
        new_name = (data.get('name') or '').strip()
        if not new_name:
            return jsonify({'error': 'name is required'}), 400
        
        old_name = team.name
        team.name = new_name
        team.updated_at = datetime.now(timezone.utc)
        
        db.session.commit()
        return jsonify({
            'message': 'updated',
            'team_id': team.id,
            'api_team_id': team.team_id,
            'old_name': old_name,
            'new_name': team.name,
        })
    except Exception as e:
        logger.exception('admin_update_team_name failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to update team name')), 500


@api_bp.route('/admin/teams/placeholder-names', methods=['GET'])
@require_api_key
def admin_list_placeholder_team_names():
    """
    List teams with placeholder names like "Team 12345".
    
    Query params:
      - season: Filter by season year
      - limit: Max results (default 100)
    """
    try:
        season = request.args.get('season')
        limit = request.args.get('limit', 100, type=int)
        
        query = Team.query.filter(
            db.func.lower(Team.name).like('team %')
        )
        
        if season:
            query = query.filter(Team.season == int(season))
        
        teams = query.order_by(Team.name.asc()).limit(limit).all()
        
        return jsonify([{
            'id': t.id,
            'team_id': t.team_id,
            'name': t.name,
            'season': t.season,
            'country': t.country,
            'logo': t.logo,
            'league_name': t.league.name if t.league else None,
        } for t in teams])
    except Exception as e:
        logger.exception('admin_list_placeholder_team_names failed')
        return jsonify(_safe_error_payload(e, 'Failed to list placeholder team names')), 500


@api_bp.route('/admin/teams/bulk-fix-names', methods=['POST'])
@require_api_key
def admin_bulk_fix_team_names():
    """
    Attempt to fix placeholder team names by fetching from API-Football.
    
    Body: {
        "team_ids": [1, 2, 3],  # Optional: specific teams to fix
        "season": 2024,  # Required: season for API lookup
        "dry_run": false  # Preview changes without saving
    }
    """
    try:
        data = request.get_json() or {}
        team_ids = data.get('team_ids', [])
        season = data.get('season')
        dry_run = bool(data.get('dry_run', False))
        
        if not season:
            return jsonify({'error': 'season is required'}), 400
        
        # Find teams to fix
        if team_ids:
            teams = Team.query.filter(
                Team.id.in_(team_ids),
                db.func.lower(Team.name).like('team %')
            ).all()
        else:
            teams = Team.query.filter(
                db.func.lower(Team.name).like('team %'),
                Team.season == int(season)
            ).limit(50).all()
        
        updated = []
        skipped = []
        
        for team in teams:
            result = _update_team_name_if_missing(team, season=int(season), dry_run=dry_run)
            if result.get('status') in ('updated', 'would_update'):
                updated.append({
                    'id': team.id,
                    'api_team_id': team.team_id,
                    'old_name': team.name if dry_run else result.get('old_name', team.name),
                    'new_name': result.get('new_name'),
                })
            else:
                skipped.append({
                    'id': team.id,
                    'api_team_id': team.team_id,
                    'name': team.name,
                    'status': result.get('status'),
                })
        
        if not dry_run:
            db.session.commit()
        
        return jsonify({
            'dry_run': dry_run,
            'updated': updated,
            'skipped': skipped,
            'updated_count': len(updated),
            'skipped_count': len(skipped),
        })
    except Exception as e:
        logger.exception('admin_bulk_fix_team_names failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to bulk fix team names')), 500


@api_bp.route('/admin/teams/propagate-names', methods=['POST'])
@require_api_key
def admin_propagate_team_names():
    """
    Propagate corrected team names from the Teams table to:
    1. LoanedPlayer records (primary_team_name, loan_team_name)
    2. Newsletter structured_content JSON
    
    Body: {
        "team_ids": [1, 2, 3],  # Optional: specific teams to propagate (DB IDs)
        "dry_run": false,  # Preview changes without saving
        "fix_loans": true,  # Update LoanedPlayer records
        "fix_newsletters": true  # Update Newsletter structured_content
    }
    """
    try:
        import json as json_module
        
        data = request.get_json() or {}
        team_ids = data.get('team_ids', [])
        dry_run = bool(data.get('dry_run', False))
        fix_loans = bool(data.get('fix_loans', True))
        fix_newsletters = bool(data.get('fix_newsletters', True))
        
        results = {
            'dry_run': dry_run,
            'loans_updated': 0,
            'newsletters_updated': 0,
            'details': []
        }
        
        # Get teams to process
        if team_ids:
            teams = Team.query.filter(Team.id.in_(team_ids)).all()
        else:
            # Only process teams that had placeholder names (now fixed)
            # We can't tell which ones were fixed, so process all
            teams = Team.query.all()
        
        # Build team_id -> name mapping
        team_name_map = {}
        for t in teams:
            team_name_map[t.id] = t.name
        
        if fix_loans:
            # Update LoanedPlayer.primary_team_name
            for team in teams:
                count = LoanedPlayer.query.filter(
                    LoanedPlayer.primary_team_id == team.id,
                    LoanedPlayer.primary_team_name != team.name
                ).count()
                
                if count > 0:
                    results['details'].append({
                        'type': 'loan_primary',
                        'team_id': team.id,
                        'team_name': team.name,
                        'records': count
                    })
                    
                    if not dry_run:
                        LoanedPlayer.query.filter(
                            LoanedPlayer.primary_team_id == team.id
                        ).update({'primary_team_name': team.name}, synchronize_session=False)
                        results['loans_updated'] += count
            
            # Update LoanedPlayer.loan_team_name
            for team in teams:
                count = LoanedPlayer.query.filter(
                    LoanedPlayer.loan_team_id == team.id,
                    LoanedPlayer.loan_team_name != team.name
                ).count()
                
                if count > 0:
                    results['details'].append({
                        'type': 'loan_borrowing',
                        'team_id': team.id,
                        'team_name': team.name,
                        'records': count
                    })
                    
                    if not dry_run:
                        LoanedPlayer.query.filter(
                            LoanedPlayer.loan_team_id == team.id
                        ).update({'loan_team_name': team.name}, synchronize_session=False)
                        results['loans_updated'] += count
        
        if fix_newsletters:
            # Update Newsletter structured_content
            newsletters = Newsletter.query.filter(
                Newsletter.structured_content.isnot(None)
            ).all()
            
            for nl in newsletters:
                try:
                    content = json_module.loads(nl.structured_content) if nl.structured_content else None
                    if not content:
                        continue
                    
                    modified = False
                    
                    # Fix team_name at top level
                    if content.get('team_id') and content['team_id'] in team_name_map:
                        new_name = team_name_map[content['team_id']]
                        if content.get('team_name') != new_name:
                            content['team_name'] = new_name
                            modified = True
                    
                    # Fix player loan_team and loan_team_name in player items
                    for item in content.get('player_items', []):
                        loan_team_id = item.get('loan_team_id')
                        if loan_team_id and loan_team_id in team_name_map:
                            new_name = team_name_map[loan_team_id]
                            if item.get('loan_team') != new_name:
                                item['loan_team'] = new_name
                                modified = True
                            if item.get('loan_team_name') != new_name:
                                item['loan_team_name'] = new_name
                                modified = True
                    
                    if modified:
                        results['details'].append({
                            'type': 'newsletter',
                            'newsletter_id': nl.id,
                            'team_id': nl.team_id
                        })
                        
                        if not dry_run:
                            nl.structured_content = json_module.dumps(content)
                            results['newsletters_updated'] += 1
                            
                except Exception as e:
                    logger.warning(f"Failed to update newsletter {nl.id}: {e}")
        
        if not dry_run:
            db.session.commit()
        
        return jsonify(results)
    except Exception as e:
        logger.exception('admin_propagate_team_names failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to propagate team names')), 500


@api_bp.route('/admin/teams/bulk-tracking', methods=['POST'])
@require_api_key
def admin_bulk_update_team_tracking():
    """
    Bulk update tracking status for multiple teams.
    
    Body: { 
        "team_ids": [1, 2, 3], 
        "is_tracked": true/false,
        "exclude_team_ids": [4, 5]  # Optional: teams to exclude from update
    }
    
    Or to update all teams except some:
    { 
        "all": true,
        "is_tracked": false,
        "exclude_team_ids": [4]  # Keep team 4 tracked
    }
    """
    try:
        data = request.get_json() or {}
        is_tracked = bool(data.get('is_tracked', False))
        exclude_ids = data.get('exclude_team_ids', [])
        
        if data.get('all'):
            # Update all teams except excluded ones
            query = Team.query
            if exclude_ids:
                query = query.filter(~Team.id.in_(exclude_ids))
            teams = query.all()
        else:
            team_ids = data.get('team_ids', [])
            if not team_ids:
                return jsonify({'error': 'team_ids or all=true required'}), 400
            teams = Team.query.filter(Team.id.in_(team_ids)).all()
        
        updated_count = 0
        for team in teams:
            if team.id not in exclude_ids:
                team.is_tracked = is_tracked
                updated_count += 1
        
        db.session.commit()
        return jsonify({
            'message': f'Updated {updated_count} teams',
            'is_tracked': is_tracked,
            'updated_count': updated_count
        })
    except Exception as e:
        logger.exception('admin_bulk_update_team_tracking failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to bulk update team tracking')), 500


# --- Admin: Team Tracking Requests ---

@api_bp.route('/admin/tracking-requests', methods=['GET'])
@require_api_key
def admin_list_tracking_requests():
    """List all team tracking requests with optional status filter."""
    try:
        status = (request.args.get('status') or 'all').strip().lower()
        q = TeamTrackingRequest.query
        if status in ('pending', 'approved', 'rejected'):
            q = q.filter(TeamTrackingRequest.status == status)
        rows = q.order_by(TeamTrackingRequest.created_at.desc()).all()
        return jsonify([r.to_dict() for r in rows])
    except Exception as e:
        logger.exception('admin_list_tracking_requests failed')
        return jsonify(_safe_error_payload(e, 'Failed to list tracking requests')), 500


@api_bp.route('/admin/tracking-requests/<int:request_id>', methods=['POST'])
@require_api_key
def admin_update_tracking_request(request_id: int):
    """
    Update a tracking request status (approve/reject).
    
    Body: { "status": "approved"|"rejected", "note": "optional admin note" }
    
    If approved, the team's is_tracked flag will be set to true.
    """
    try:
        req = TeamTrackingRequest.query.get_or_404(request_id)
        data = request.get_json() or {}
        status = (data.get('status') or '').strip().lower()
        note = (data.get('note') or '').strip()
        
        if status not in ('approved', 'rejected', 'pending'):
            return jsonify({'error': 'status must be approved, rejected, or pending'}), 400
        
        req.status = status
        if note:
            req.admin_note = note
        
        if status in ('approved', 'rejected'):
            req.resolved_at = datetime.now(timezone.utc)
        else:
            req.resolved_at = None
        
        # If approved, mark the team as tracked
        if status == 'approved' and req.team_id:
            team = Team.query.get(req.team_id)
            if team:
                team.is_tracked = True
        
        db.session.commit()
        return jsonify({
            'message': 'updated',
            'request': req.to_dict()
        })
    except Exception as e:
        logger.exception('admin_update_tracking_request failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to update tracking request')), 500


# --- Public: Team Tracking Requests ---

@api_bp.route('/teams/<int:team_id>/request-tracking', methods=['POST'])
def submit_tracking_request(team_id: int):
    """
    Submit a request to track a team.
    
    Body: { "email": "optional@email.com", "reason": "Why you want this team tracked" }
    
    Rate limited to prevent abuse.
    """
    try:
        team = Team.query.get_or_404(team_id)
        
        # Check if team is already tracked
        if team.is_tracked:
            return jsonify({'error': 'This team is already being tracked'}), 400
        
        # Check for recent pending request for same team (prevent duplicates)
        recent_cutoff = datetime.now(timezone.utc) - timedelta(hours=24)
        existing = TeamTrackingRequest.query.filter(
            TeamTrackingRequest.team_id == team_id,
            TeamTrackingRequest.status == 'pending',
            TeamTrackingRequest.created_at > recent_cutoff
        ).first()
        
        if existing:
            return jsonify({
                'message': 'A tracking request for this team is already pending',
                'existing_request_id': existing.id
            }), 200
        
        data = request.get_json() or {}
        email = (data.get('email') or '').strip()
        reason = (data.get('reason') or '').strip()
        
        # Create the request
        tracking_request = TeamTrackingRequest(
            team_id=team.id,
            team_api_id=team.team_id,
            team_name=team.name,
            email=email[:255] if email else None,
            reason=reason[:1000] if reason else None,
            ip_address=get_client_ip()[:64] if get_client_ip() else None,
            user_agent=(request.headers.get('User-Agent') or '')[:512],
            status='pending'
        )
        
        db.session.add(tracking_request)
        db.session.commit()
        
        return jsonify({
            'message': f'Tracking request submitted for {team.name}',
            'request_id': tracking_request.id
        }), 201
        
    except Exception as e:
        logger.exception('submit_tracking_request failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to submit tracking request')), 500


@api_bp.route('/teams/<int:team_id>/tracking-status', methods=['GET'])
def get_team_tracking_status(team_id: int):
    """
    Get tracking status for a team, including any pending requests.
    """
    try:
        team = Team.query.get_or_404(team_id)
        
        pending_request = TeamTrackingRequest.query.filter(
            TeamTrackingRequest.team_id == team_id,
            TeamTrackingRequest.status == 'pending'
        ).first()
        
        return jsonify({
            'team_id': team.id,
            'team_name': team.name,
            'is_tracked': team.is_tracked,
            'has_pending_request': pending_request is not None,
            'pending_request_id': pending_request.id if pending_request else None,
            'loan_count': LoanedPlayer.query.filter_by(primary_team_id=team_id, is_active=True).count()
        })
    except Exception as e:
        logger.exception('get_team_tracking_status failed')
        return jsonify(_safe_error_payload(e, 'Failed to get tracking status')), 500


# --- Admin: Newsletters management (list/view/update) ---


def _normalize_int_list(values) -> list[int]:
    """Normalize a list of values into unique positive integers."""
    if not values:
        return []
    normalized: list[int] = []
    seen = set()
    for value in values:
        try:
            num = int(value)
        except (TypeError, ValueError):
            continue
        if num <= 0 or num in seen:
            continue
        normalized.append(num)
        seen.add(num)
    return normalized


def _get_param_value(source, key):
    if source is None:
        return None
    getter = getattr(source, 'get', None)
    if callable(getter):
        value = getter(key)
    else:
        value = source[key] if isinstance(source, dict) and key in source else None
    if isinstance(value, (list, tuple)):
        return value[0] if value else None
    return value


def _apply_admin_newsletter_filters(base_query, params):
    """Apply shared newsletter filters used by admin endpoints.

    Returns tuple of (query, meta) where meta includes flags about applied filters.
    """
    params = params or {}
    query = base_query
    meta = {
        'issue_filter_applied': False,
    }

    # Team filter
    team_value = _get_param_value(params, 'team')
    try:
        team_id = int(team_value) if team_value not in (None, '') else None
    except (TypeError, ValueError):
        team_id = None
    if team_id:
        query = query.filter(Newsletter.team_id == team_id)
        meta['team_id'] = team_id

    # Published toggle
    published_only_value = _get_param_value(params, 'published_only')
    if published_only_value is not None:
        want = str(published_only_value).lower() in ('true', '1', 'yes', 'y')
        query = query.filter(Newsletter.published.is_(want))
        meta['published_only'] = want

    # Week range
    week_start_str = _get_param_value(params, 'week_start')
    week_end_str = _get_param_value(params, 'week_end')
    if week_start_str and week_end_str:
        try:
            ws = datetime.strptime(week_start_str, '%Y-%m-%d').date()
            we = datetime.strptime(week_end_str, '%Y-%m-%d').date()
            query = query.filter(
                db.and_(
                    Newsletter.week_start_date <= we,
                    Newsletter.week_end_date >= ws,
                )
            )
            meta['week_range'] = (week_start_str, week_end_str)
        except ValueError:
            meta['week_range'] = None

    # Issue date range (primary)
    issue_start_str = _get_param_value(params, 'issue_start')
    issue_end_str = _get_param_value(params, 'issue_end')
    if issue_start_str and issue_end_str:
        try:
            isd = datetime.strptime(issue_start_str, '%Y-%m-%d').date()
            ied = datetime.strptime(issue_end_str, '%Y-%m-%d').date()
            query = query.filter(
                db.and_(
                    Newsletter.issue_date >= isd,
                    Newsletter.issue_date <= ied,
                )
            )
            meta['issue_filter_applied'] = True
            meta['issue_range'] = (issue_start_str, issue_end_str)
        except ValueError:
            meta['issue_filter_applied'] = False

    # Created date range
    created_start_str = _get_param_value(params, 'created_start')
    created_end_str = _get_param_value(params, 'created_end')
    if created_start_str and created_end_str:
        try:
            cs = datetime.strptime(created_start_str, '%Y-%m-%d').date()
            ce = datetime.strptime(created_end_str, '%Y-%m-%d').date()
            cs_dt = datetime.combine(cs, datetime.min.time(), tzinfo=timezone.utc)
            ce_dt = datetime.combine(ce, datetime.max.time(), tzinfo=timezone.utc)
            query = query.filter(
                db.and_(
                    Newsletter.generated_date >= cs_dt,
                    Newsletter.generated_date <= ce_dt,
                )
            )
            meta['created_range'] = (created_start_str, created_end_str)
        except ValueError:
            meta['created_range'] = None

    return query, meta


def _resolve_newsletter_filter_targets(filter_params, exclude_ids):
    base_query, filter_meta = _apply_admin_newsletter_filters(Newsletter.query, filter_params)
    matched_rows = base_query.with_entities(Newsletter.id).all()
    matched_ids = [row.id for row in matched_rows]
    exclude_set = set(_normalize_int_list(exclude_ids))
    excluded_in_matched = [nid for nid in matched_ids if nid in exclude_set]
    exclude_missing = [nid for nid in exclude_set if nid not in matched_ids]
    selected_ids = [nid for nid in matched_ids if nid not in exclude_set]

    meta = {
        'mode': 'filters',
        'total_matched': len(matched_ids),
        'total_selected': len(selected_ids),
        'total_excluded': len(excluded_in_matched),
        'excluded_ids': excluded_in_matched,
        'exclude_missing': exclude_missing,
        'filter_info': filter_meta,
    }
    return selected_ids, matched_ids, meta
@api_bp.route('/admin/newsletters', methods=['GET'])
@require_api_key
def admin_list_newsletters():
    try:
        filtered_query, filter_meta = _apply_admin_newsletter_filters(Newsletter.query, request.args)
        page = request.args.get('page', type=int) or 1
        if page < 1:
            page = 1

        page_size_param = request.args.get('page_size', type=int)
        page_size = None
        if page_size_param is not None:
            page_size = page_size_param
            if page_size < 1:
                page_size = 1
            if page_size > 200:
                page_size = 200

        total = filtered_query.order_by(None).count()

        total_pages = 1
        if page_size is not None:
            total_pages = max(1, math.ceil(total / page_size))
            if page > total_pages:
                page = total_pages
        else:
            page = 1

        # Ordering: issue date first if provided, otherwise created desc
        if filter_meta.get('issue_filter_applied'):
            ordered_query = filtered_query.order_by(Newsletter.issue_date.desc(), Newsletter.generated_date.desc())
        else:
            ordered_query = filtered_query.order_by(Newsletter.generated_date.desc())

        if page_size is not None:
            offset = (page - 1) * page_size
            if offset < 0:
                offset = 0
            ordered_query = ordered_query.offset(offset).limit(page_size)

        rows = ordered_query.all()
        effective_page_size = page_size if page_size is not None else total
        return jsonify({
            'items': [r.to_dict() for r in rows],
            'page': page,
            'page_size': effective_page_size,
            'total': total,
            'total_pages': total_pages,
            'meta': {
                'filters': filter_meta,
            }
        })
    except Exception as e:
        logger.exception('admin_list_newsletters failed')
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/admin/newsletters/<int:nid>', methods=['GET'])
@require_api_key
def admin_get_newsletter(nid: int):
    try:
        n = Newsletter.query.get_or_404(nid)
        payload = n.to_dict()
        try:
            payload['enriched_content'] = _load_newsletter_json(n)
        except Exception:
            payload['enriched_content'] = None
        return jsonify(payload)
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/admin/newsletters/<int:nid>', methods=['PUT'])
@require_api_key
def admin_update_newsletter(nid: int):
    try:
        n = Newsletter.query.get_or_404(nid)
        data = request.get_json() or {}
        # Update title
        title_updated = False
        if 'title' in data:
            new_title = (data.get('title') or '').strip()
            if new_title:
                title_updated = new_title != n.title
                n.title = new_title
        # Update content
        if 'content_json' in data:
            payload = data.get('content_json')
            try:
                if isinstance(payload, str):
                    obj = json.loads(payload)
                else:
                    obj = payload
            except Exception:
                return jsonify({'error': 'content_json must be valid JSON'}), 400
            content_str = json.dumps(obj, ensure_ascii=False)
            n.content = content_str
            n.structured_content = content_str
        elif title_updated:
            # Sync title into existing JSON when only title changes
            raw = n.structured_content or n.content
            try:
                obj = json.loads(raw) if isinstance(raw, str) else raw
            except Exception:
                obj = None
            if isinstance(obj, dict):
                obj['title'] = n.title
                content_str = json.dumps(obj, ensure_ascii=False)
                n.content = content_str
                n.structured_content = content_str
        # Update week/issue dates (optional)
        def _parse_date(s):
            try:
                return datetime.strptime(s, '%Y-%m-%d').date()
            except Exception:
                return None
        if 'issue_date' in data and data.get('issue_date'):
            d = _parse_date(str(data.get('issue_date')))
            if d:
                n.issue_date = d
        if 'week_start_date' in data and data.get('week_start_date'):
            d = _parse_date(str(data.get('week_start_date')))
            if d:
                n.week_start_date = d
        if 'week_end_date' in data and data.get('week_end_date'):
            d = _parse_date(str(data.get('week_end_date')))
            if d:
                n.week_end_date = d
        # Publish/unpublish toggle
        auto_send_trigger = False
        if 'published' in data:
            want_pub = bool(data.get('published'))
            # Detect transition from not published -> published
            auto_send_trigger = (want_pub is True and not n.published)
            n.published = want_pub
            if want_pub:
                n.published_date = datetime.now(timezone.utc)
            else:
                n.published_date = None
        n.updated_at = datetime.now(timezone.utc)
        db.session.commit()

        # Optional: auto-send on approval
        _maybe_auto_send_on_publish(n, auto_send_trigger)

        return jsonify({'message': 'updated', 'newsletter': n.to_dict()})
    except Exception as e:
        logger.exception('admin_update_newsletter failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500


@api_bp.route('/admin/newsletters/bulk-publish', methods=['POST'])
@require_api_key
def admin_bulk_publish_newsletters():
    """Bulk publish or unpublish newsletters.
    
    Body:
      - publish: Boolean, whether to publish (true) or unpublish (false)
      - ids: Array of newsletter IDs (if not using filter_params)
      - filter_params: Object with filter criteria (alternative to ids)
      - post_to_reddit: Boolean, if true and publishing, also post to Reddit
    """
    try:
        data = request.get_json() or {}
        publish_flag = bool(data.get('publish'))
        post_to_reddit = bool(data.get('post_to_reddit', False))
        filter_params = data.get('filter_params') or data.get('filters')

        meta: dict[str, Any] | None = None
        missing: list[int] = []
        unchanged = 0

        if filter_params:
            if not isinstance(filter_params, dict):
                return jsonify({'error': 'filter_params must be an object'}), 400
            expected_total_raw = data.get('expected_total')
            try:
                expected_total = int(expected_total_raw)
            except (TypeError, ValueError):
                expected_total = None
            if expected_total is None or expected_total < 0:
                return jsonify({'error': 'expected_total is required when using filter_params', 'field': 'expected_total'}), 400

            selected_ids, matched_ids, filter_meta = _resolve_newsletter_filter_targets(filter_params, data.get('exclude_ids'))
            if len(matched_ids) != expected_total:
                return jsonify({
                    'error': 'expected_total_mismatch',
                    'expected_total': expected_total,
                    'actual_total': len(matched_ids),
                }), 409

            target_ids = selected_ids
            meta = dict(filter_meta)
            meta['expected_total'] = expected_total
            meta['total_requested'] = len(matched_ids)
        else:
            normalized_ids = _normalize_int_list(data.get('ids'))
            if not normalized_ids:
                return jsonify({'error': 'ids array required'}), 400
            target_ids = normalized_ids
            meta = {
                'mode': 'ids',
                'total_requested': len(normalized_ids),
            }

        if not target_ids:
            meta.setdefault('total_selected', 0)
            meta.setdefault('excluded_ids', [])
            return jsonify({
                'updated': 0,
                'unchanged': 0,
                'missing': [],
                'publish': publish_flag,
                'total_requested': meta.get('total_requested', 0),
                'meta': meta,
            })

        rows = Newsletter.query.filter(Newsletter.id.in_(target_ids)).all()
        found_ids = {row.id for row in rows}
        missing = [i for i in target_ids if i not in found_ids]
        meta.setdefault('missing_ids', missing)
        meta.setdefault('total_selected', len(target_ids) - len(missing))

        now = datetime.now(timezone.utc)
        updated = 0
        auto_send_targets = []
        for row in rows:
            was_published = row.published
            if publish_flag:
                if not was_published:
                    row.published = True
                    row.published_date = now
                    updated += 1
                    auto_send_targets.append(row)
                else:
                    unchanged += 1
            else:
                if was_published:
                    row.published = False
                    row.published_date = None
                    updated += 1
                else:
                    unchanged += 1
        db.session.commit()

        logger.info(
            'Admin bulk publish user=%s publish=%s updated=%s unchanged=%s selection=%s meta=%s',
            getattr(g, 'user_email', None),
            publish_flag,
            updated,
            unchanged,
            target_ids,
            meta,
        )

        if publish_flag and auto_send_targets:
            for target in auto_send_targets:
                _maybe_auto_send_on_publish(target, auto_send_trigger=True)

        # Post to Reddit if requested
        reddit_results = []
        if publish_flag and post_to_reddit and auto_send_targets:
            reddit_results = _maybe_post_to_reddit_on_publish(auto_send_targets)

        response_data = {
            'updated': updated,
            'missing': missing,
            'publish': publish_flag,
            'unchanged': unchanged,
            'total_requested': meta.get('total_requested', len(target_ids)),
            'meta': meta,
        }
        
        if post_to_reddit:
            response_data['reddit'] = {
                'requested': post_to_reddit,
                'results': reddit_results,
                'posted_count': sum(1 for r in reddit_results if r.get('success_count', 0) > 0)
            }

        return jsonify(response_data)
    except Exception as e:
        logger.exception('admin_bulk_publish_newsletters failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to update newsletter status. Please try again later.')), 500


def _maybe_post_to_reddit_on_publish(newsletters: list) -> list:
    """Attempt to post newsletters to Reddit after publishing.
    
    Args:
        newsletters: List of Newsletter objects that were just published
        
    Returns:
        List of result dicts per newsletter
    """
    results = []
    
    try:
        from src.services.reddit_service import (
            RedditService, RedditServiceError, post_newsletter_to_reddit
        )
        from src.utils.newsletter_markdown import (
            convert_newsletter_to_markdown,
            convert_newsletter_to_compact_markdown,
            generate_post_title
        )
        
        service = RedditService.get_instance()
        if not service.is_configured():
            logger.warning('Reddit not configured, skipping auto-post')
            return [{'newsletter_id': n.id, 'skipped': True, 'reason': 'Reddit not configured'} for n in newsletters]
        
        for newsletter in newsletters:
            newsletter_result = {
                'newsletter_id': newsletter.id,
                'team_name': newsletter.team.name if newsletter.team else None,
                'subreddit_posts': [],
                'success_count': 0,
                'failed_count': 0
            }
            
            # Get active subreddits for this team
            subreddits = TeamSubreddit.query.filter_by(
                team_id=newsletter.team_id,
                is_active=True
            ).all()
            
            if not subreddits:
                newsletter_result['skipped'] = True
                newsletter_result['reason'] = 'No active subreddits configured'
                results.append(newsletter_result)
                continue
            
            # Get newsletter data
            newsletter_data = newsletter.to_dict()
            team_name = newsletter.team.name if newsletter.team else 'Unknown Team'
            title = generate_post_title(newsletter_data, team_name)
            
            web_url = None
            if newsletter.public_slug:
                web_url = f"https://goonloan.com/newsletters/{newsletter.public_slug}"
            
            for sub in subreddits:
                try:
                    # Generate markdown
                    if sub.post_format == 'compact':
                        markdown = convert_newsletter_to_compact_markdown(newsletter_data)
                    else:
                        markdown = convert_newsletter_to_markdown(
                            newsletter_data,
                            include_expanded_stats=True,
                            include_links=True,
                            web_url=web_url
                        )
                    
                    result = post_newsletter_to_reddit(
                        newsletter_id=newsletter.id,
                        team_subreddit_id=sub.id,
                        title=title,
                        markdown_content=markdown,
                        post_format=sub.post_format
                    )
                    
                    if result.get('status') == 'success':
                        newsletter_result['success_count'] += 1
                    elif result.get('status') == 'failed':
                        newsletter_result['failed_count'] += 1
                    
                    newsletter_result['subreddit_posts'].append({
                        'subreddit': sub.subreddit_name,
                        **result
                    })
                    
                except Exception as e:
                    newsletter_result['failed_count'] += 1
                    newsletter_result['subreddit_posts'].append({
                        'subreddit': sub.subreddit_name,
                        'status': 'failed',
                        'error': str(e)
                    })
            
            results.append(newsletter_result)
            
            logger.info(
                'Auto-posted newsletter %s to Reddit: success=%s failed=%s',
                newsletter.id,
                newsletter_result['success_count'],
                newsletter_result['failed_count']
            )
        
    except Exception as e:
        logger.exception('_maybe_post_to_reddit_on_publish failed')
        return [{'newsletter_id': n.id, 'error': str(e)} for n in newsletters]
    
    return results

# --- Simple run-history using AdminSetting key 'run_history' ---

def _get_run_history_list() -> list:
    row = AdminSetting.query.filter_by(key='run_history').first()
    if not row or not row.value_json:
        return []
    try:
        return json.loads(row.value_json) or []
    except Exception:
        return []

def _save_run_history_list(items: list):
    row = AdminSetting.query.filter_by(key='run_history').first()
    if not row:
        row = AdminSetting(key='run_history', value_json=json.dumps(items))
        db.session.add(row)
    else:
        row.value_json = json.dumps(items)
    db.session.commit()

def _append_run_history(event: dict):
    try:
        event = dict(event or {})
        event['ts'] = datetime.now(timezone.utc).isoformat()
        items = _get_run_history_list()
        items.insert(0, event)
        _save_run_history_list(items[:200])
    except Exception:
        db.session.rollback()
        logger.exception('append_run_history failed')


def _maybe_auto_send_on_publish(n: Newsletter, auto_send_trigger: bool):
    """Attempt to auto-send a newsletter after it is published."""
    if not auto_send_trigger:
        return None
    try:
        if os.getenv('NEWSLETTER_AUTO_SEND_ON_APPROVAL', '1').lower() not in ('1', 'true', 'yes'):
            return None
        if n.email_sent:
            return None

        out = _deliver_newsletter_via_webhook(n)
        logger.info(
            "Auto-send newsletter %s to team %s - status=%s", n.id, n.team_id, out.get('status')
        )

        if out.get('status') == 'ok':
            from datetime import datetime as _dt, timezone as _tz

            subs = UserSubscription.query.filter_by(team_id=n.team_id, active=True).all()
            valid_subs = [s for s in subs if (s.email or '').strip() and not s.email_bounced]
            used_count = len(valid_subs)
            n.email_sent = True
            n.email_sent_date = _dt.now(_tz.utc)
            n.subscriber_count = used_count

            try:
                ts = n.email_sent_date
                for s in valid_subs:
                    s.last_email_sent = ts
            except Exception:
                pass

            db.session.commit()

        try:
            _append_run_history({
                'kind': 'newsletter-auto-send',
                'newsletter_id': n.id,
                'team_id': n.team_id,
                'status': out.get('status'),
                'http_status': out.get('http_status'),
                'recipient_count': out.get('recipient_count'),
            })
        except Exception:
            pass

        return out
    except Exception:
        logger.exception('auto-send on approval failed')
        try:
            db.session.rollback()
        except Exception:
            pass
        return None


@api_bp.route('/admin/newsletters/bulk', methods=['DELETE'])
@require_api_key
def admin_bulk_delete_newsletters():
    try:
        data = request.get_json() or {}
        filter_params = data.get('filter_params') or data.get('filters')

        meta: dict[str, Any] | None = None
        missing: list[int] = []

        if filter_params:
            if not isinstance(filter_params, dict):
                return jsonify({'error': 'filter_params must be an object'}), 400
            expected_total_raw = data.get('expected_total')
            try:
                expected_total = int(expected_total_raw)
            except (TypeError, ValueError):
                expected_total = None
            if expected_total is None or expected_total < 0:
                return jsonify({'error': 'expected_total is required when using filter_params', 'field': 'expected_total'}), 400

            selected_ids, matched_ids, filter_meta = _resolve_newsletter_filter_targets(filter_params, data.get('exclude_ids'))
            if len(matched_ids) != expected_total:
                return jsonify({
                    'error': 'expected_total_mismatch',
                    'expected_total': expected_total,
                    'actual_total': len(matched_ids),
                }), 409

            target_ids = selected_ids
            meta = dict(filter_meta)
            meta['expected_total'] = expected_total
            meta['total_requested'] = len(matched_ids)
        else:
            normalized_ids = _normalize_int_list(data.get('ids'))
            if not normalized_ids:
                return jsonify({'error': 'ids array required'}), 400
            target_ids = normalized_ids
            meta = {
                'mode': 'ids',
                'total_requested': len(normalized_ids),
            }

        if not target_ids:
            meta.setdefault('total_selected', 0)
            meta.setdefault('excluded_ids', [])
            return jsonify({
                'deleted': 0,
                'missing': [],
                'meta': meta,
            })

        existing_rows = Newsletter.query.filter(Newsletter.id.in_(target_ids)).with_entities(Newsletter.id).all()
        existing_ids = [row.id for row in existing_rows]
        missing = [i for i in target_ids if i not in existing_ids]
        meta.setdefault('missing_ids', missing)
        meta.setdefault('total_selected', len(target_ids) - len(missing))

        deleted_count = 0
        if existing_ids:
            NewsletterComment.query.filter(NewsletterComment.newsletter_id.in_(existing_ids)).delete(synchronize_session=False)
            NewsletterDigestQueue.query.filter(NewsletterDigestQueue.newsletter_id.in_(existing_ids)).delete(synchronize_session=False)
            deleted_count = Newsletter.query.filter(Newsletter.id.in_(existing_ids)).delete(synchronize_session=False)
            db.session.commit()
        else:
            db.session.commit()

        logger.info(
            'Admin bulk delete user=%s deleted=%s selection=%s meta=%s',
            getattr(g, 'user_email', None),
            deleted_count,
            target_ids,
            meta,
        )

        return jsonify({
            'deleted': deleted_count,
            'missing': missing,
            'meta': meta,
        })
    except Exception as e:
        logger.exception('admin_bulk_delete_newsletters failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to delete newsletters. Please try again later.')), 500


@api_bp.route('/admin/newsletters/send-digests', methods=['POST'])
@require_api_key
def admin_send_digest_emails():
    """Trigger sending of weekly digest emails to users who prefer digest delivery.
    
    Body options:
      - week_key: Optional week key to process (e.g., '2025-W48'). Defaults to current week.
    """
    try:
        from src.services.newsletter_deadline_service import send_digest_emails, get_current_week_key
        
        data = request.get_json() or {}
        week_key = data.get('week_key') or get_current_week_key()
        
        result = send_digest_emails(week_key)
        
        logger.info(
            'Admin triggered digest send user=%s week=%s result=%s',
            getattr(g, 'user_email', None),
            week_key,
            result,
        )
        
        return jsonify({
            'week_key': week_key,
            **result
        })
    except Exception as e:
        logger.exception('admin_send_digest_emails failed')
        return jsonify(_safe_error_payload(e, 'Failed to send digest emails. Please try again later.')), 500


@api_bp.route('/admin/newsletters/digest-queue', methods=['GET'])
@require_api_key
def admin_get_digest_queue():
    """Get the current digest queue status."""
    try:
        from src.services.newsletter_deadline_service import get_current_week_key
        
        week_key = request.args.get('week_key') or get_current_week_key()
        
        # Get queue stats
        from sqlalchemy import func
        
        queue_stats = db.session.query(
            NewsletterDigestQueue.sent,
            func.count(NewsletterDigestQueue.id).label('count'),
            func.count(func.distinct(NewsletterDigestQueue.user_id)).label('unique_users')
        ).filter(
            NewsletterDigestQueue.week_key == week_key
        ).group_by(NewsletterDigestQueue.sent).all()
        
        pending_count = 0
        pending_users = 0
        sent_count = 0
        sent_users = 0
        
        for row in queue_stats:
            if row.sent:
                sent_count = row.count
                sent_users = row.unique_users
            else:
                pending_count = row.count
                pending_users = row.unique_users
        
        return jsonify({
            'week_key': week_key,
            'pending': {
                'items': pending_count,
                'users': pending_users
            },
            'sent': {
                'items': sent_count,
                'users': sent_users
            },
            'total': pending_count + sent_count
        })
    except Exception as e:
        logger.exception('admin_get_digest_queue failed')
        return jsonify(_safe_error_payload(e, 'Failed to get digest queue. Please try again later.')), 500


# --- Admin: Reddit Integration Endpoints ---

@api_bp.route('/admin/team-subreddits', methods=['GET'])
@require_api_key
def admin_list_team_subreddits():
    """List all team-subreddit mappings.
    
    Query params:
      - team_id: Filter by specific team ID
      - active_only: If 'true', only return active subreddits
    """
    try:
        team_id = request.args.get('team_id', type=int)
        active_only = request.args.get('active_only', '').lower() in ('true', '1', 'yes')
        
        query = TeamSubreddit.query
        if team_id:
            query = query.filter_by(team_id=team_id)
        if active_only:
            query = query.filter_by(is_active=True)
        
        query = query.order_by(TeamSubreddit.team_id, TeamSubreddit.subreddit_name)
        subreddits = query.all()
        
        return jsonify({
            'subreddits': [s.to_dict() for s in subreddits],
            'count': len(subreddits)
        })
    except Exception as e:
        logger.exception('admin_list_team_subreddits failed')
        return jsonify(_safe_error_payload(e, 'Failed to list subreddits')), 500


@api_bp.route('/admin/team-subreddits', methods=['POST'])
@require_api_key
def admin_add_team_subreddit():
    """Add a subreddit mapping for a team.
    
    Body:
      - team_id: Required team database ID
      - subreddit_name: Required subreddit name (without r/)
      - post_format: Optional, 'full' or 'compact' (default: 'full')
      - is_active: Optional boolean (default: true)
    """
    try:
        data = request.get_json() or {}
        
        team_id = data.get('team_id')
        subreddit_name = (data.get('subreddit_name') or '').strip().lower()
        
        if not team_id:
            return jsonify({'error': 'team_id is required'}), 400
        if not subreddit_name:
            return jsonify({'error': 'subreddit_name is required'}), 400
        
        # Remove r/ prefix if provided
        if subreddit_name.startswith('r/'):
            subreddit_name = subreddit_name[2:]
        
        # Validate team exists
        team = Team.query.get(team_id)
        if not team:
            return jsonify({'error': f'Team {team_id} not found'}), 404
        
        # Check for duplicate
        existing = TeamSubreddit.query.filter_by(
            team_id=team_id,
            subreddit_name=subreddit_name
        ).first()
        if existing:
            return jsonify({
                'error': f'Subreddit r/{subreddit_name} already configured for this team',
                'existing': existing.to_dict()
            }), 409
        
        post_format = data.get('post_format', 'full')
        if post_format not in ('full', 'compact'):
            post_format = 'full'
        
        is_active = data.get('is_active', True)
        if isinstance(is_active, str):
            is_active = is_active.lower() in ('true', '1', 'yes')
        
        subreddit = TeamSubreddit(
            team_id=team_id,
            subreddit_name=subreddit_name,
            post_format=post_format,
            is_active=bool(is_active)
        )
        db.session.add(subreddit)
        db.session.commit()
        
        logger.info(
            'Admin added team subreddit user=%s team_id=%s subreddit=%s',
            getattr(g, 'user_email', None),
            team_id,
            subreddit_name
        )
        
        return jsonify({
            'subreddit': subreddit.to_dict(),
            'message': f'Added r/{subreddit_name} for {team.name}'
        }), 201
    except Exception as e:
        logger.exception('admin_add_team_subreddit failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to add subreddit')), 500


@api_bp.route('/admin/team-subreddits/<int:subreddit_id>', methods=['PUT'])
@require_api_key
def admin_update_team_subreddit(subreddit_id: int):
    """Update a team subreddit mapping.
    
    Body:
      - post_format: Optional, 'full' or 'compact'
      - is_active: Optional boolean
    """
    try:
        subreddit = TeamSubreddit.query.get(subreddit_id)
        if not subreddit:
            return jsonify({'error': 'Subreddit mapping not found'}), 404
        
        data = request.get_json() or {}
        
        if 'post_format' in data:
            post_format = data['post_format']
            if post_format in ('full', 'compact'):
                subreddit.post_format = post_format
        
        if 'is_active' in data:
            is_active = data['is_active']
            if isinstance(is_active, str):
                is_active = is_active.lower() in ('true', '1', 'yes')
            subreddit.is_active = bool(is_active)
        
        db.session.commit()
        
        logger.info(
            'Admin updated team subreddit user=%s subreddit_id=%s',
            getattr(g, 'user_email', None),
            subreddit_id
        )
        
        return jsonify({
            'subreddit': subreddit.to_dict(),
            'message': 'Subreddit mapping updated'
        })
    except Exception as e:
        logger.exception('admin_update_team_subreddit failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to update subreddit')), 500


@api_bp.route('/admin/team-subreddits/<int:subreddit_id>', methods=['DELETE'])
@require_api_key
def admin_delete_team_subreddit(subreddit_id: int):
    """Delete a team subreddit mapping."""
    try:
        subreddit = TeamSubreddit.query.get(subreddit_id)
        if not subreddit:
            return jsonify({'error': 'Subreddit mapping not found'}), 404
        
        subreddit_name = subreddit.subreddit_name
        team_id = subreddit.team_id
        
        db.session.delete(subreddit)
        db.session.commit()
        
        logger.info(
            'Admin deleted team subreddit user=%s subreddit_id=%s team_id=%s subreddit=%s',
            getattr(g, 'user_email', None),
            subreddit_id,
            team_id,
            subreddit_name
        )
        
        return jsonify({
            'message': f'Deleted r/{subreddit_name} mapping',
            'deleted_id': subreddit_id
        })
    except Exception as e:
        logger.exception('admin_delete_team_subreddit failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to delete subreddit mapping')), 500


@api_bp.route('/admin/newsletters/<int:newsletter_id>/reddit-posts', methods=['GET'])
@require_api_key
def admin_get_newsletter_reddit_posts(newsletter_id: int):
    """Get all Reddit posts for a specific newsletter."""
    try:
        newsletter = Newsletter.query.get(newsletter_id)
        if not newsletter:
            return jsonify({'error': 'Newsletter not found'}), 404
        
        posts = RedditPost.query.filter_by(newsletter_id=newsletter_id).all()
        
        return jsonify({
            'newsletter_id': newsletter_id,
            'posts': [p.to_dict() for p in posts],
            'count': len(posts)
        })
    except Exception as e:
        logger.exception('admin_get_newsletter_reddit_posts failed')
        return jsonify(_safe_error_payload(e, 'Failed to get Reddit posts')), 500


@api_bp.route('/admin/newsletters/<int:newsletter_id>/post-to-reddit', methods=['POST'])
@require_api_key
def admin_post_newsletter_to_reddit(newsletter_id: int):
    """Post a newsletter to Reddit.
    
    Body:
      - subreddit_id: Optional specific subreddit ID to post to.
                      If not provided, posts to all active subreddits for the team.
    """
    try:
        from src.services.reddit_service import (
            RedditService, RedditServiceError, post_newsletter_to_reddit
        )
        from src.utils.newsletter_markdown import (
            convert_newsletter_to_markdown,
            convert_newsletter_to_compact_markdown,
            generate_post_title
        )
        
        newsletter = Newsletter.query.get(newsletter_id)
        if not newsletter:
            return jsonify({'error': 'Newsletter not found'}), 404
        
        if not newsletter.published:
            return jsonify({'error': 'Newsletter must be published before posting to Reddit'}), 400
        
        # Check if Reddit is configured
        service = RedditService.get_instance()
        if not service.is_configured():
            return jsonify({
                'error': 'Reddit credentials not configured',
                'message': 'Please set REDDIT_CLIENT_ID, REDDIT_CLIENT_SECRET, REDDIT_USERNAME, and REDDIT_PASSWORD environment variables'
            }), 503
        
        data = request.get_json() or {}
        specific_subreddit_id = data.get('subreddit_id')
        
        # Get target subreddits
        if specific_subreddit_id:
            subreddits = TeamSubreddit.query.filter_by(
                id=specific_subreddit_id,
                team_id=newsletter.team_id,
                is_active=True
            ).all()
            if not subreddits:
                return jsonify({'error': 'Subreddit not found or not active'}), 404
        else:
            subreddits = TeamSubreddit.query.filter_by(
                team_id=newsletter.team_id,
                is_active=True
            ).all()
        
        if not subreddits:
            return jsonify({
                'error': 'No subreddits configured for this team',
                'message': 'Please configure subreddit(s) for this team first'
            }), 400
        
        # Get newsletter data for markdown conversion
        newsletter_data = newsletter.to_dict()
        team_name = newsletter.team.name if newsletter.team else 'Unknown Team'
        
        # Generate the post title
        title = generate_post_title(newsletter_data, team_name)
        
        # Get web URL for linking back
        web_url = None
        if newsletter.public_slug:
            web_url = f"https://goonloan.com/newsletters/{newsletter.public_slug}"
        
        results = []
        for sub in subreddits:
            try:
                # Generate markdown based on format preference
                if sub.post_format == 'compact':
                    markdown = convert_newsletter_to_compact_markdown(newsletter_data)
                else:
                    markdown = convert_newsletter_to_markdown(
                        newsletter_data,
                        include_expanded_stats=True,
                        include_links=True,
                        web_url=web_url
                    )
                
                result = post_newsletter_to_reddit(
                    newsletter_id=newsletter_id,
                    team_subreddit_id=sub.id,
                    title=title,
                    markdown_content=markdown,
                    post_format=sub.post_format
                )
                results.append({
                    'subreddit': sub.subreddit_name,
                    **result
                })
            except RedditServiceError as e:
                results.append({
                    'subreddit': sub.subreddit_name,
                    'status': 'failed',
                    'error': str(e)
                })
        
        success_count = sum(1 for r in results if r.get('status') == 'success')
        already_posted = sum(1 for r in results if r.get('status') == 'already_posted')
        failed_count = sum(1 for r in results if r.get('status') == 'failed')
        
        logger.info(
            'Admin posted newsletter to Reddit user=%s newsletter_id=%s success=%s already=%s failed=%s',
            getattr(g, 'user_email', None),
            newsletter_id,
            success_count,
            already_posted,
            failed_count
        )
        
        return jsonify({
            'newsletter_id': newsletter_id,
            'results': results,
            'summary': {
                'success': success_count,
                'already_posted': already_posted,
                'failed': failed_count,
                'total': len(results)
            }
        })
    except Exception as e:
        logger.exception('admin_post_newsletter_to_reddit failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to post to Reddit')), 500


@api_bp.route('/admin/reddit/status', methods=['GET'])
@require_api_key
def admin_reddit_status():
    """Check Reddit integration status and credentials."""
    try:
        from src.services.reddit_service import RedditService, RedditAuthenticationError
        
        service = RedditService.get_instance()
        
        if not service.is_configured():
            return jsonify({
                'configured': False,
                'authenticated': False,
                'message': 'Reddit credentials not configured'
            })
        
        # Try to authenticate
        try:
            reddit = service.authenticate()
            user = reddit.user.me()
            return jsonify({
                'configured': True,
                'authenticated': True,
                'username': user.name if user else service.username,
                'message': 'Reddit connection successful'
            })
        except RedditAuthenticationError as e:
            return jsonify({
                'configured': True,
                'authenticated': False,
                'message': str(e)
            })
    except Exception as e:
        logger.exception('admin_reddit_status failed')
        return jsonify(_safe_error_payload(e, 'Failed to check Reddit status')), 500


# Newsletter YouTube Links endpoints
@api_bp.route('/admin/newsletters/<int:newsletter_id>/youtube-links', methods=['GET'])
@require_api_key
def admin_get_newsletter_youtube_links(newsletter_id: int):
    """Get all YouTube links for a specific newsletter."""
    try:
        newsletter = Newsletter.query.get_or_404(newsletter_id)
        links = NewsletterPlayerYoutubeLink.query.filter_by(newsletter_id=newsletter_id).order_by(NewsletterPlayerYoutubeLink.player_name).all()
        return jsonify([link.to_dict() for link in links])
    except Exception as e:
        logger.exception('admin_get_newsletter_youtube_links failed')
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/admin/newsletters/<int:newsletter_id>/youtube-links', methods=['POST'])
@require_api_key
def admin_create_newsletter_youtube_link(newsletter_id: int):
    """Add a YouTube link for a player in this newsletter."""
    try:
        newsletter = Newsletter.query.get_or_404(newsletter_id)
        data = request.get_json() or {}
        
        player_id = data.get('player_id')
        player_name = (data.get('player_name') or '').strip()
        youtube_link = (data.get('youtube_link') or '').strip()
        
        if not player_name:
            return jsonify({'error': 'player_name is required'}), 400
        if not youtube_link:
            return jsonify({'error': 'youtube_link is required'}), 400
        if not player_id:
            return jsonify({'error': 'player_id is required'}), 400
        
        # Check for duplicate entries
        existing = NewsletterPlayerYoutubeLink.query.filter_by(
            newsletter_id=newsletter_id,
            player_id=player_id
        ).first()
        
        if existing:
            return jsonify({'error': 'YouTube link already exists for this player in this newsletter'}), 409
        
        link = NewsletterPlayerYoutubeLink(
            newsletter_id=newsletter_id,
            player_id=player_id,
            player_name=player_name,
            youtube_link=youtube_link
        )
        
        db.session.add(link)
        db.session.commit()
        
        return jsonify({'message': 'created', 'link': link.to_dict()}), 201
    except Exception as e:
        logger.exception('admin_create_newsletter_youtube_link failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/admin/newsletters/<int:newsletter_id>/youtube-links/<int:link_id>', methods=['PUT'])
@require_api_key
def admin_update_newsletter_youtube_link(newsletter_id: int, link_id: int):
    """Update a YouTube link."""
    try:
        link = NewsletterPlayerYoutubeLink.query.filter_by(id=link_id, newsletter_id=newsletter_id).first_or_404()
        data = request.get_json() or {}
        
        if 'player_name' in data:
            player_name = (data.get('player_name') or '').strip()
            if player_name:
                link.player_name = player_name
        
        if 'youtube_link' in data:
            youtube_link = (data.get('youtube_link') or '').strip()
            if youtube_link:
                link.youtube_link = youtube_link
        
        if 'player_id' in data:
            link.player_id = data.get('player_id')
        
        link.updated_at = datetime.now(timezone.utc)
        db.session.commit()
        
        return jsonify({'message': 'updated', 'link': link.to_dict()})
    except Exception as e:
        logger.exception('admin_update_newsletter_youtube_link failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/admin/newsletters/<int:newsletter_id>/youtube-links/<int:link_id>', methods=['DELETE'])
@require_api_key
def admin_delete_newsletter_youtube_link(newsletter_id: int, link_id: int):
    """Delete a YouTube link."""
    try:
        link = NewsletterPlayerYoutubeLink.query.filter_by(id=link_id, newsletter_id=newsletter_id).first_or_404()
        db.session.delete(link)
        db.session.commit()
        
        return jsonify({'message': 'deleted'})
    except Exception as e:
        logger.exception('admin_delete_newsletter_youtube_link failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500


@api_bp.route('/newsletters/pending-games/<int:team_id>', methods=['GET'])
@require_api_key
def admin_check_pending_games(team_id: int):
    """Check if any active loanees for a team have unplayed games WITHIN the target week."""
    try:
        # Get target date (default to today)
        target_date_str = request.args.get('target_date')
        if target_date_str:
            target_date = datetime.strptime(target_date_str, '%Y-%m-%d').date()
        else:
            target_date = datetime.now(timezone.utc).date()

        # Calculate week range (Monday to Sunday) for the newsletter
        week_start = target_date - timedelta(days=target_date.weekday())
        week_end = week_start + timedelta(days=6)
        
        logger.info(f"Checking pending games for team {team_id}, week {week_start} to {week_end}")

        # 1. Find the parent team
        parent_team = Team.query.get(team_id)
        if not parent_team:
            return jsonify({'error': 'Team not found'}), 404
            
        # 2. Find active loans for this team
        active_loans = parent_team.unique_active_loans()
        
        if not active_loans:
            return jsonify({'pending': False, 'games': [], 'message': 'No active loans found'})
            
        # 3. Group players by loan team API ID
        loan_team_map = {} # api_id -> list of LoanedPlayer objects
        for loan in active_loans:
            if loan.borrowing_team and loan.borrowing_team.team_id:
                api_id = loan.borrowing_team.team_id
                if api_id not in loan_team_map:
                    loan_team_map[api_id] = []
                loan_team_map[api_id].append(loan)
        
        if not loan_team_map:
            return jsonify({'pending': False, 'games': [], 'message': 'No loan teams with API IDs found'})

        # 4. Check fixtures for each loan team WITHIN the target week
        detailed_pending_games = []
        
        for loan_api_id, players in loan_team_map.items():
            # Fetch ALL fixtures for this loan team in the ENTIRE week
            season = api_client.current_season_start_year
            fixtures = api_client.get_fixtures_for_team(
                loan_api_id, 
                season, 
                week_start.strftime('%Y-%m-%d'),  # Check the entire week
                week_end.strftime('%Y-%m-%d')
            )
            
            for f in fixtures:
                fixture_date_str = (f.get('fixture') or {}).get('date')
                status = (f.get('fixture') or {}).get('status', {}).get('short')
                
                # Parse the fixture date to check if it's within the week
                try:
                    if fixture_date_str:
                        fixture_date = datetime.fromisoformat(fixture_date_str.replace('Z', '+00:00')).date()
                    else:
                        continue
                except:
                    continue
                
                # Only include games WITHIN the target week that haven't been played
                # NS = Not Started, TBD = Time To Be Defined
                if week_start <= fixture_date <= week_end and status in ['NS', 'TBD']:
                    opponent = (f.get('teams') or {}).get('away', {}).get('name') \
                                if (f.get('teams') or {}).get('home', {}).get('id') == loan_api_id \
                                else (f.get('teams') or {}).get('home', {}).get('name')
                    league = (f.get('league') or {}).get('name')
                    
                    # Add an entry for EACH player at this club
                    for player in players:
                        detailed_pending_games.append({
                            'player_name': player.player_name,
                            'loan_team': player.loan_team_name,
                            'opponent': opponent,
                            'date': fixture_date_str,
                            'league': league,
                            'status': status,
                            'fixture_id': (f.get('fixture') or {}).get('id')
                        })
                        logger.info(f"Found pending game for {player.player_name} on {fixture_date}: {opponent}")

        # Sort by date
        detailed_pending_games.sort(key=lambda x: x['date'])
        
        logger.info(f"Total pending games found: {len(detailed_pending_games)}")
        
        return jsonify({
            'pending': len(detailed_pending_games) > 0,
            'games': detailed_pending_games
        })

    except Exception as e:
        logger.exception(f"admin_check_pending_games failed for team {team_id}")
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred.')), 500


@api_bp.route('/newsletters/readiness', methods=['GET'])
@require_api_key
def admin_check_newsletter_readiness():
    """
    Check newsletter generation readiness for all tracked teams.
    Returns a summary showing which teams have all games completed vs pending games.
    
    Query params:
      - target_date: YYYY-MM-DD (defaults to today)
      - team_ids: comma-separated list of team DB IDs to check (optional, defaults to all tracked teams)
    
    Returns:
    {
        "target_date": "2024-11-25",
        "week_start": "2024-11-25",
        "week_end": "2024-12-01",
        "ready": true/false,  # All teams ready?
        "teams": [
            {
                "team_id": 1,
                "team_name": "Manchester United",
                "ready": true,
                "pending_count": 0,
                "total_loans": 5
            },
            ...
        ],
        "summary": {
            "total_teams": 10,
            "ready_count": 8,
            "pending_count": 2
        }
    }
    """
    try:
        # Get target date
        target_date_str = request.args.get('target_date')
        if target_date_str:
            target_date = datetime.strptime(target_date_str, '%Y-%m-%d').date()
        else:
            target_date = datetime.now(timezone.utc).date()

        # Calculate week range (Monday to Sunday)
        week_start = target_date - timedelta(days=target_date.weekday())
        week_end = week_start + timedelta(days=6)
        
        # Get teams to check
        team_ids_param = request.args.get('team_ids', '')
        if team_ids_param:
            team_ids = [int(tid.strip()) for tid in team_ids_param.split(',') if tid.strip()]
            teams = Team.query.filter(Team.id.in_(team_ids)).all()
        else:
            # Get all tracked teams
            teams = Team.query.filter(Team.is_tracked == True).all()
        
        if not teams:
            return jsonify({
                'target_date': target_date.isoformat(),
                'week_start': week_start.isoformat(),
                'week_end': week_end.isoformat(),
                'ready': True,
                'teams': [],
                'summary': {
                    'total_teams': 0,
                    'ready_count': 0,
                    'pending_count': 0
                }
            })
        
        results = []
        season = api_client.current_season_start_year
        
        for team in teams:
            # Get active loans for this team
            active_loans = team.unique_active_loans()
            
            if not active_loans:
                results.append({
                    'team_id': team.id,
                    'team_name': team.name,
                    'ready': True,
                    'pending_count': 0,
                    'total_loans': 0,
                    'pending_games': []
                })
                continue
            
            # Group players by loan team API ID
            loan_team_map = {}
            for loan in active_loans:
                if loan.borrowing_team and loan.borrowing_team.team_id:
                    api_id = loan.borrowing_team.team_id
                    if api_id not in loan_team_map:
                        loan_team_map[api_id] = []
                    loan_team_map[api_id].append(loan)
            
            pending_games = []
            
            # Check fixtures for each loan team within the week
            for loan_api_id, players in loan_team_map.items():
                try:
                    fixtures = api_client.get_fixtures_for_team(
                        loan_api_id, 
                        season, 
                        week_start.strftime('%Y-%m-%d'),
                        week_end.strftime('%Y-%m-%d')
                    )
                    
                    for f in fixtures:
                        fixture_date_str = (f.get('fixture') or {}).get('date')
                        status = (f.get('fixture') or {}).get('status', {}).get('short')
                        
                        try:
                            if fixture_date_str:
                                fixture_date = datetime.fromisoformat(fixture_date_str.replace('Z', '+00:00')).date()
                            else:
                                continue
                        except:
                            continue
                        
                        # Only include games within the week that haven't been played
                        if week_start <= fixture_date <= week_end and status in ['NS', 'TBD']:
                            opponent = (f.get('teams') or {}).get('away', {}).get('name') \
                                        if (f.get('teams') or {}).get('home', {}).get('id') == loan_api_id \
                                        else (f.get('teams') or {}).get('home', {}).get('name')
                            
                            for player in players:
                                pending_games.append({
                                    'player_name': player.player_name,
                                    'loan_team': player.loan_team_name,
                                    'opponent': opponent,
                                    'date': fixture_date_str,
                                })
                except Exception as e:
                    logger.warning(f"Failed to check fixtures for loan team {loan_api_id}: {e}")
            
            results.append({
                'team_id': team.id,
                'team_name': team.name,
                'ready': len(pending_games) == 0,
                'pending_count': len(pending_games),
                'total_loans': len(active_loans),
                'pending_games': pending_games[:5]  # Only first 5 for brevity
            })
        
        # Sort: not-ready teams first
        results.sort(key=lambda x: (x['ready'], x['team_name']))
        
        ready_count = sum(1 for r in results if r['ready'])
        pending_count = len(results) - ready_count
        
        return jsonify({
            'target_date': target_date.isoformat(),
            'week_start': week_start.isoformat(),
            'week_end': week_end.isoformat(),
            'ready': pending_count == 0,
            'teams': results,
            'summary': {
                'total_teams': len(results),
                'ready_count': ready_count,
                'pending_count': pending_count
            }
        })

    except Exception as e:
        logger.exception("admin_check_newsletter_readiness failed")
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred.')), 500


# --------------------------------------------------------------------------------
# Newsletter Commentary Endpoints
# --------------------------------------------------------------------------------

def require_commentary_author(f):
    """Decorator to require can_author_commentary permission."""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        # First check basic API key authentication
        # The user email should be in g.admin_email after require_api_key
        if not hasattr(g, 'admin_email') or not g.admin_email:
            return jsonify({'error': 'Authentication required'}), 401
        
        # Check if user has commentary authorship permission
        user = UserAccount.query.filter_by(email=g.admin_email).first()
        if not user or not user.can_author_commentary:
            return jsonify({'error': 'You do not have permission to author commentary'}), 403
        
        # Store user in g for the handler to use
        g.commentary_author = user
        return f(*args, **kwargs)
    
    return decorated_function


@api_bp.route('/admin/newsletters/<int:newsletter_id>/commentary', methods=['GET'])
@require_api_key
def admin_list_newsletter_commentary(newsletter_id: int):
    """List all commentary for a newsletter."""
    try:
        newsletter = Newsletter.query.get_or_404(newsletter_id)
        commentaries = NewsletterCommentary.query.filter_by(
            newsletter_id=newsletter_id,
            is_active=True
        ).order_by(
            NewsletterCommentary.commentary_type,
            NewsletterCommentary.position
        ).all()
        
        return jsonify({
            'newsletter_id': newsletter_id,
            'commentaries': [c.to_dict() for c in commentaries]
        })
    except Exception as e:
        logger.exception('admin_list_newsletter_commentary failed')
        return jsonify(_safe_error_payload(e, 'Failed to list commentary')), 500


@api_bp.route('/admin/newsletters/<int:newsletter_id>/commentary', methods=['POST'])
@require_api_key
@require_commentary_author
def admin_create_newsletter_commentary(newsletter_id: int):
    """Create new commentary for a newsletter."""
    try:
        newsletter = Newsletter.query.get_or_404(newsletter_id)
        data = request.get_json()
        
        if not data:
            return jsonify({'error': 'Request body is required'}), 400
        
        commentary_type = data.get('commentary_type')
        content = data.get('content')
        player_id = data.get('player_id')
        position = data.get('position', 0)
        
        # Validation
        if not commentary_type:
            return jsonify({'error': 'commentary_type is required'}), 400
        if not content:
            return jsonify({'error': 'content is required'}), 400
        if commentary_type not in ['player', 'intro', 'summary']:
            return jsonify({'error': 'commentary_type must be player, intro, or summary'}), 400
        if commentary_type == 'player' and not player_id:
            return jsonify({'error': 'player_id is required for player commentary'}), 400
        
        # Get author from g (set by require_commentary_author)
        author = g.commentary_author
        
        # Create commentary using the factory method (which sanitizes)
        try:
            commentary = NewsletterCommentary.sanitize_and_create(
                newsletter_id=newsletter_id,
                author_id=author.id,
                author_name=author.display_name,
                commentary_type=commentary_type,
                content=content,
                player_id=player_id,
                position=position
            )
        except ValueError as ve:
            return jsonify({'error': str(ve)}), 400
        
        db.session.add(commentary)
        db.session.commit()
        
        return jsonify(commentary.to_dict()), 201
        
    except Exception as e:
        logger.exception('admin_create_newsletter_commentary failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to create commentary')), 500


@api_bp.route('/admin/commentary/<int:commentary_id>', methods=['PUT'])
@require_api_key
@require_commentary_author
def admin_update_commentary(commentary_id: int):
    """Update existing commentary."""
    try:
        commentary = NewsletterCommentary.query.get_or_404(commentary_id)
        author = g.commentary_author
        
        # Check ownership (only author or admin can edit)
        admin_emails = _admin_email_list()
        is_admin = g.admin_email in admin_emails
        if commentary.author_id != author.id and not is_admin:
            return jsonify({'error': 'You can only edit your own commentary'}), 403
        
        data = request.get_json()
        if not data:
            return jsonify({'error': 'Request body is required'}), 400
        
        # Update fields if provided
        if 'content' in data:
            try:
                commentary.content = sanitize_commentary_html(data['content'])
            except ValueError as ve:
                return jsonify({'error': str(ve)}), 400
        
        if 'position' in data:
            commentary.position = int(data['position'])
        
        if 'is_active' in data:
            commentary.is_active = bool(data['is_active'])
        
        commentary.updated_at = datetime.now(timezone.utc)
        db.session.commit()
        
        return jsonify(commentary.to_dict())
        
    except Exception as e:
        logger.exception('admin_update_commentary failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to update commentary')), 500


@api_bp.route('/admin/commentary/<int:commentary_id>', methods=['DELETE'])
@require_api_key
@require_commentary_author
def admin_delete_commentary(commentary_id: int):
    """Delete commentary."""
    try:
        commentary = NewsletterCommentary.query.get_or_404(commentary_id)
        author = g.commentary_author
        
        # Check ownership (only author or admin can delete)
        admin_emails = _admin_email_list()
        is_admin = g.admin_email in admin_emails
        if commentary.author_id != author.id and not is_admin:
            return jsonify({'error': 'You can only delete your own commentary'}), 403
        
        db.session.delete(commentary)
        db.session.commit()
        
        return jsonify({'message': 'deleted'})
        
    except Exception as e:
        logger.exception('admin_delete_commentary failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to delete commentary')), 500


@api_bp.route('/admin/authors', methods=['GET'])
@require_api_key
def admin_list_authors():
    """List all users with commentary authorship permission."""
    try:
        authors = UserAccount.query.filter_by(can_author_commentary=True).all()
        
        # Include commentary count for each author
        result = []
        for author in authors:
            author_dict = author.to_dict()
            commentary_count = NewsletterCommentary.query.filter_by(author_id=author.id).count()
            author_dict['commentary_count'] = commentary_count
            result.append(author_dict)
        
        return jsonify({'authors': result})
        
    except Exception as e:
        logger.exception('admin_list_authors failed')
        return jsonify(_safe_error_payload(e, 'Failed to list authors')), 500


@api_bp.route('/admin/users/<int:user_id>/author-permission', methods=['PUT'])
@require_api_key
def admin_update_author_permission(user_id: int):
    """Grant or revoke commentary authorship permission. Admin only."""
    try:
        # Check if requester is admin
        admin_emails = _admin_email_list()
        if not hasattr(g, 'admin_email') or g.admin_email not in admin_emails:
            return jsonify({'error': 'Only admins can manage author permissions'}), 403
        
        user = UserAccount.query.get_or_404(user_id)
        data = request.get_json()
        
        if not data or 'can_author_commentary' not in data:
            return jsonify({'error': 'can_author_commentary field is required'}), 400
        
        user.can_author_commentary = bool(data['can_author_commentary'])
        user.updated_at = datetime.now(timezone.utc)
        db.session.commit()
        
        return jsonify({
            'user_id': user.id,
            'email': user.email,
            'display_name': user.display_name,
            'can_author_commentary': user.can_author_commentary
        })
        
    except Exception as e:
        logger.exception('admin_update_author_permission failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to update author permission')), 500


# Unified Player Management endpoints
@api_bp.route('/admin/players', methods=['GET'])
@require_api_key
def admin_list_players():
    """
    List all players with comprehensive information, team filtering, and pagination.
    Query params:
    - team_id: filter by primary or loan team
    - search: search player names
    - has_sofascore: filter by sofascore ID presence ('true', 'false', or omit for all)
    - page: page number (default 1)
    - page_size: items per page (default 50, max 200)
    """
    try:
        page = request.args.get('page', type=int, default=1)
        page_size = request.args.get('page_size', type=int, default=50)
        if page < 1:
            page = 1
        if page_size < 1 or page_size > 200:
            page_size = 50
        
        team_id_param = request.args.get('team_id', type=int)
        search_query = request.args.get('search', '').strip()
        has_sofascore_param = request.args.get('has_sofascore', '').lower()
        
        # Get all loaned players first
        loan_query = LoanedPlayer.query
        
        # Apply team filter
        if team_id_param:
            loan_query = loan_query.filter(
                or_(
                    LoanedPlayer.primary_team_id == team_id_param,
                    LoanedPlayer.loan_team_id == team_id_param
                )
            )
        
        # Apply search filter
        if search_query:
            loan_query = loan_query.filter(LoanedPlayer.player_name.ilike(f'%{search_query}%'))
        
        # Get all loans
        all_loans = loan_query.all()
        
        # Group by player_id
        player_map = {}
        for loan in all_loans:
            if loan.player_id not in player_map:
                # Extract season from window_key (e.g., "2024-25::summer" -> "2024-25")
                loan_season = None
                if loan.window_key:
                    loan_season = loan.window_key.split('::')[0] if '::' in loan.window_key else loan.window_key
                
                player_map[loan.player_id] = {
                    'player_id': loan.player_id,
                    'player_name': loan.player_name,
                    'primary_team_name': loan.primary_team_name,
                    'loan_team_name': loan.loan_team_name,
                    'primary_team_id': loan.primary_team_id,
                    'loan_team_id': loan.loan_team_id,
                    'is_active': loan.is_active,
                    'loan_count': 0,
                    'loan_id': loan.id,  # ID of the first/primary loan record for team editing
                    'window_key': loan.window_key,  # Full window key (e.g., "2024-25::summer")
                    'loan_season': loan_season  # Human-readable season (e.g., "2024-25")
                }
            player_map[loan.player_id]['loan_count'] += 1
        
        # Get Player records with sofascore IDs
        player_ids = list(player_map.keys())
        player_records = {}
        if player_ids:
            try:
                players = Player.query.filter(Player.player_id.in_(player_ids)).all()
                player_records = {p.player_id: p for p in players}
            except Exception as player_error:
                logger.warning(f'Could not fetch Player records: {player_error}')
                # Continue without player records if table doesn't exist yet
                player_records = {}
        
        # Build comprehensive player list
        players_data = []
        for player_id, player_info in player_map.items():
            player_record = player_records.get(player_id)
            sofascore_id = player_record.sofascore_id if player_record else None
            display_name = ''
            if player_record and player_record.name:
                display_name = player_record.name.strip()
            if not display_name:
                display_name = (player_info.get('player_name') or '').strip()
            if not display_name:
                display_name = f'Player {player_id}'
            
            # Apply sofascore filter
            if has_sofascore_param == 'true' and not sofascore_id:
                continue
            if has_sofascore_param == 'false' and sofascore_id:
                continue
            
            player_data = {
                'player_id': player_info['player_id'],
                'player_name': display_name,
                'primary_team_name': player_info['primary_team_name'],
                'loan_team_name': player_info['loan_team_name'],
                'primary_team_id': player_info['primary_team_id'],
                'loan_team_id': player_info['loan_team_id'],
                'is_active': player_info['is_active'],
                'loan_count': player_info['loan_count'],
                'window_key': player_info.get('window_key'),
                'loan_season': player_info.get('loan_season'),
                'loan_id': player_info['loan_id'],  # Primary loan record ID for team updates
                'sofascore_id': sofascore_id,
                'has_sofascore_id': bool(sofascore_id),
                'photo_url': player_record.photo_url if player_record else None,
                'position': player_record.position if player_record else None,
                'nationality': player_record.nationality if player_record else None,
                'age': player_record.age if player_record else None,
            }
            players_data.append(player_data)
        
        # Sort by name
        players_data.sort(key=lambda x: x['player_name'].lower())
        
        # Paginate
        total = len(players_data)
        total_pages = max(1, math.ceil(total / page_size)) if total > 0 else 1
        start = (page - 1) * page_size
        end = start + page_size
        paginated_data = players_data[start:end]
        
        return jsonify({
            'items': paginated_data,
            'page': page,
            'page_size': page_size,
            'total': total,
            'total_pages': total_pages
        })
    except Exception as e:
        logger.exception('admin_list_players failed')
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/admin/players/<player_id>', methods=['GET'])
@require_api_key
def admin_get_player(player_id):
    """Get detailed player information."""
    try:
        # Convert player_id to int (supports negative IDs for manual players)
        try:
            player_id = int(player_id)
        except ValueError:
            return jsonify({'error': 'Invalid player ID'}), 400
        # Get Player record
        player_record = Player.query.filter_by(player_id=player_id).first()
        
        # Get all loans for this player
        loans = LoanedPlayer.query.filter_by(player_id=player_id).order_by(LoanedPlayer.created_at.desc()).all()
        
        # Get supplemental loans if any
        supplemental = SupplementalLoan.query.filter_by(api_player_id=player_id).order_by(SupplementalLoan.created_at.desc()).all()
        
        player_data = {
            'player_id': player_id,
            'name': player_record.name if player_record else (loans[0].player_name if loans else f"Player {player_id}"),
            'sofascore_id': player_record.sofascore_id if player_record else None,
            'photo_url': player_record.photo_url if player_record else None,
            'position': player_record.position if player_record else None,
            'nationality': player_record.nationality if player_record else None,
            'age': player_record.age if player_record else None,
            'height': player_record.height if player_record else None,
            'weight': player_record.weight if player_record else None,
            'firstname': player_record.firstname if player_record else None,
            'lastname': player_record.lastname if player_record else None,
            'loans': [l.to_dict() for l in loans],
            'supplemental_loans': [s.to_dict() for s in supplemental],
            'total_loans': len(loans) + len(supplemental),
            'created_at': player_record.created_at.isoformat() if player_record and player_record.created_at else None,
            'updated_at': player_record.updated_at.isoformat() if player_record and player_record.updated_at else None,
        }
        
        return jsonify(player_data)
    except Exception as e:
        logger.exception('admin_get_player failed')
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/admin/players/<player_id>', methods=['PUT'])
@require_api_key
def admin_update_player(player_id):
    """Update player information including sofascore_id."""
    try:
        # Convert player_id to int (supports negative IDs for manual players)
        try:
            player_id = int(player_id)
        except ValueError:
            return jsonify({'error': 'Invalid player ID'}), 400
        data = request.get_json() or {}
        
        # Get or create Player record
        player_record = Player.query.filter_by(player_id=player_id).first()
        if not player_record:
            player_record = Player(player_id=player_id)
            player_record.created_at = datetime.now(timezone.utc)
            db.session.add(player_record)
        
        # Update fields
        propagated_name = None
        if 'name' in data:
            name = (data.get('name') or '').strip()
            if name:
                player_record.name = name
                propagated_name = name
        
        if 'sofascore_id' in data:
            sofascore_id = data.get('sofascore_id')
            # Check for duplicates
            if sofascore_id:
                existing = Player.query.filter(
                    Player.sofascore_id == sofascore_id,
                    Player.player_id != player_id
                ).first()
                if existing:
                    return jsonify({
                        'error': f'Sofascore ID {sofascore_id} is already assigned to player #{existing.player_id}'
                    }), 409
            player_record.sofascore_id = sofascore_id
        
        if 'position' in data:
            player_record.position = data.get('position')
        
        if 'nationality' in data:
            player_record.nationality = data.get('nationality')
        
        if 'age' in data:
            player_record.age = data.get('age')
        
        if 'height' in data:
            player_record.height = data.get('height')
        
        if 'weight' in data:
            player_record.weight = data.get('weight')
        
        if 'firstname' in data:
            player_record.firstname = data.get('firstname')
        
        if 'lastname' in data:
            player_record.lastname = data.get('lastname')
        
        if 'photo_url' in data:
            player_record.photo_url = data.get('photo_url')
        
        player_record.updated_at = datetime.now(timezone.utc)
        if propagated_name:
            updated_rows = LoanedPlayer.query.filter_by(player_id=player_id).update(
                {
                    'player_name': propagated_name,
                    'updated_at': datetime.now(timezone.utc),
                },
                synchronize_session=False,
            )
            if updated_rows:
                logger.info('Propagated name update to %d loan rows for player_id=%s', updated_rows, player_id)

        db.session.commit()
        
        return jsonify({'message': 'updated', 'player': player_record.to_dict()})
    except Exception as e:
        logger.exception('admin_update_player failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/admin/players/bulk-update-sofascore', methods=['POST'])
@require_api_key
def admin_bulk_update_sofascore():
    """Bulk update Sofascore IDs for multiple players."""
    try:
        data = request.get_json() or {}
        updates = data.get('updates', [])
        
        if not isinstance(updates, list):
            return jsonify({'error': 'updates must be an array'}), 400
        
        results = {
            'updated': [],
            'failed': [],
            'skipped': []
        }
        
        for update in updates:
            player_id = update.get('player_id')
            sofascore_id = update.get('sofascore_id')
            
            if not player_id:
                results['failed'].append({'error': 'missing player_id', 'update': update})
                continue
            
            try:
                # Get or create player record
                player_record = Player.query.filter_by(player_id=player_id).first()
                if not player_record:
                    player_record = Player(player_id=player_id)
                    player_record.name = update.get('player_name', f'Player {player_id}')
                    player_record.created_at = datetime.now(timezone.utc)
                    db.session.add(player_record)
                
                # Check for duplicate sofascore_id
                if sofascore_id:
                    existing = Player.query.filter(
                        Player.sofascore_id == sofascore_id,
                        Player.player_id != player_id
                    ).first()
                    if existing:
                        results['failed'].append({
                            'player_id': player_id,
                            'error': f'Sofascore ID already assigned to player #{existing.player_id}'
                        })
                        continue
                
                player_record.sofascore_id = sofascore_id
                player_record.updated_at = datetime.now(timezone.utc)
                
                results['updated'].append({
                    'player_id': player_id,
                    'sofascore_id': sofascore_id
                })
            except Exception as e:
                results['failed'].append({
                    'player_id': player_id,
                    'error': str(e)
                })
        
        db.session.commit()
        
        return jsonify({
            'message': 'bulk update completed',
            'results': results
        })
    except Exception as e:
        logger.exception('admin_bulk_update_sofascore failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/admin/players/field-options', methods=['GET'])
@require_api_key
def admin_get_player_field_options():
    """
    Get existing values for player fields (positions, nationalities) for dropdown population.
    This helps normalize data entry by providing existing values.
    """
    try:
        # Get unique positions from Player table
        positions_query = db.session.query(Player.position).filter(
            Player.position.isnot(None),
            Player.position != ''
        ).distinct().all()
        positions = sorted([p[0] for p in positions_query if p[0]])
        
        # Get unique nationalities from Player table
        nationalities_query = db.session.query(Player.nationality).filter(
            Player.nationality.isnot(None),
            Player.nationality != ''
        ).distinct().all()
        nationalities = sorted([n[0] for n in nationalities_query if n[0]])
        
        return jsonify({
            'positions': positions,
            'nationalities': nationalities
        })
    except Exception as e:
        logger.exception('admin_get_player_field_options failed')
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500


@api_bp.route('/admin/players', methods=['POST'])
@require_api_key
def admin_create_player():
    """
    Create a new manual player with loan association.
    
    This creates both a Player record and a LoanedPlayer record to properly
    track the player's loan status and team associations.
    """
    try:
        data = request.get_json() or {}
        
        # Validate required fields
        name = (data.get('name') or '').strip()
        if not name:
            return jsonify({'error': 'Player name is required'}), 400
        
        window_key = data.get('window_key')
        if not window_key:
            return jsonify({'error': 'Season/window is required'}), 400
        
        # Handle primary team (either from database or custom)
        primary_team_id = data.get('primary_team_id')
        custom_primary_team_name = (data.get('custom_primary_team_name') or '').strip()
        
        if primary_team_id:
            # Using team from database
            primary_team = Team.query.get(primary_team_id)
            if not primary_team:
                return jsonify({'error': f'Primary team ID {primary_team_id} not found'}), 404
            primary_team_name = primary_team.name
            primary_team_api_id = primary_team.team_id
        elif custom_primary_team_name:
            # Using custom team name
            primary_team = None
            primary_team_id = None
            primary_team_name = custom_primary_team_name
            primary_team_api_id = None
        else:
            return jsonify({'error': 'Primary team or custom primary team name is required'}), 400
        
        # Handle loan team (either from database or custom)
        loan_team_id = data.get('loan_team_id')
        custom_loan_team_name = (data.get('custom_loan_team_name') or '').strip()
        
        if loan_team_id:
            # Using team from database
            loan_team = Team.query.get(loan_team_id)
            if not loan_team:
                return jsonify({'error': f'Loan team ID {loan_team_id} not found'}), 404
            loan_team_name = loan_team.name
            loan_team_api_id = loan_team.team_id
        elif custom_loan_team_name:
            # Using custom team name
            loan_team = None
            loan_team_id = None
            loan_team_name = custom_loan_team_name
            loan_team_api_id = None
        else:
            return jsonify({'error': 'Loan team or custom loan team name is required'}), 400
        
        # Generate a unique player_id for manual players (negative IDs to avoid conflicts with API-Football)
        existing_manual_players = Player.query.filter(Player.player_id < 0).order_by(Player.player_id.asc()).all()
        if existing_manual_players:
            new_player_id = existing_manual_players[0].player_id - 1
        else:
            new_player_id = -1
        
        # Create player record
        player_record = Player(player_id=new_player_id)
        player_record.name = name
        player_record.firstname = data.get('firstname')
        player_record.lastname = data.get('lastname')
        player_record.position = data.get('position')
        player_record.nationality = data.get('nationality')
        player_record.age = data.get('age')
        player_record.height = data.get('height')
        player_record.weight = data.get('weight')
        player_record.photo_url = data.get('photo_url')
        player_record.created_at = datetime.now(timezone.utc)
        player_record.updated_at = datetime.now(timezone.utc)
        
        # Handle sofascore_id with duplicate check
        sofascore_id = data.get('sofascore_id')
        if sofascore_id:
            existing = Player.query.filter_by(sofascore_id=sofascore_id).first()
            if existing:
                return jsonify({
                    'error': f'Sofascore ID {sofascore_id} is already assigned to player #{existing.player_id}'
                }), 409
            player_record.sofascore_id = sofascore_id
        
        db.session.add(player_record)
        db.session.flush()  # Get player_id before creating loan record
        
        # Create LoanedPlayer record to track the loan
        # Build team_ids string (comma-separated API IDs, if available)
        team_ids_parts = []
        if primary_team_api_id:
            team_ids_parts.append(str(primary_team_api_id))
        if loan_team_api_id:
            team_ids_parts.append(str(loan_team_api_id))
        team_ids_str = ','.join(team_ids_parts) if team_ids_parts else None
        
        loaned_player = LoanedPlayer(
            player_id=new_player_id,
            player_name=name,
            age=data.get('age'),
            nationality=data.get('nationality'),
            primary_team_id=primary_team_id,  # Will be None for custom teams
            primary_team_name=primary_team_name,
            loan_team_id=loan_team_id,  # Will be None for custom teams
            loan_team_name=loan_team_name,
            team_ids=team_ids_str,
            window_key=window_key,
            is_active=True,
            data_source='manual',
            can_fetch_stats=False,  # Manual players can't auto-fetch stats
            created_at=datetime.now(timezone.utc),
            updated_at=datetime.now(timezone.utc)
        )
        
        db.session.add(loaned_player)
        db.session.commit()
        
        return jsonify({
            'message': f'Player "{name}" created successfully with loan from {primary_team_name} to {loan_team_name}',
            'player': player_record.to_dict(),
            'loan': loaned_player.to_dict()
        }), 201
    except Exception as e:
        logger.exception('admin_create_player failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/admin/players/<player_id>', methods=['DELETE'])
@require_api_key
def admin_delete_player(player_id):
    """
    Delete a player from the system.
    This removes the player from tracking and cleans up associated data.
    Useful for removing false positives from API-Football.
    """
    try:
        # Convert player_id to int (supports negative IDs for manual players)
        try:
            player_id = int(player_id)
        except ValueError:
            return jsonify({'error': 'Invalid player ID'}), 400
        # Check for loaned player records
        loaned_records = LoanedPlayer.query.filter_by(player_id=player_id).all()
        loaned_count = len(loaned_records)
        
        # Check for YouTube links
        youtube_links = NewsletterPlayerYoutubeLink.query.filter_by(player_id=player_id).all()
        youtube_count = len(youtube_links)
        
        # Get player record if it exists
        player_record = Player.query.filter_by(player_id=player_id).first()
        
        # If no data exists anywhere, player not found
        if not player_record and loaned_count == 0 and youtube_count == 0:
            return jsonify({'error': 'Player not found'}), 404
        
        # Delete all associated data
        # 1. Delete YouTube links
        for link in youtube_links:
            db.session.delete(link)
        
        # 2. Delete loaned player records
        for loan in loaned_records:
            db.session.delete(loan)
        
        # 3. Delete player record if it exists
        if player_record:
            db.session.delete(player_record)
        
        db.session.commit()
        
        return jsonify({
            'message': 'Player deleted successfully',
            'deleted': {
                'loaned_records': loaned_count,
                'youtube_links': youtube_count,
                'player_record': player_record is not None
            }
        })
    except Exception as e:
        logger.exception('admin_delete_player failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/admin/runs/history', methods=['GET', 'POST'])
@require_api_key
def admin_runs_history():
    try:
        if request.method == 'GET':
            return jsonify(_get_run_history_list())
        _append_run_history(request.get_json() or {})
        return jsonify({'message': 'appended'})
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/admin/runs/history/clear', methods=['POST'])
@require_api_key
def admin_runs_history_clear():
    try:
        _save_run_history_list([])
        return jsonify({'message': 'cleared'})
    except Exception as e:
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

# --- Admin: Supplemental Loans management ---
@api_bp.route('/admin/supplemental-loans', methods=['GET'])
@require_api_key
def admin_list_supplemental_loans():
    """DEPRECATED: List supplemental loans with optional filters.
    
    Use LoanedPlayer with can_fetch_stats=False instead.
    """
    try:
        parent_team_api_id = request.args.get('parent_team_api_id', type=int)
        parent_team_db_id = request.args.get('parent_team_db_id', type=int)
        season = request.args.get('season', type=int)
        player_name = request.args.get('player_name')

        q = SupplementalLoan.query

        # Filter by parent team
        if parent_team_db_id:
            q = q.filter(SupplementalLoan.parent_team_id == parent_team_db_id)
        elif parent_team_api_id and season:
            row = Team.query.filter_by(team_id=parent_team_api_id, season=season).first()
            if row:
                q = q.filter(SupplementalLoan.parent_team_id == row.id)

        # Filter by season
        if season:
            q = q.filter(SupplementalLoan.season_year == season)

        # Filter by player name
        if player_name:
            q = q.filter(SupplementalLoan.player_name.ilike(f"%{player_name}%"))

        loans = q.order_by(SupplementalLoan.updated_at.desc()).all()
        return jsonify([l.to_dict() for l in loans])
    except Exception as e:
        logger.exception('admin_list_supplemental_loans failed')
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/admin/supplemental-loans', methods=['POST'])
@require_api_key
def admin_create_supplemental_loan():
    """DEPRECATED: Create a new supplemental loan entry.
    
    Use POST /admin/players instead to create manual players as LoanedPlayer records.
    """
    try:
        data = request.get_json() or {}
        
        player_name = (data.get('player_name') or '').strip()
        if not player_name:
            return jsonify({'error': 'player_name is required'}), 400

        parent_team_name = (data.get('parent_team_name') or '').strip()
        loan_team_name = (data.get('loan_team_name') or '').strip()
        if not parent_team_name or not loan_team_name:
            return jsonify({'error': 'parent_team_name and loan_team_name are required'}), 400

        season_year = data.get('season_year', type=int)
        if not season_year:
            return jsonify({'error': 'season_year is required'}), 400

        # Optional team IDs for linking
        parent_team_db_id = data.get('parent_team_db_id', type=int)
        loan_team_db_id = data.get('loan_team_db_id', type=int)
        parent_team_api_id = data.get('parent_team_api_id', type=int)
        loan_team_api_id = data.get('loan_team_api_id', type=int)

        # Resolve parent team
        parent_team = None
        if parent_team_db_id:
            parent_team = Team.query.get(parent_team_db_id)
        elif parent_team_api_id:
            parent_team = Team.query.filter_by(team_id=parent_team_api_id, season=season_year).first()

        # Resolve loan team
        loan_team = None
        if loan_team_db_id:
            loan_team = Team.query.get(loan_team_db_id)
        elif loan_team_api_id:
            loan_team = Team.query.filter_by(team_id=loan_team_api_id, season=season_year).first()

        # Create supplemental loan
        supp_loan = SupplementalLoan(
            player_name=player_name,
            parent_team_id=parent_team.id if parent_team else None,
            parent_team_name=parent_team_name,
            loan_team_id=loan_team.id if loan_team else None,
            loan_team_name=loan_team_name,
            season_year=season_year,
            data_source=data.get('data_source', 'manual'),
            can_fetch_stats=data.get('can_fetch_stats', False),
            source_url=data.get('source_url'),
            wiki_title=data.get('wiki_title'),
            is_verified=data.get('is_verified', False),
            youtube_link=data.get('youtube_link'),
        )

        db.session.add(supp_loan)
        db.session.commit()

        return jsonify({'message': 'created', 'loan': supp_loan.to_dict()}), 201
    except Exception as e:
        logger.exception('admin_create_supplemental_loan failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/admin/supplemental-loans/<int:loan_id>', methods=['PUT'])
@require_api_key
def admin_update_supplemental_loan(loan_id: int):
    """DEPRECATED: Update an existing supplemental loan entry.
    
    Use PUT /admin/loans/{id} to update LoanedPlayer records instead.
    """
    try:
        loan = SupplementalLoan.query.get_or_404(loan_id)
        data = request.get_json() or {}

        # Update basic fields
        if 'player_name' in data:
            loan.player_name = (data.get('player_name') or '').strip() or loan.player_name
        if 'parent_team_name' in data:
            loan.parent_team_name = (data.get('parent_team_name') or '').strip() or loan.parent_team_name
        if 'loan_team_name' in data:
            loan.loan_team_name = (data.get('loan_team_name') or '').strip() or loan.loan_team_name
        if 'season_year' in data:
            loan.season_year = int(data.get('season_year'))
        if 'data_source' in data:
            loan.data_source = data.get('data_source')
        if 'can_fetch_stats' in data:
            loan.can_fetch_stats = bool(data.get('can_fetch_stats'))
        if 'source_url' in data:
            loan.source_url = data.get('source_url')
        if 'wiki_title' in data:
            loan.wiki_title = data.get('wiki_title')
        if 'is_verified' in data:
            loan.is_verified = bool(data.get('is_verified'))
        if 'youtube_link' in data:
            loan.youtube_link = data.get('youtube_link')

        # Update team relationships if provided
        if 'parent_team_db_id' in data:
            team = Team.query.get(data.get('parent_team_db_id'))
            if team:
                loan.parent_team_id = team.id
        if 'loan_team_db_id' in data:
            team = Team.query.get(data.get('loan_team_db_id'))
            if team:
                loan.loan_team_id = team.id

        db.session.commit()
        return jsonify({'message': 'updated', 'loan': loan.to_dict()})
    except Exception as e:
        logger.exception('admin_update_supplemental_loan failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/admin/supplemental-loans/<int:loan_id>', methods=['DELETE'])
@require_api_key
def admin_delete_supplemental_loan(loan_id: int):
    """DEPRECATED: Delete a supplemental loan entry.
    
    Use DELETE /admin/loans/{id} to delete LoanedPlayer records instead.
    """
    try:
        loan = SupplementalLoan.query.get_or_404(loan_id)
        db.session.delete(loan)
        db.session.commit()
        return jsonify({'message': 'deleted', 'id': loan_id})
    except Exception as e:
        logger.exception('admin_delete_supplemental_loan failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500


# --- Admin: Dashboard Stats ---
@api_bp.route('/admin/dashboard-stats', methods=['GET'])
@require_api_key
def admin_dashboard_stats():
    """Get overview stats for the admin dashboard."""
    try:
        from src.models.league import Newsletter, LoanedPlayer, Player
        
        # Newsletter stats
        total_newsletters = Newsletter.query.count()
        published_newsletters = Newsletter.query.filter_by(published=True).count()
        draft_newsletters = total_newsletters - published_newsletters
        
        # Loan stats
        total_loans = LoanedPlayer.query.count()
        active_loans = LoanedPlayer.query.filter_by(is_active=True).count()
        
        # Player stats
        total_players = Player.query.count()
        
        return jsonify({
            'newsletters': {
                'total': total_newsletters,
                'published': published_newsletters,
                'drafts': draft_newsletters,
            },
            'loans': {
                'total': total_loans,
                'active': active_loans,
            },
            'players': {
                'total': total_players,
            }
        })
    except Exception as e:
        logger.exception('admin_dashboard_stats failed')
        return jsonify(_safe_error_payload(e, 'Failed to fetch dashboard stats')), 500


# --- Admin: Subscriber Analytics ---
@api_bp.route('/admin/subscriber-stats', methods=['GET'])
@require_api_key
def admin_subscriber_stats():
    """Get subscriber statistics aggregated by team."""
    request_id = request.headers.get('X-Debug-Request-ID') or uuid4().hex[:12]
    started_at = time.monotonic()
    try:
        search = request.args.get('search', '').strip()
        min_subs = request.args.get('min_subscribers', type=int)
        sort_order = request.args.get('sort', 'desc').lower()
        logger.info(
            'admin_subscriber_stats request request_id=%s search=%s min_subs=%s sort=%s',
            request_id,
            search or '',
            min_subs,
            sort_order,
        )
        
        # Query for teams with their subscriber counts
        from sqlalchemy import func
        
        # Subquery to get the latest season for each team_id
        latest_season_subq = db.session.query(
            Team.team_id,
            func.max(Team.season).label('latest_season')
        ).group_by(Team.team_id).subquery()
        
        # Subquery to aggregate subscriptions by team_id (API team ID) across all seasons
        # This ensures we count all subscriptions for a team regardless of which season's team record they're linked to
        subscription_agg_subq = db.session.query(
            Team.team_id,
            func.count(UserSubscription.id).label('subscriber_count'),
            func.count(db.case((UserSubscription.active == True, 1))).label('active_subscriber_count')
        ).join(
            UserSubscription, Team.id == UserSubscription.team_id
        ).group_by(Team.team_id).subquery()
        
        # Subquery to get latest newsletter date by team_id
        newsletter_agg_subq = db.session.query(
            Team.team_id,
            func.max(Newsletter.published_date).label('latest_newsletter_date')
        ).join(
            Newsletter, Team.id == Newsletter.team_id
        ).group_by(Team.team_id).subquery()
        
        # Main query: get latest season team records and join with aggregated subscription data
        query = db.session.query(
            Team,
            func.coalesce(subscription_agg_subq.c.subscriber_count, 0).label('subscriber_count'),
            func.coalesce(subscription_agg_subq.c.active_subscriber_count, 0).label('active_subscriber_count'),
            newsletter_agg_subq.c.latest_newsletter_date.label('latest_newsletter_date')
        ).join(
            latest_season_subq,
            db.and_(
                Team.team_id == latest_season_subq.c.team_id,
                Team.season == latest_season_subq.c.latest_season
            )
        ).outerjoin(
            subscription_agg_subq, Team.team_id == subscription_agg_subq.c.team_id
        ).outerjoin(
            newsletter_agg_subq, Team.team_id == newsletter_agg_subq.c.team_id
        )
        
        # Apply search filter
        if search:
            query = query.filter(Team.name.ilike(f'%{search}%'))
        
        # Execute query
        results = query.all()
        
        # Filter by minimum subscribers if specified
        if min_subs is not None:
            results = [r for r in results if r.subscriber_count >= min_subs]
        
        # Sort by subscriber count
        if sort_order == 'asc':
            results.sort(key=lambda r: r.subscriber_count)
        else:
            results.sort(key=lambda r: r.subscriber_count, reverse=True)
        
        # Format response
        teams_data = []
        for team, sub_count, active_sub_count, latest_date in results:
            teams_data.append({
                'id': team.id,
                'team_id': team.team_id,
                'name': team.name,
                'logo': team.logo,
                'season': team.season,
                'subscriber_count': sub_count,
                'active_subscriber_count': active_sub_count,
                'newsletters_active': team.newsletters_active,
                'latest_newsletter_date': latest_date.isoformat() if latest_date else None
            })
        
        # Calculate total unique subscribers
        total_subscribers = db.session.query(
            func.count(func.distinct(UserSubscription.email))
        ).filter(UserSubscription.active == True).scalar() or 0

        duration_ms = (time.monotonic() - started_at) * 1000
        logger.info(
            'admin_subscriber_stats success request_id=%s team_count=%d total_subscribers=%d duration_ms=%.1f',
            request_id,
            len(teams_data),
            total_subscribers,
            duration_ms,
        )
        
        payload = {
            'teams': teams_data,
            'total_subscribers': total_subscribers,
            'request_id': request_id,
        }
        response = jsonify(payload)
        response.headers['X-Request-ID'] = request_id
        return response
    except Exception as e:
        duration_ms = (time.monotonic() - started_at) * 1000
        logger.exception('admin_subscriber_stats failed request_id=%s duration_ms=%.1f', request_id, duration_ms)
        payload = _safe_error_payload(e, 'An unexpected error occurred. Please try again later.')
        payload['request_id'] = request_id
        response = jsonify(payload)
        response.headers['X-Request-ID'] = request_id
        return response, 500


@api_bp.route('/admin/teams/<int:team_id>/newsletter-status', methods=['PATCH'])
@require_api_key
def admin_toggle_newsletter_status(team_id: int):
    """Toggle the newsletters_active status for a team."""
    try:
        team = Team.query.get_or_404(team_id)
        data = request.get_json() or {}
        
        if 'newsletters_active' in data:
            team.newsletters_active = bool(data['newsletters_active'])
            team.updated_at = datetime.now(timezone.utc)
            db.session.commit()
            
            return jsonify({
                'message': 'Newsletter status updated',
                'team': team.to_dict()
            })
        else:
            return jsonify({'error': 'newsletters_active field required'}), 400
    except Exception as e:
        logger.exception('admin_toggle_newsletter_status failed')
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'An unexpected error occurred. Please try again later.')), 500

@api_bp.route('/commentaries/<int:commentary_id>/applaud', methods=['POST'])
@limiter.limit("10 per minute")
def applaud_commentary(commentary_id):
    """Applaud a commentary (Like)."""
    try:
        commentary = NewsletterCommentary.query.get(commentary_id)
        if not commentary:
            return jsonify({'error': 'Commentary not found'}), 404
            
        # Optional: Track user if logged in
        user_id = None
        auth = request.headers.get('Authorization', '')
        if auth.startswith('Bearer '):
            try:
                token = auth.split(' ', 1)[1]
                s = _user_serializer()
                data = s.loads(token, max_age=60 * 60 * 24 * 30)
                email = data.get('email')
                user = UserAccount.query.filter_by(email=email).first()
                if user:
                    user_id = user.id
            except Exception:
                pass # Ignore auth errors for applause, treat as anonymous
        
        # Simple session tracking to prevent spamming from same session?
        # For now, we'll just rely on rate limiting and allow multiple claps (Medium style)
        # But we'll log the session_id if available or generate one
        session_id = request.headers.get('X-Session-ID')
        
        applause = CommentaryApplause(
            commentary_id=commentary.id,
            user_id=user_id,
            session_id=session_id
        )
        db.session.add(applause)
        db.session.commit()
        
        # Get updated count
        count = commentary.applause.count()
        
        return jsonify({
            'message': 'Applauded',
            'applause_count': count
        })
    except Exception as e:
        db.session.rollback()
        return jsonify(_safe_error_payload(e, 'Failed to applaud')), 500


@api_bp.route('/admin/subscriptions/backfill-tokens', methods=['POST'])
@require_api_key
def admin_backfill_unsubscribe_tokens():
    """Backfill unsubscribe_token for all subscriptions that don't have one."""
    try:
        subs_without_token = UserSubscription.query.filter(
            UserSubscription.unsubscribe_token.is_(None)
        ).all()
        
        count = 0
        for sub in subs_without_token:
            sub.unsubscribe_token = str(uuid.uuid4())
            count += 1
        
        db.session.commit()
        
        return jsonify({
            'message': f'Backfilled {count} subscription(s) with unsubscribe tokens',
            'updated_count': count,
        })
    except Exception as e:
        db.session.rollback()
        logger.exception('Failed to backfill unsubscribe tokens')
        return jsonify(_safe_error_payload(e, 'Failed to backfill tokens')), 500


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Sponsor Endpoints
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

@api_bp.route('/sponsors', methods=['GET'])
def get_sponsors():
    """Public endpoint to get active sponsors for display."""
    try:
        sponsors = Sponsor.query.filter_by(is_active=True).order_by(Sponsor.display_order.asc()).all()
        return jsonify({
            'sponsors': [s.to_public_dict() for s in sponsors]
        })
    except Exception as e:
        logger.exception('Failed to fetch sponsors')
        return jsonify(_safe_error_payload(e, 'Failed to fetch sponsors')), 500


@api_bp.route('/sponsors/<int:sponsor_id>/click', methods=['POST'])
def track_sponsor_click(sponsor_id):
    """Track a click on a sponsor link (basic analytics)."""
    try:
        sponsor = Sponsor.query.get(sponsor_id)
        if not sponsor:
            return jsonify({'error': 'Sponsor not found'}), 404
        
        sponsor.click_count = (sponsor.click_count or 0) + 1
        db.session.commit()
        
        return jsonify({'message': 'Click tracked'})
    except Exception as e:
        db.session.rollback()
        logger.exception('Failed to track sponsor click')
        return jsonify(_safe_error_payload(e, 'Failed to track click')), 500


@api_bp.route('/admin/sponsors', methods=['GET'])
@require_api_key
def admin_get_sponsors():
    """Admin endpoint to get all sponsors with full details."""
    try:
        sponsors = Sponsor.query.order_by(Sponsor.display_order.asc()).all()
        return jsonify({
            'sponsors': [s.to_dict() for s in sponsors]
        })
    except Exception as e:
        logger.exception('Failed to fetch sponsors')
        return jsonify(_safe_error_payload(e, 'Failed to fetch sponsors')), 500


@api_bp.route('/admin/sponsors', methods=['POST'])
@require_api_key
def admin_create_sponsor():
    """Create a new sponsor."""
    try:
        data = request.get_json() or {}
        
        name = (data.get('name') or '').strip()
        image_url = (data.get('image_url') or '').strip()
        link_url = (data.get('link_url') or '').strip()
        
        if not name:
            return jsonify({'error': 'Name is required'}), 400
        if not image_url:
            return jsonify({'error': 'Image URL is required'}), 400
        if not link_url:
            return jsonify({'error': 'Link URL is required'}), 400
        
        # Get the next display order (put new sponsors at the end)
        max_order = db.session.query(db.func.max(Sponsor.display_order)).scalar() or 0
        
        sponsor = Sponsor(
            name=name,
            image_url=image_url,
            link_url=link_url,
            description=(data.get('description') or '').strip() or None,
            is_active=data.get('is_active', True),
            display_order=max_order + 1,
        )
        
        db.session.add(sponsor)
        db.session.commit()
        
        return jsonify({
            'message': 'Sponsor created',
            'sponsor': sponsor.to_dict()
        }), 201
    except Exception as e:
        db.session.rollback()
        logger.exception('Failed to create sponsor')
        return jsonify(_safe_error_payload(e, 'Failed to create sponsor')), 500


@api_bp.route('/admin/sponsors/<int:sponsor_id>', methods=['PUT'])
@require_api_key
def admin_update_sponsor(sponsor_id):
    """Update an existing sponsor."""
    try:
        sponsor = Sponsor.query.get(sponsor_id)
        if not sponsor:
            return jsonify({'error': 'Sponsor not found'}), 404
        
        data = request.get_json() or {}
        
        if 'name' in data:
            name = (data['name'] or '').strip()
            if not name:
                return jsonify({'error': 'Name cannot be empty'}), 400
            sponsor.name = name
        
        if 'image_url' in data:
            image_url = (data['image_url'] or '').strip()
            if not image_url:
                return jsonify({'error': 'Image URL cannot be empty'}), 400
            sponsor.image_url = image_url
        
        if 'link_url' in data:
            link_url = (data['link_url'] or '').strip()
            if not link_url:
                return jsonify({'error': 'Link URL cannot be empty'}), 400
            sponsor.link_url = link_url
        
        if 'description' in data:
            sponsor.description = (data['description'] or '').strip() or None
        
        if 'is_active' in data:
            sponsor.is_active = bool(data['is_active'])
        
        if 'display_order' in data:
            sponsor.display_order = int(data['display_order'])
        
        db.session.commit()
        
        return jsonify({
            'message': 'Sponsor updated',
            'sponsor': sponsor.to_dict()
        })
    except Exception as e:
        db.session.rollback()
        logger.exception('Failed to update sponsor')
        return jsonify(_safe_error_payload(e, 'Failed to update sponsor')), 500


@api_bp.route('/admin/sponsors/<int:sponsor_id>', methods=['DELETE'])
@require_api_key
def admin_delete_sponsor(sponsor_id):
    """Delete a sponsor."""
    try:
        sponsor = Sponsor.query.get(sponsor_id)
        if not sponsor:
            return jsonify({'error': 'Sponsor not found'}), 404
        
        db.session.delete(sponsor)
        db.session.commit()
        
        return jsonify({'message': 'Sponsor deleted'})
    except Exception as e:
        db.session.rollback()
        logger.exception('Failed to delete sponsor')
        return jsonify(_safe_error_payload(e, 'Failed to delete sponsor')), 500


@api_bp.route('/admin/sponsors/reorder', methods=['POST'])
@require_api_key
def admin_reorder_sponsors():
    """Reorder sponsors by providing an array of sponsor IDs in the desired order."""
    try:
        data = request.get_json() or {}
        sponsor_ids = data.get('sponsor_ids', [])
        
        if not sponsor_ids or not isinstance(sponsor_ids, list):
            return jsonify({'error': 'sponsor_ids array is required'}), 400
        
        for index, sponsor_id in enumerate(sponsor_ids):
            sponsor = Sponsor.query.get(sponsor_id)
            if sponsor:
                sponsor.display_order = index
        
        db.session.commit()
        
        return jsonify({'message': 'Sponsors reordered'})
    except Exception as e:
        db.session.rollback()
        logger.exception('Failed to reorder sponsors')
        return jsonify(_safe_error_payload(e, 'Failed to reorder sponsors')), 500


@api_bp.route('/admin/team-aliases', methods=['GET'])
@require_api_key
def admin_list_team_aliases():
    """List all team aliases."""
    try:
        aliases = TeamAlias.query.order_by(TeamAlias.canonical_name.asc(), TeamAlias.alias.asc()).all()
        return jsonify([a.to_dict() for a in aliases])
    except Exception as e:
        logger.exception('Failed to list team aliases')
        return jsonify(_safe_error_payload(e, 'Failed to list team aliases')), 500


@api_bp.route('/admin/team-aliases', methods=['POST'])
@require_api_key
def admin_create_team_alias():
    """Create a new team alias."""
    try:
        data = request.get_json() or {}
        canonical_name = (data.get('canonical_name') or '').strip()
        alias_name = (data.get('alias') or '').strip()
        
        if not canonical_name or not alias_name:
            return jsonify({'error': 'canonical_name and alias are required'}), 400
            
        # Check if alias already exists
        existing = TeamAlias.query.filter(func.lower(TeamAlias.alias) == func.lower(alias_name)).first()
        if existing:
            return jsonify({'error': f'Alias "{alias_name}" already exists for "{existing.canonical_name}"'}), 400
            
        # Try to find team_id for canonical name
        team = Team.query.filter(func.lower(Team.name) == func.lower(canonical_name)).first()
        team_id = team.id if team else None
        
        alias = TeamAlias(
            canonical_name=canonical_name,
            alias=alias_name,
            team_id=team_id
        )
        db.session.add(alias)
        db.session.commit()
        
        return jsonify(alias.to_dict()), 201
    except Exception as e:
        db.session.rollback()
        logger.exception('Failed to create team alias')
        return jsonify(_safe_error_payload(e, 'Failed to create team alias')), 500


@api_bp.route('/admin/team-aliases/<int:alias_id>', methods=['DELETE'])
@require_api_key
def admin_delete_team_alias(alias_id):
    """Delete a team alias."""
    try:
        alias = db.session.get(TeamAlias, alias_id)
        if not alias:
            return jsonify({'error': 'Alias not found'}), 404
            
        db.session.delete(alias)
        db.session.commit()
        
        return jsonify({'message': 'Alias deleted'})
    except Exception as e:
        db.session.rollback()
        logger.exception('Failed to delete team alias')
        return jsonify(_safe_error_payload(e, 'Failed to delete team alias')), 500


@api_bp.route('/admin/manual-players', methods=['GET'])
@require_api_key
def admin_list_manual_players():
    """List all manual player submissions."""
    try:
        status = request.args.get('status')
        query = ManualPlayerSubmission.query
        
        if status:
            query = query.filter_by(status=status)
            
        submissions = query.order_by(ManualPlayerSubmission.created_at.desc()).all()
        return jsonify([s.to_dict() for s in submissions])
    except Exception as e:
        logger.exception('Failed to list manual players')
        return jsonify(_safe_error_payload(e, 'Failed to list manual players')), 500


@api_bp.route('/admin/manual-players/<int:submission_id>/review', methods=['POST'])
@require_api_key
def admin_review_manual_player(submission_id):
    """Review (approve/reject) a manual player submission."""
    try:
        submission = db.session.get(ManualPlayerSubmission, submission_id)
        if not submission:
            return jsonify({'error': 'Submission not found'}), 404
            
        data = request.get_json() or {}
        status = data.get('status')
        admin_notes = data.get('admin_notes')
        
        if status not in ['approved', 'rejected']:
            return jsonify({'error': 'Invalid status. Must be approved or rejected'}), 400
            
        submission.status = status
        if admin_notes is not None:
            submission.admin_notes = admin_notes
            
        submission.reviewed_at = datetime.now(timezone.utc)
        
        db.session.commit()
        
        return jsonify(submission.to_dict())
    except Exception as e:
        db.session.rollback()
        logger.exception('Failed to review manual player')
        return jsonify(_safe_error_payload(e, 'Failed to review manual player')), 500
